<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta
      name="viewport"
      content="width=device-width, initial-scale=1, maximum-scale=1, minimum-scale=1, user-scalable=no"
    />
    <link rel="shortcut icon" type="image/x-icon" href="/logo.png" />
    <link rel="stylesheet" href="/blog-other/umi.css" />
    <script>
      window.routerBase = "/blog-other";
    </script>
    <script>
      //! umi version: 3.5.41
    </script>
    <script>
      !(function () {
        var e =
            navigator.cookieEnabled && void 0 !== window.localStorage
              ? localStorage.getItem("dumi:prefers-color")
              : "auto",
          o = window.matchMedia("(prefers-color-scheme: dark)").matches,
          t = ["light", "dark", "auto"];
        document.documentElement.setAttribute(
          "data-prefers-color",
          e === t[2] ? (o ? t[1] : t[0]) : t.indexOf(e) > -1 ? e : t[0]
        );
      })();
    </script>
    <title>11｜深度学习（上）：用CNN带你认识深度学习 - 大师兄</title>
  </head>
  <body>
    <div id="root"><div class="__dumi-default-layout" data-route="/零基础实战机器学习/03.业务场景闯关篇/07" data-show-sidemenu="true" data-show-slugs="true" data-site-mode="true" data-gapless="false"><div class="__dumi-default-navbar" data-mode="site"><button class="__dumi-default-navbar-toggle"></button><a class="__dumi-default-navbar-logo" style="background-image:url(&#x27;/logo.png&#x27;)" href="/blog-other/">大师兄</a><nav><div class="__dumi-default-search"><input type="search" class="__dumi-default-search-input" value=""/><ul></ul></div><span>前端开发<ul><li><a href="/blog-other/说透低代码">说透低代码</a></li><li><a href="/blog-other/反爬虫兵法演绎20讲">反爬虫兵法演绎20讲</a></li></ul></span><span>产品与用户体验<ul><li><a href="/blog-other/大厂广告产品心法">大厂广告产品心法</a></li></ul></span><span>面试<ul><li><a href="/blog-other/技术面试官识人手册">技术面试官识人手册</a></li><li><a href="/blog-other/面试现场">面试现场</a></li></ul></span><span>杂谈<ul><li><a href="/blog-other/乔新亮的cto成长复盘">乔新亮的cto成长复盘</a></li><li><a href="/blog-other/互联网人的英语私教课">互联网人的英语私教课</a></li><li><a href="/blog-other/从0开始学游戏开发">从0开始学游戏开发</a></li><li><a href="/blog-other/全栈工程师修炼指南">全栈工程师修炼指南</a></li><li><a href="/blog-other/手机摄影">手机摄影</a></li><li><a href="/blog-other/物联网开发实战">物联网开发实战</a></li><li><a href="/blog-other/白话法律42讲">白话法律42讲</a></li><li><a href="/blog-other/说透5g">说透5g</a></li><li><a href="/blog-other/超级访谈对话张雪峰">超级访谈对话张雪峰</a></li><li><a aria-current="page" class="active" href="/blog-other/零基础实战机器学习">零基础实战机器学习</a></li></ul></span><div class="__dumi-default-navbar-tool"><div class="__dumi-default-dark"><div class="__dumi-default-dark-switch "></div></div></div></nav></div><div class="__dumi-default-menu" data-mode="site"><div class="__dumi-default-menu-inner"><div class="__dumi-default-menu-header"><a class="__dumi-default-menu-logo" style="background-image:url(&#x27;/logo.png&#x27;)" href="/blog-other/"></a><h1>大师兄</h1><p></p></div><div class="__dumi-default-menu-mobile-area"><ul class="__dumi-default-menu-nav-list"><li>前端开发<ul><li><a href="/blog-other/说透低代码">说透低代码</a></li><li><a href="/blog-other/反爬虫兵法演绎20讲">反爬虫兵法演绎20讲</a></li></ul></li><li>产品与用户体验<ul><li><a href="/blog-other/大厂广告产品心法">大厂广告产品心法</a></li></ul></li><li>面试<ul><li><a href="/blog-other/技术面试官识人手册">技术面试官识人手册</a></li><li><a href="/blog-other/面试现场">面试现场</a></li></ul></li><li>杂谈<ul><li><a href="/blog-other/乔新亮的cto成长复盘">乔新亮的cto成长复盘</a></li><li><a href="/blog-other/互联网人的英语私教课">互联网人的英语私教课</a></li><li><a href="/blog-other/从0开始学游戏开发">从0开始学游戏开发</a></li><li><a href="/blog-other/全栈工程师修炼指南">全栈工程师修炼指南</a></li><li><a href="/blog-other/手机摄影">手机摄影</a></li><li><a href="/blog-other/物联网开发实战">物联网开发实战</a></li><li><a href="/blog-other/白话法律42讲">白话法律42讲</a></li><li><a href="/blog-other/说透5g">说透5g</a></li><li><a href="/blog-other/超级访谈对话张雪峰">超级访谈对话张雪峰</a></li><li><a aria-current="page" class="active" href="/blog-other/零基础实战机器学习">零基础实战机器学习</a></li></ul></li></ul><div class="__dumi-default-dark"><div class="__dumi-default-dark-switch "><button title="Dark theme" class="__dumi-default-dark-moon "><svg viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="3854" width="22" height="22"><path d="M991.816611 674.909091a69.166545 69.166545 0 0 0-51.665455-23.272727 70.795636 70.795636 0 0 0-27.438545 5.585454A415.674182 415.674182 0 0 1 754.993338 698.181818c-209.594182 0-393.472-184.785455-393.472-395.636363 0-52.363636 38.539636-119.621818 69.515637-173.614546 4.887273-8.610909 9.634909-16.756364 14.103272-24.901818A69.818182 69.818182 0 0 0 384.631156 0a70.842182 70.842182 0 0 0-27.438545 5.585455C161.678429 90.298182 14.362065 307.898182 14.362065 512c0 282.298182 238.824727 512 532.38691 512a522.286545 522.286545 0 0 0 453.957818-268.334545A69.818182 69.818182 0 0 0 991.816611 674.909091zM546.679156 954.181818c-248.785455 0-462.941091-192-462.941091-442.181818 0-186.647273 140.637091-372.829091 300.939637-442.181818-36.817455 65.629091-92.578909 151.970909-92.578909 232.727273 0 250.181818 214.109091 465.454545 462.917818 465.454545a488.331636 488.331636 0 0 0 185.181091-46.545455 453.003636 453.003636 0 0 1-393.565091 232.727273z m103.656728-669.323636l-14.266182 83.781818a34.909091 34.909091 0 0 0 50.362182 36.770909l74.775272-39.563636 74.752 39.563636a36.142545 36.142545 0 0 0 16.174546 3.956364 34.909091 34.909091 0 0 0 34.210909-40.727273l-14.289455-83.781818 60.509091-59.345455a35.025455 35.025455 0 0 0-19.223272-59.578182l-83.61891-12.101818-37.376-76.101818a34.56 34.56 0 0 0-62.254545 0l-37.376 76.101818-83.618909 12.101818a34.909091 34.909091 0 0 0-19.246546 59.578182z m70.423272-64.698182a34.280727 34.280727 0 0 0 26.135273-19.083636l14.312727-29.090909 14.336 29.090909a34.257455 34.257455 0 0 0 26.135273 19.083636l32.046546 4.887273-23.272728 22.574545a35.234909 35.234909 0 0 0-10.007272 30.952727l5.46909 32.116364-28.625454-15.127273a34.490182 34.490182 0 0 0-32.302546 0l-28.695272 15.127273 5.469091-32.116364a35.141818 35.141818 0 0 0-9.984-30.952727l-23.272728-22.574545z" p-id="3855"></path></svg></button><button title="Light theme" class="__dumi-default-dark-sun "><svg viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="4026" width="22" height="22"><path d="M915.2 476.16h-43.968c-24.704 0-44.736 16-44.736 35.84s20.032 35.904 44.736 35.904H915.2c24.768 0 44.8-16.064 44.8-35.904s-20.032-35.84-44.8-35.84zM512 265.6c-136.704 0-246.464 109.824-246.464 246.4 0 136.704 109.76 246.464 246.464 246.464S758.4 648.704 758.4 512c0-136.576-109.696-246.4-246.4-246.4z m0 425.6c-99.008 0-179.2-80.128-179.2-179.2 0-98.944 80.192-179.2 179.2-179.2S691.2 413.056 691.2 512c0 99.072-80.192 179.2-179.2 179.2zM197.44 512c0-19.84-19.136-35.84-43.904-35.84H108.8c-24.768 0-44.8 16-44.8 35.84s20.032 35.904 44.8 35.904h44.736c24.768 0 43.904-16.064 43.904-35.904zM512 198.464c19.776 0 35.84-20.032 35.84-44.8v-44.8C547.84 84.032 531.84 64 512 64s-35.904 20.032-35.904 44.8v44.8c0 24.768 16.128 44.864 35.904 44.864z m0 627.136c-19.776 0-35.904 20.032-35.904 44.8v44.736C476.096 940.032 492.16 960 512 960s35.84-20.032 35.84-44.8v-44.736c0-24.768-16.064-44.864-35.84-44.864z m329.92-592.832c17.472-17.536 20.288-43.072 6.4-57.024-14.016-14.016-39.488-11.2-57.024 6.336-4.736 4.864-26.496 26.496-31.36 31.36-17.472 17.472-20.288 43.008-6.336 57.024 13.952 14.016 39.488 11.2 57.024-6.336 4.8-4.864 26.496-26.56 31.296-31.36zM213.376 759.936c-4.864 4.8-26.56 26.624-31.36 31.36-17.472 17.472-20.288 42.944-6.4 56.96 14.016 13.952 39.552 11.2 57.024-6.336 4.8-4.736 26.56-26.496 31.36-31.36 17.472-17.472 20.288-43.008 6.336-56.96-14.016-13.952-39.552-11.072-56.96 6.336z m19.328-577.92c-17.536-17.536-43.008-20.352-57.024-6.336-14.08 14.016-11.136 39.488 6.336 57.024 4.864 4.864 26.496 26.56 31.36 31.424 17.536 17.408 43.008 20.288 56.96 6.336 14.016-14.016 11.264-39.488-6.336-57.024-4.736-4.864-26.496-26.56-31.296-31.424z m527.168 628.608c4.864 4.864 26.624 26.624 31.36 31.424 17.536 17.408 43.072 20.224 57.088 6.336 13.952-14.016 11.072-39.552-6.4-57.024-4.864-4.8-26.56-26.496-31.36-31.36-17.472-17.408-43.072-20.288-57.024-6.336-13.952 14.016-11.008 39.488 6.336 56.96z" p-id="4027"></path></svg></button><button title="Default to system" class="__dumi-default-dark-auto "><svg viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="11002" width="22" height="22"><path d="M127.658667 492.885333c0-51.882667 10.24-101.717333 30.378666-149.162666s47.786667-88.064 81.92-122.538667 75.093333-61.781333 122.538667-81.92 96.938667-30.378667 149.162667-30.378667 101.717333 10.24 149.162666 30.378667 88.405333 47.786667 122.88 81.92 61.781333 75.093333 81.92 122.538667 30.378667 96.938667 30.378667 149.162666-10.24 101.717333-30.378667 149.162667-47.786667 88.405333-81.92 122.88-75.093333 61.781333-122.88 81.92-97.28 30.378667-149.162666 30.378667-101.717333-10.24-149.162667-30.378667-88.064-47.786667-122.538667-81.92-61.781333-75.093333-81.92-122.88-30.378667-96.938667-30.378666-149.162667z m329.045333 0c0 130.048 13.994667 244.394667 41.984 343.381334h12.970667c46.762667 0 91.136-9.216 133.461333-27.306667s78.848-42.666667 109.568-73.386667 54.954667-67.242667 73.386667-109.568 27.306667-86.698667 27.306666-133.461333c0-46.421333-9.216-90.794667-27.306666-133.12s-42.666667-78.848-73.386667-109.568-67.242667-54.954667-109.568-73.386667-86.698667-27.306667-133.461333-27.306666h-11.605334c-28.672 123.562667-43.349333 237.909333-43.349333 343.722666z" p-id="11003"></path></svg></button></div></div></div><ul class="__dumi-default-menu-list"><li><a href="/blog-other/零基础实战机器学习">零基础实战机器学习</a></li><li><a href="/blog-other/零基础实战机器学习/01.开篇词">01.开篇词</a><ul><li><a href="/blog-other/零基础实战机器学习/01.开篇词/01"><span>开篇词｜开发者为什么要从实战出发学机器学习？</span></a></li></ul></li><li><a href="/blog-other/零基础实战机器学习/02.准备篇">02.准备篇</a><ul><li><a href="/blog-other/零基础实战机器学习/02.准备篇/01"><span>01｜打好基础：到底什么是机器学习？</span></a></li><li><a href="/blog-other/零基础实战机器学习/02.准备篇/02"><span>02｜工具准备：安装并使用Jupyter Notebook</span></a></li><li><a href="/blog-other/零基础实战机器学习/02.准备篇/03"><span>03｜实战5步（上）：怎么定义问题和预处理数据？</span></a></li><li><a href="/blog-other/零基础实战机器学习/02.准备篇/04"><span>04｜ 实战5步（下）：怎么建立估计10万+软文点击率的模型？</span></a></li></ul></li><li><a aria-current="page" class="active" href="/blog-other/零基础实战机器学习/03.业务场景闯关篇">03.业务场景闯关篇</a><ul><li><a href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/01"><span>05 | 数据探索：怎样从数据中找到用户的RFM值？</span></a></li><li><a href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/02"><span>06 | 聚类分析：如何用RFM给电商用户做价值分组画像？</span></a></li><li><a href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/03"><span>07｜回归分析：怎样用模型预测用户的生命周期价值？</span></a></li><li><a href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/04"><span>08 | 模型优化（上）：怎么用特征工程提高模型效率？</span></a></li><li><a href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/05"><span>09｜模型优化（中）：防止过拟合，模型也不能太精细</span></a></li><li><a href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/06"><span>10｜模型优化（下）：交叉验证，同时寻找最优的参数</span></a></li><li><a aria-current="page" class="active" href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/07"><span>11｜深度学习（上）：用CNN带你认识深度学习</span></a></li><li><a href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/08"><span>12｜深度学习（中）：如何用RNN预测激活率走势？</span></a></li><li><a href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/09"><span>13｜深度学习（下）：3招提升神经网络预测准确率</span></a></li><li><a href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/10"><span>14｜留存分析：哪些因素会影响用户的留存率？</span></a></li><li><a href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/11"><span>15｜二元分类：怎么预测用户是否流失？从逻辑回归到深度学习</span></a></li><li><a href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/12"><span>16｜性能评估：不平衡数据集应该使用何种评估指标？</span></a></li><li><a href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/13"><span>17｜集成学习：机器学习模型如何“博采众长”?</span></a></li><li><a href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/14"><span>18 | 增长模型：用XGBoost评估裂变海报的最佳受众群体</span></a></li></ul></li><li><a href="/blog-other/零基础实战机器学习/04.持续赋能篇">04.持续赋能篇</a><ul><li><a href="/blog-other/零基础实战机器学习/04.持续赋能篇/01"><span>19 | 胸有成竹：如何快速定位合适的机器学习算法？</span></a></li><li><a href="/blog-other/零基础实战机器学习/04.持续赋能篇/02"><span>20 | 模型部署：怎么发布训练好的机器学习模型？</span></a></li><li><a href="/blog-other/零基础实战机器学习/04.持续赋能篇/03"><span>21｜持续精进：如何在机器学习领域中找准前进的方向？</span></a></li></ul></li><li><a href="/blog-other/零基础实战机器学习/05.结束语">05.结束语</a><ul><li><a href="/blog-other/零基础实战机器学习/05.结束语/01"><span>一套习题，测出你对机器学习的掌握程度</span></a></li><li><a href="/blog-other/零基础实战机器学习/05.结束语/02"><span>结束语 | 可以不完美，但重要的是马上开始</span></a></li></ul></li><li><a href="/blog-other/零基础实战机器学习/summary">零基础实战机器学习</a></li></ul></div></div><ul role="slug-list" class="__dumi-default-layout-toc"><li title="问题定义" data-depth="2"><a href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/07#问题定义"><span>问题定义</span></a></li><li title="数据收集和预处理" data-depth="2"><a href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/07#数据收集和预处理"><span>数据收集和预处理</span></a></li><li title="1.数据的导入及可视化" data-depth="3"><a href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/07#1数据的导入及可视化"><span>1.数据的导入及可视化</span></a></li><li title="2.构建特征集和标签集" data-depth="3"><a href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/07#2构建特征集和标签集"><span>2.构建特征集和标签集</span></a></li><li title="3. 特征工程和数据集拆分" data-depth="3"><a href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/07#3-特征工程和数据集拆分"><span>3. 特征工程和数据集拆分</span></a></li><li title="选择算法建立模型" data-depth="2"><a href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/07#选择算法建立模型"><span>选择算法建立模型</span></a></li><li title="1.选择算法" data-depth="3"><a href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/07#1选择算法"><span>1.选择算法</span></a></li><li title="2.建立模型" data-depth="3"><a href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/07#2建立模型"><span>2.建立模型</span></a></li><li title="模型的训练和拟合" data-depth="2"><a href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/07#模型的训练和拟合"><span>模型的训练和拟合</span></a></li><li title="模型性能的评估" data-depth="2"><a href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/07#模型性能的评估"><span>模型性能的评估</span></a></li><li title="总结一下" data-depth="2"><a href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/07#总结一下"><span>总结一下</span></a></li><li title="思考题" data-depth="2"><a href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/07#思考题"><span>思考题</span></a></li></ul><div class="__dumi-default-layout-content"><div class="markdown"><h1 id="11深度学习上用cnn带你认识深度学习"><a aria-hidden="true" tabindex="-1" href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/07#11深度学习上用cnn带你认识深度学习"><span class="icon icon-link"></span></a>11｜深度学习（上）：用CNN带你认识深度学习</h1><p>你好，我是黄佳。</p><p>随着课程的不断深入，我们已经成功闯过两个关卡，获客关和变现关，学到了多种机器学习算法和模型的优化方法。今天这一讲，我们正式进入“激活关”。在这一关中，我们的主要任务是根据易速鲜花App的历史记录，借助深度学习神经网络，来预测它的日激活数趋势。通过“激活关”，相信你会对深度学习神经网络的原理和用法有一个比较深入的理解。</p><p><img src="/blog-other/static/httpsstatic001geekbangorgresourceimagea038a02545b94937eaf80701766acf6d7038.72b86f5f.jpg" alt=""/></p><p>不过，在正式进入这个项目之前呢，我们需要先打打基础，解决两个问题：1. 深度学习的原理是什么？2. 怎么搭建起一个深层神经网络CNN？这两个问题，我们将通过一个完整的小项目来搞定。</p><h2 id="问题定义"><a aria-hidden="true" tabindex="-1" href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/07#问题定义"><span class="icon icon-link"></span></a>问题定义</h2><p>易速鲜花的供应商每天都会发来大量的鲜花图片，不过，这些图片都没有按鲜花的类别进行分门别类，要是由人工来做的话，比较麻烦，成本也比较高。现在，我们需要根据易速鲜花大量已归类的鲜花图片，来建立一个能识别鲜花的模型，给未归类的图片自动贴标签。</p><p><img src="/blog-other/static/httpsstatic001geekbangorgresourceimageb944b9b26c72c613730ccdf5a908771a9144.762fc536.png" alt=""/></p><p>这是一个典型的分类问题，同时也是一个计算机视觉领域的图片识别问题。那么下面我们先来看看在哪里可以找到这些花的图片。</p><h2 id="数据收集和预处理"><a aria-hidden="true" tabindex="-1" href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/07#数据收集和预处理"><span class="icon icon-link"></span></a>数据收集和预处理</h2><p>不知道你是否还记得，在<a target="_blank" rel="noopener noreferrer" href="https://time.geekbang.org/column/article/413648">第2讲<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="__dumi-default-external-link-icon"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>中我曾经说过，在深度学习的实战部分，我会带你去Kaggle网站用一用GPU、TPU等加速器。Kaggle网站是一个在线Jupyter Notebook平台，同时也是数据科学爱好者最好的学校交流场所，里面有数据集、源代码、课程资料等。我们这个项目会在Kaggle网站上完成。</p><h3 id="1数据的导入及可视化"><a aria-hidden="true" tabindex="-1" href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/07#1数据的导入及可视化"><span class="icon icon-link"></span></a>1.数据的导入及可视化</h3><p>在Kaggle网站上，有一个<a target="_blank" rel="noopener noreferrer" href="https://www.kaggle.com/alxmamaev/flowers-recognition">公开的数据集<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="__dumi-default-external-link-icon"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>，里面收纳了各类花朵图片，我们可以将它作为这个项目的数据集。由于这个花朵图片的数据集较大，我们不必把它下载下来，可以直接在网站中创建Notebook，来完成对花朵图片进行归类的工作。</p><p>首先，请你点开这个<a target="_blank" rel="noopener noreferrer" href="https://www.kaggle.com/alxmamaev/flowers-recognition">花朵数据集<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="__dumi-default-external-link-icon"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>，单击New Notebook，建立你在Kaggle网站上的第一个深度学习Notebook。如果你没有用过这个网站，那在这个过程中，肯定需要你新注册用户，你跟着网站的说明走就可以了。当然了，你也可以访问我公开发表的<a target="_blank" rel="noopener noreferrer" href="https://www.kaggle.com/tohuangjia/cnn-network">Notebook<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="__dumi-default-external-link-icon"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>，并Copy &amp; Edit我的代码。</p><p><img src="/blog-other/static/httpsstatic001geekbangorgresourceimage3dc63d32d6aa7131e0bf07e1c64872d36cc6.2548d9f3.png" alt=""/></p><p>新建Notebook之后，你就会来到像这样的页面，这个页面的基本操作和我们在本机安装的Jupyter Notebook完全一致，它其实就是网页版的Jupyter Notebook：</p><p><img src="/blog-other/static/httpsstatic001geekbangorgresourceimage8700870784808087a94ca975b97ef3a41900.ed3c00ae.png" alt=""/></p><p>这里我要提醒你注意3个地方，就是我在图中用红框标出的：</p><ul><li><p>右上角红框里的Input，代表我们当前正在使用的数据集，基本上每一个Notebook都需要基于相关数据集创建；</p></li><li><p>左下角点击“+ Code”，可以生成一段新的代码单元；</p></li><li><p>右侧第二个红框是GPU加速选项，在跑深度学习项目时，你可以考虑打开它，如果你新注册了Kaggle，就会有30多个小时的GPU使用时间，跑完项目后你要记得关掉。还有就是，在安装新的工具包的时候，要打开Internet选项，不然，无法pip install新的包。</p></li></ul><p>在打开GPU选项的时候，会提示你每周可以使用GPU的小时数，选择“Turn on GPU”就可以了。</p><p><img src="/blog-other/static/httpsstatic001geekbangorgresourceimage2ab62a7dab64c717329b73c73aec10092ab6.97c5abc4.png" alt=""/></p><p>下面，我们指定4个花朵目录，并通过Open CV（开源计算机视觉库）工具箱，读入图片的数据。OpenCV是一个跨平台的开源计算机视觉方面的API库，这里我们应用其中的imread和resize功能读入并裁剪图片到150*150像素：</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">import numpy as np # 导入Numpy</span></div><div class="token-line"><span class="token plain">    import pandas as pd # 导入Pandas</span></div><div class="token-line"><span class="token plain">    import os # 导入OS</span></div><div class="token-line"><span class="token plain">    import cv2 # 导入Open CV工具箱</span></div><div class="token-line"><span class="token plain">    </span></div><div class="token-line"><span class="token plain">    </span></div><div class="token-line"><span class="token plain">    print(os.listdir(&#x27;../input/flowers-recognition/flowers&#x27;)) #打印目录结构</span></div><div class="token-line"><span class="token plain">    daisy_dir=&#x27;../input/flowers-recognition/flowers/daisy&#x27; #雏菊目录</span></div><div class="token-line"><span class="token plain">    rose_dir=&#x27;../input/flowers-recognition/flowers/rose&#x27; #玫瑰目录</span></div><div class="token-line"><span class="token plain">    sunflower_dir=&#x27;../input/flowers-recognition/flowers/sunflower&#x27; #向日葵目录</span></div><div class="token-line"><span class="token plain">    tulip_dir=&#x27;../input/flowers-recognition/flowers/tulip&#x27; #郁金香目录</span></div><div class="token-line"><span class="token plain">    </span></div><div class="token-line"><span class="token plain">    </span></div><div class="token-line"><span class="token plain">    X = [] #初始化</span></div><div class="token-line"><span class="token plain">    y_label = [] #初始化</span></div><div class="token-line"><span class="token plain">    imgsize = 150 #图片大小</span></div><div class="token-line"><span class="token plain">    # 定义一个函数读入花的图片</span></div><div class="token-line"><span class="token plain">    def training_data(label,data_dir):</span></div><div class="token-line"><span class="token plain">        print (&quot;正在读入：&quot;, data_dir) </span></div><div class="token-line"><span class="token plain">        for img in os.listdir(data_dir): #目录</span></div><div class="token-line"><span class="token plain">            path = os.path.join(data_dir,img) #目录+文件名</span></div><div class="token-line"><span class="token plain">            img = cv2.imread(path,cv2.IMREAD_COLOR) #读入图片</span></div><div class="token-line"><span class="token plain">            img = cv2.resize(img,(imgsize,imgsize)) #设定图片像素维度</span></div><div class="token-line"><span class="token plain">            X.append(np.array(img)) #X特征集</span></div><div class="token-line"><span class="token plain">            y_label.append(str(label)) #y标签，即花的类别</span></div><div class="token-line"><span class="token plain">    # 读入目录中的图片</span></div><div class="token-line"><span class="token plain">    training_data(&#x27;daisy&#x27;,daisy_dir) #读入雏菊</span></div><div class="token-line"><span class="token plain">    training_data(&#x27;rose&#x27;,rose_dir) #读入玫瑰</span></div><div class="token-line"><span class="token plain">    training_data(&#x27;sunflower&#x27;,sunflower_dir) #读入向日葵</span></div><div class="token-line"><span class="token plain">    training_data(&#x27;tulip&#x27;,tulip_dir) #读入郁金香</span></div></pre></div><p>输出如下：</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">正在读入： ../input/flowers/daisy</span></div><div class="token-line"><span class="token plain">    正在读入： ../input/flowers/sunflower</span></div><div class="token-line"><span class="token plain">    正在读入： ../input/flowers/tulip</span></div><div class="token-line"><span class="token plain">    正在读入： ../input/flowers/rose</span></div></pre></div><p>图片数据导入程序之后，我们随机用imshow功能显示几张花朵的图片，来确认一下我们已经成功读入了图片。</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">import matplotlib.pyplot as plt # 导入matplotlib</span></div><div class="token-line"><span class="token plain">    import random as rdm # 导入随机数工具</span></div><div class="token-line"><span class="token plain">    # 随机显示几张漂亮的花朵图片吧</span></div><div class="token-line"><span class="token plain">    fig,ax=plt.subplots(5,2) #画布</span></div><div class="token-line"><span class="token plain">    fig.set_size_inches(15,15) #大小</span></div><div class="token-line"><span class="token plain">    for i in range(5):</span></div><div class="token-line"><span class="token plain">        for j in range (2):</span></div><div class="token-line"><span class="token plain">            r=rdm.randint(0,len(X)) #随机选择图片</span></div><div class="token-line"><span class="token plain">            ax[i,j].imshow(X[r]) #显示图片</span></div><div class="token-line"><span class="token plain">            ax[i,j].set_title(&#x27;Flower: &#x27;+y_label[r]) #花的类别</span></div><div class="token-line"><span class="token plain">    plt.tight_layout() #绘图</span></div></pre></div><p>输出如下：</p><p><img src="/blog-other/static/httpsstatic001geekbangorgresourceimagef73df7f9477a11413a070e0c1a45b8290c3d.ce5b2bb5.png" alt=""/></p><p>好，到这里呢，按照常规的机器学习项目步骤，紧接着下一个数据预处理环节就是数据清洗了，不过我们这个数据集的质量不错，没有需要清洗的内容，所以我们直接来构建特征集X和标签集y。</p><h3 id="2构建特征集和标签集"><a aria-hidden="true" tabindex="-1" href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/07#2构建特征集和标签集"><span class="icon icon-link"></span></a>2.构建特征集和标签集</h3><p>在下面的代码中，我们用LabelEncoder给标签y编码，并且把特征集X转换为了张量数组：</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">from sklearn.preprocessing import LabelEncoder # 导入标签编码工具</span></div><div class="token-line"><span class="token plain">    from tensorflow.keras.utils import to_categorical # 导入One-hot编码工具</span></div><div class="token-line"><span class="token plain">    label_encoder = LabelEncoder()</span></div><div class="token-line"><span class="token plain">    y = label_encoder.fit_transform(y_label) # 标签编码</span></div><div class="token-line"><span class="token plain">    y = to_categorical(y,4) # 将标签转换为One-hot编码</span></div><div class="token-line"><span class="token plain">    X = np.array(X) # 将X从列表转换为张量数组</span></div></pre></div><p>请你注意，这时候特征集X的格式不再是DataFrame表结构，而是NumPy数组，在机器学习里，我们把它称为“张量”，它的形状输出如下：</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">array([[[[214, 237, 233],</span></div><div class="token-line"><span class="token plain">             [224, 234, 235],</span></div><div class="token-line"><span class="token plain">             [229, 232, 237],</span></div><div class="token-line"><span class="token plain">             ...,</span></div><div class="token-line"><span class="token plain">             [ 67,  93, 124],</span></div><div class="token-line"><span class="token plain">             [ 63,  91, 121],</span></div><div class="token-line"><span class="token plain">             [ 61,  93, 115]]]], dtype=uint8)</span></div></pre></div><p>如果用NumPy里面shape（就是张量的形状）的属性，我们就会看到当前特征集X的格式是4阶的张量。</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">X.shape</span></div></pre></div><p>输出如下：</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">(3265, 150, 150, 3)</span></div></pre></div><p>这个输出结果表示，在当前这个数据集中，一共有3265张150像素*150像素的图片，且所有图片的颜色通道数为RGB 3。</p><p>相信你已经体会到了，我们这里说的“4阶张量”代表了图片数据集中的4个维度：行（图片数量）、宽（像素宽）、高（像素高）和颜色通道数，缺少其中任何一个，都无法精准描述这个图片数据集。这就是为什么我们当前这个特征集X不再是我们之前常见的二维DataFrame表结构，而是NumPy数组，也就是深度学习中的“张量”。</p><p>如果是视频格式的数据集，则需要5阶张量才放得下，其形状为（样本，帧，高度，宽度，颜色深度）。此外，文本数据集通常是3阶张量，形状为（样本，序号，字编码）</p><p>其实，从严格意义上讲，前几节课中那些的二维DataFrame数据表格，也就是一行一列，也都属于2阶张量。</p><p>那为什么我们这里强调“阶”，而不再叫“维度”呢？这是因为在机器学习中，我们又把每一个阶上的特征的个数称为“特征的维度”。所以，为了避免混淆，当我们提到张量时，就称其为几<strong>阶</strong>张量；而提到特征时，就称特征的<strong>维度</strong>是多少。</p><p>对于这个花朵图片的数据集来说，在图片“宽度”这阶特征上面，就有150个维度，对应着150个值；而“高度”这阶特征呢，也是150个维度；宽、高组合，就形成了150*150，共这么多个像素点。这里面有点绕，你可以停下来体会一下，也可以看看下面的图。</p><p><img src="/blog-other/static/httpsstatic001geekbangorgresourceimageb93db9d7880759d497bb6da4ac604f61153d.58d44c2c.jpg" alt="" title="各种张量"/></p><p>现在你应该明白了，为什么像图片、视频、文本这样的数据集，特征的维度和整体特征空间，体量都如此巨大。就这么一张小小的150 * 150像素的RGB图片，特征就有可能达到150 * 150 * 3的天文数字。所以，除了深层神经网络之外，传统机器学习方法根本解决不了。</p><p>而此时，y的格式也转换成了One-hot编码的张量。至于什么是One-hot编码，我们在<a target="_blank" rel="noopener noreferrer" href="https://time.geekbang.org/column/article/418354">第8讲<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="__dumi-default-external-link-icon"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>中介绍过，我在这里就不重复了。</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">array([[1., 0., 0., 0.],</span></div><div class="token-line"><span class="token plain">           [1., 0., 0., 0.],</span></div><div class="token-line"><span class="token plain">           [1., 0., 0., 0.],</span></div><div class="token-line"><span class="token plain">           ...,</span></div><div class="token-line"><span class="token plain">           [0., 1., 0., 0.],</span></div><div class="token-line"><span class="token plain">           [0., 1., 0., 0.],</span></div><div class="token-line"><span class="token plain">           [0., 1., 0., 0.]], dtype=float32)</span></div></pre></div><p>其中，[1., 0., 0., 0.]代表Daisy（雏菊），[0., 1., 0., 0.]就代表Rose（玫瑰），[0., 0., 1., 0.]就代表Sunflower（向日葵），[0., 0., 0., 1.]就代表Tulip（郁金香）。</p><p>至此，我们的特征集X和标签集y就构建完毕。</p><h3 id="3-特征工程和数据集拆分"><a aria-hidden="true" tabindex="-1" href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/07#3-特征工程和数据集拆分"><span class="icon icon-link"></span></a>3. 特征工程和数据集拆分</h3><p>我们在<a target="_blank" rel="noopener noreferrer" href="https://time.geekbang.org/column/article/413057">第1讲<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="__dumi-default-external-link-icon"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>中说过，深层神经网络的厉害之处在于，它能对非结构的数据集进行自动的复杂特征提取，完全不需要人工干预。因此，我们并不用做什么复杂的特征工程处理。</p><p>不过，由于神经网络特别喜欢小范围的数值，这里我们只需要做个归一化处理，把0-255的RGB像素值压缩到0-1之间最好。这个步骤非常重要，不然神经网络会跑不起来：</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">X = X/255 # 将X张量归一化</span></div></pre></div><p>接下来，就是数据集的拆分了，拆分的代码相信你已经非常熟悉了：</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">from sklearn.model_selection import train_test_split # 导入拆分工具</span></div><div class="token-line"><span class="token plain">    X_train, X_test, y_train, y_test = train_test_split(X, y, #拆分数据集</span></div><div class="token-line"><span class="token plain">                                 test_size=0.2,random_state=1)</span></div></pre></div><p>那到这里呢，我们就完成了数据集的所有准备工作，下面进入关键的建立模型环节。</p><h2 id="选择算法建立模型"><a aria-hidden="true" tabindex="-1" href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/07#选择算法建立模型"><span class="icon icon-link"></span></a>选择算法建立模型</h2><p>就我们的鲜花分类来说，选择算法的过程在所有问题中是最简单的。因为对于图像分类识别问题来说，深度学习中的卷积神经网络CNN是不二之选。</p><h3 id="1选择算法"><a aria-hidden="true" tabindex="-1" href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/07#1选择算法"><span class="icon icon-link"></span></a>1.选择算法</h3><p>我们曾经说过，深层神经网络是由大量的人工神经元相互联结而成，这些神经元都具有可以调整的参数，而训练机器、建立模型的过程，也就是确定网络参数的过程。一旦参数确定，模型也就确定下来了。关于深度神经网络的结构，你可以看看下面的图。</p><p><img src="/blog-other/static/httpsstatic001geekbangorgresourceimagef55af58bd8f5074c096279d302101348f45a.19f986e6.jpg" alt=""/></p><p>那么你还记不记得，深度学习和传统机器学习算法相比，它的优势在哪里呢？</p><p>没错，深度学习特别擅长处理非结构化的数据。我们前面的每一个实战所用的数据集，都是具有良好的结构，每一个特征是什么，我们都能说得很清楚。但是，还有另外一大类数据是没有良好结构的，比如说图形图像数据、文本数据等，这些数据集的特征长什么样呢？不太容易说清楚。</p><p>所以，传统的模型需要先做各种各样的特征工程，让数据变得“计算机友好”，再输入模型进行学习。而深度学习模型则可以自动进行特征提取，因此就省略掉了手工做特征工程的环节。你可以看一看图中所示的这个图片识别问题的机器学习流程。</p><p><img src="/blog-other/static/httpsstatic001geekbangorgresourceimagedf77df3931a4c47af6e4b326e73872b0b377.7f910774.jpg" alt=""/></p><p>那么既然鲜花分类的算法易于确定，下面我们看看怎么选择一个好用的深度学习包（也叫框架）来创建神经网络模型。</p><p>我们知道，在传统机器学习领域中，工具包sklearn是一枝独秀，但深度学习框架就不一样了，在这个领域呈现的是TensorFlow和PyTorch两强争霸的格局。这二者都是开源项目，一个来自Google，一个来自Facebook。PyTorch因为编辑开发环境更具亲和力，支持快速和动态的训练，现在越来越受学术界和研究型开发者的欢迎，而TensorFlow则因为可以直接部署机器学习模型，能快速地开发和构建 AI 相关产品，它仍然在保持着工业界的霸主地位。</p><p>TensorFlow的另一个优势是有简单的内置高级 API，这个API就是非常有名的Keras，这也是初学者进入深度学习领域的最佳入门选择。Keras把TensorFlow的底层深度学习功能进行了良好的封装，是最好用、最适合初学者上手的深度学习工具包了。所以，我们下面就选择Keras来搭建神经网络。</p><h3 id="2建立模型"><a aria-hidden="true" tabindex="-1" href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/07#2建立模型"><span class="icon icon-link"></span></a>2.建立模型</h3><p>在搭建卷积神经网络之前，我们先来简单了解一下卷积网络是怎么一回事，这样我们在用代码构建时，就能清楚地知道每一步在干什么了。这里会出现一些新名词、新概念，不过你也不用害怕，因为我们并不是用编码来实现每一层，而是通过调用API来构建它们，你只要了解基本的结构框架，以及每一层的功能是什么，就足够了。</p><p>一个典型的卷积网络结构如下所示，它实现了一个图像分类功能：输入的是图像，输出的是图像的类别标签。</p><p><img src="/blog-other/static/httpsstatic001geekbangorgresourceimagee618e60e42c79c339f2becb63c3b0d6c2a18.efb84740.png" alt="" title="卷积网络的结构图"/></p><p>整体来看，卷积神经网络由输入层、一个或多个卷积层和输出层的全连接层组成。下面，我们按照图中从左往右的顺序，逐一来了解。</p><p>网络左边是数据输入部分，也就是输入层。这一层会对数据做初始处理，比如标准化、图片压缩、降维等，让最初的数据集变成形状为（ 样本，图像高度，图像宽度，颜色深度）的数据集。</p><p>接着，到了中间的卷积层。这一层主要负责抽取图片的特征，其中的卷积核（上图中红框部分）也叫滤波器，能够自动进行图像特征的提取。一般卷积层之后会接一个池化层，主要用来降低特征空间的维度，其中，池化层又包括最大池化和平均池化，它们的区别就在于输出时计算图片区域池化窗口内元素的最大值还是平均值。</p><p>通常，卷积+池化的架构会重复几次，形成深度卷积网络。在这个过程中，图片特征张</p><p>量的尺寸通常会逐渐减小，而深度将逐渐加深。就像在图中画的那样，特征图从一张扁扁的纸片形状变成了胖胖的矩形。</p><p>之后是一个展平层，主要负责将网络展平。展平之后通常会接一个普通的全连接层。而最右边的输出层也是全连接层，用Softmax进行激活分类输出层，所有神经网络都是用Softmax做多分类的激活函数。</p><p>卷积网络的核心特点就是“卷积+池化”的架构，而“卷积层”中的参数，其实是远少于全连接层的。这是因为卷积网络中各层的神经元之间，包括输入层的特征和卷积层之间，不是彼此全部连接的，而是以卷积的方式有选择性的局部连接。这种结构除了能大大减少参数的数量之外，还有有利于对图像特征的提取。</p><p>说完了卷积网络的结构和原理，现在我们用Keras来建立卷积神经网络模型。因为Tensorflow和Keras完全集成在Kaggle的Notebook中了，所以你不用pip install它们。我们直接调用其中的API，就能够搭建起网络模型来。下面这段不到20行的代码，就为我们搭建起了一个能够为花朵图片分类的卷积神经网络：</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">from tensorflow.keras import layers # 导入所有层 行1</span></div><div class="token-line"><span class="token plain">    from tensorflow.keras import models # 导入所有模型 行2</span></div><div class="token-line"><span class="token plain">    cnn = models.Sequential() # 贯序模型 行3</span></div><div class="token-line"><span class="token plain">    cnn.add(layers.Conv2D(32, (3, 3), activation=&#x27;relu&#x27;, # 输入卷积层 行4</span></div><div class="token-line"><span class="token plain">                            input_shape=(150, 150, 3))) </span></div><div class="token-line"><span class="token plain">    cnn.add(layers.MaxPooling2D((2, 2))) # 最大池化层 行5</span></div><div class="token-line"><span class="token plain">    cnn.add(layers.Conv2D(64, (3, 3), activation=&#x27;relu&#x27;)) # 卷积层 行6</span></div><div class="token-line"><span class="token plain">    cnn.add(layers.MaxPooling2D((2, 2))) # 最大池化层 行7</span></div><div class="token-line"><span class="token plain">    cnn.add(layers.Conv2D(128, (3, 3), activation=&#x27;relu&#x27;)) # 卷积层 行8</span></div><div class="token-line"><span class="token plain">    cnn.add(layers.MaxPooling2D((2, 2))) # 最大池化层 行9</span></div><div class="token-line"><span class="token plain">    cnn.add(layers.Conv2D(128, (3, 3), activation=&#x27;relu&#x27;)) # 卷积层 行10</span></div><div class="token-line"><span class="token plain">    cnn.add(layers.MaxPooling2D((2, 2))) # 最大池化层 行11</span></div><div class="token-line"><span class="token plain">    cnn.add(layers.Flatten()) # 展平层 行12</span></div><div class="token-line"><span class="token plain">    cnn.add(layers.Dense(512, activation=&#x27;relu&#x27;)) # 全连接层 行13</span></div><div class="token-line"><span class="token plain">    cnn.add(layers.Dense(4, activation=&#x27;softmax&#x27;)) # 分类输出层 行14</span></div><div class="token-line"><span class="token plain">    cnn.compile(loss=&#x27;categorical_crossentropy&#x27;, # 损失函数 行15</span></div><div class="token-line"><span class="token plain">                optimizer=&#x27;RMSprop&#x27;, # 优化器</span></div><div class="token-line"><span class="token plain">                metrics=[&#x27;acc&#x27;]) # 评估指标</span></div></pre></div><p>怎么样，这段代码的结构看起来也不复杂吧。其实神经网络中最主要的结构就是“层”，各种各样不同的层像拼积木一样组合起来，就形成了各种各样的神经网络。而对于我们的卷积神经网络CNN来说，其中最重要的就是Conv2D这个卷积层，它是我们这个神经网络的主要功能层，决定了我们所构建的神经网络是一个卷积神经网络。</p><p>现在我们一起来看看我们刚才搭建的这个CNN网络是个什么样子的结构，你可以用下面的方法来图片化显示这整个的CNN神经网络模型：</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">from IPython.display import SVG # 实现神经网络结构的图形化显示</span></div><div class="token-line"><span class="token plain">    from tensorflow.keras.utils import model_to_dot # 导入model_to_dot工具</span></div><div class="token-line"><span class="token plain">    SVG(model_to_dot(cnn).create(prog=&#x27;dot&#x27;, format=&#x27;svg&#x27;)) # 绘图</span></div></pre></div><p>输出如下：</p><p><img src="/blog-other/static/httpsstatic001geekbangorgresourceimagecc27ccde4a8748ea21fe37a16faa22e82427.39de60bd.png" alt=""/></p><p>那么这个结构是怎么用刚才的Keras API搭建出来的呢？下面我就给你说一说，以后你自己搭建新的神经网络，也就是这样照猫画虎，搭积木似地往上构建就行了。</p><p>首先，我们通过cnn = models.Sequential()创建一个序贯模型（代码行3）。序贯模型也是最简单的模型，就是像盖楼一样，一层一层往上堆叠着搭新的层。我们所有神经网络都用序贯模型，还有一种模型是函数式模型，是比较高级地技巧，不过比较少见，你如果有兴趣可以查阅资料去了解。</p><p>然后，我们通过cnn.add(layers.Conv2D(32, (3, 3), activation=‘relu’, input_shape=(150, 150, 3)))语句（代码行4）在模型中加入了神经网络的输入层。这里面的激活函数relu我们以后再解释，现在你只要知道relu是一个常用的激活函数就可以了。这里，你需要注意的是，输入层需要通过input_shape=(150, 150, 3)指定输入的特征数据集的形状。这个刚才我们已经说过了，如果形状不对，等会儿拟合时就会报错。</p><p>接着，从代码行5开始直到行13，我们为神经网络添加了各种各样的中间层（也叫隐层），这些层如何添加、配置，我们有足够的自由去尝试。少可以两三层，多可以几万层。</p><p>其中，cnn.add(layers.Conv2D(64, (3, 3), activation=‘relu’))（代码行6）这个语句是用来添加输入层之后的中间卷积层的，这里面的64是输出空间的维度，也就是卷积过程中输出滤波器的数量，而(3, 3)则指定 2D 卷积窗口的高度和宽度。cnn.add(layers.MaxPooling2D((2, 2)))（代码行7）这个语句是用来添加池化层，(2, 2)也是指定 2D 卷积窗口的高度和宽度。</p><p>以此类推，卷积层+池化层的组合会持续出现，然后再输出层之前需要有展品层（代码行12）和全连接层（代码行13）。</p><p>我们接着看代码行14，cnn.add(layers.Dense(10, activation=‘softmax’)) 这一行叫做输出层，其中activation=&#x27;softmax’这个参数，就用于多分类输出。这个暂时你就记住，先不用去管细节，讲分类问题的时候我们再详谈。</p><p>那么你可能会问，怎么看一个神经网络是普通神经网络DNN，还是CNN或者RNN呢？这其中的关键就是看输入层和中间层主要是什么类型。DNN的输入层和中间层主要是Dense层，CNN的输入层和中间层主要是Conv1D、Conv2D或者Conv3D，RNN的输入层和中间层主要是SimpleRNN或者GRU或者LSTM层。</p><p>怎么样，讲到这里，你明白怎么去搭建神经网络了吗？我知道，如果你是第一次接触深度学习的话，这里的新概念的确有点多，不过，这里其实也并没有什么很难懂的东西，你需要把选择算法建立模型这个环节，反复阅读，咀嚼几遍，就可以掌握搭建神经网络模型的方法。</p><h2 id="模型的训练和拟合"><a aria-hidden="true" tabindex="-1" href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/07#模型的训练和拟合"><span class="icon icon-link"></span></a>模型的训练和拟合</h2><p>模型构建好之后，我们用非常熟悉的fit语句来进行训练：</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain"># 训练网络并把训练过程信息存入history对象</span></div><div class="token-line"><span class="token plain">    history = cnn.fit(X_train,y_train, #训练数据</span></div><div class="token-line"><span class="token plain">                      epochs=10, #训练轮次（梯度下降）</span></div><div class="token-line"><span class="token plain">                      validation_split=0.2) #训练的同时进行验证</span></div></pre></div><p>在训练过程中，我们还指定了validation_split，它可以在训练的同时，自动把训练集部分拆出来，进行验证，在每一个训练轮次中，求出该轮次在训练集和验证集上面的损失和预测准确率。</p><p>训练输出如下：</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">Train on 2089 samples, validate on 523 samples</span></div><div class="token-line"><span class="token plain">    Epoch 1/5</span></div><div class="token-line"><span class="token plain">    2089/2089 [==============================] - 86s 41ms/step - loss: 1.3523 - acc: 0.3978 - val_loss: 1.0567 - val_acc: 0.5411</span></div><div class="token-line"><span class="token plain">    Epoch 2/5</span></div><div class="token-line"><span class="token plain">    2089/2089 [==============================] - 85s 41ms/step - loss: 1.0167 - acc: 0.5692 - val_loss: 1.0336 - val_acc: 0.5526</span></div><div class="token-line"><span class="token plain">    Epoch 3/5</span></div><div class="token-line"><span class="token plain">    2089/2089 [==============================] - 85s 41ms/step - loss: 0.8912 - acc: 0.6343 - val_loss: 0.9183 - val_acc: 0.6310</span></div><div class="token-line"><span class="token plain">    Epoch 4/5</span></div><div class="token-line"><span class="token plain">    2089/2089 [==============================] - 84s 40ms/step - loss: 0.8295 - acc: 0.6596 - val_loss: 0.9289 - val_acc: 0.6138</span></div><div class="token-line"><span class="token plain">    Epoch 5/5</span></div><div class="token-line"><span class="token plain">    2089/2089 [==============================] - 85s 41ms/step - loss: 0.7228 - acc: 0.7056 - val_loss: 1.0086 - val_acc: 0.5736</span></div><div class="token-line"><span class="token plain">    ... ...</span></div></pre></div><p>这个输出的信息包括了训练的轮次（梯度下降的次数）、每轮训练的时长、每轮训练过程中的平均损失，以及分类的准确度。这里的每一个轮次，其实就是神经网络对其中的每一个神经元自动调参、通过梯度下降进行最优化的过程。</p><h2 id="模型性能的评估"><a aria-hidden="true" tabindex="-1" href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/07#模型性能的评估"><span class="icon icon-link"></span></a>模型性能的评估</h2><p>刚才的训练过程已经包含了验证的环节。不过，为了更好地体现训练过程中的损失变化情况，我们这里把每轮的损失和准确率做一个可视化，绘制出损失曲线，来展示模型在训练集上评估分数和损失的变化过程。</p><p>这种损失曲线其实你并不陌生，在<a target="_blank" rel="noopener noreferrer" href="https://time.geekbang.org/column/article/416824">第6讲<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="__dumi-default-external-link-icon"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>中，我们在讲K-Means算法中的手肘图时候就绘制过类似的曲线：</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">def show_history(history): # 显示训练过程中的学习曲线</span></div><div class="token-line"><span class="token plain">        loss = history.history[&#x27;loss&#x27;] #训练损失</span></div><div class="token-line"><span class="token plain">        val_loss = history.history[&#x27;val_loss&#x27;] #验证损失</span></div><div class="token-line"><span class="token plain">        epochs = range(1, len(loss) + 1) #训练轮次</span></div><div class="token-line"><span class="token plain">        plt.figure(figsize=(12,4)) # 图片大小</span></div><div class="token-line"><span class="token plain">        plt.subplot(1, 2, 1) #子图1</span></div><div class="token-line"><span class="token plain">        plt.plot(epochs, loss, &#x27;bo&#x27;, label=&#x27;Training loss&#x27;) #训练损失</span></div><div class="token-line"><span class="token plain">        plt.plot(epochs, val_loss, &#x27;b&#x27;, label=&#x27;Validation loss&#x27;) #验证损失</span></div><div class="token-line"><span class="token plain">        plt.title(&#x27;Training and validation loss&#x27;) #图题</span></div><div class="token-line"><span class="token plain">        plt.xlabel(&#x27;Epochs&#x27;) #X轴文字</span></div><div class="token-line"><span class="token plain">        plt.ylabel(&#x27;Loss&#x27;) #Y轴文字</span></div><div class="token-line"><span class="token plain">        plt.legend() #图例</span></div><div class="token-line"><span class="token plain">        acc = history.history[&#x27;acc&#x27;] #训练准确率</span></div><div class="token-line"><span class="token plain">        val_acc = history.history[&#x27;val_acc&#x27;] #验证准确率</span></div><div class="token-line"><span class="token plain">        plt.subplot(1, 2, 2) #子图2</span></div><div class="token-line"><span class="token plain">        plt.plot(epochs, acc, &#x27;bo&#x27;, label=&#x27;Training acc&#x27;) #训练准确率</span></div><div class="token-line"><span class="token plain">        plt.plot(epochs, val_acc, &#x27;b&#x27;, label=&#x27;Validation acc&#x27;) #验证准确率</span></div><div class="token-line"><span class="token plain">        plt.title(&#x27;Training and validation accuracy&#x27;) #图题</span></div><div class="token-line"><span class="token plain">        plt.xlabel(&#x27;Epochs&#x27;) #X轴文字</span></div><div class="token-line"><span class="token plain">        plt.ylabel(&#x27;Accuracy&#x27;) #Y轴文字</span></div><div class="token-line"><span class="token plain">        plt.legend() #图例</span></div><div class="token-line"><span class="token plain">        plt.show() #绘图</span></div><div class="token-line"><span class="token plain">    show_history(history) # 调用这个函数</span></div></pre></div><p>损失曲线输出如下：</p><p><img src="/blog-other/static/httpsstatic001geekbangorgresourceimage220322c6de1353412c227c124c6ec999e003.da035d29.png" alt=""/></p><p>可以看到，训练集的损失呈现下降趋势，但是测试集上的损失则呈现跳跃，这说明这个神经网络性能不是很稳定，似乎有过拟合的现象。我们将在后面的讲解中探讨如何优化神经网络，让神经网络的损失值更低，准确率更高。</p><p>最后，我们用这个训练好了的模型，在测试集上进行分类结果的评分。</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">result = cnn.evaluate(X_test, y_test) #评估测试集上的准确率</span></div><div class="token-line"><span class="token plain">    print(&#x27;CNN的测试准确率为&#x27;,&quot;{0:.2f}%&quot;.format(result[1]))</span></div></pre></div><p>输入如下：</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">653/653 [==============================] - 10s 15ms/step</span></div><div class="token-line"><span class="token plain">    CNN的测试准确率为 0.69%</span></div></pre></div><p>输出显示，在653张测试集的图片中测试，模型的分类准确率达到了0.69以上。</p><p>最后呢，我们可以应用模型的predict属性把X特征集传入，进行花朵图片的分类。</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">prediction = cnn.predict(X_test) #预测测试集的图片分类</span></div></pre></div><p>下面的代码我们输出第一个图片（Python是从0开始索引的，所以下标0就是第一张图片）的分类预测值：</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">prediction[0] #第一张图片的分类</span></div></pre></div><p>输出如下：</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">array([0.0030566 , 0.13018326, 0.00846946, 0.8582906 ], dtype=float32)</span></div></pre></div><p>这里请你注意，此时输出的是分类概率。上面的输出结果表示，第一类花Daisy（雏菊）的概率为0.03，第二类花Rose（玫瑰）的概率为0.13，第三类花Sunflower（向日葵）的概率为0.008，第四类花Tulip（郁金香）的概率为0.858。</p><p>下面的代码中，我们选出最大的那个概率，并把它当作CNN的分类结果：</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">print(&#x27;第一张测试图片的分类结果为:&#x27;, np.argmax(prediction[0]))</span></div></pre></div><p>输出如下：</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">第一张测试图片的分类结果为: 3</span></div></pre></div><p>结果显示第一个图片被CNN网络模型分类为第4种花（索引从0开始，所以类别3就是第4种花），也就是Tulip（郁金香）。</p><p>好啦，这个神经网络完成了很好的分类功能，准确率达到69%！这比我可强多了，反正我是区分不出来这些花的种类的。那么，神经网络的超参数我们还不知道是怎么一会事，也不知道如何继续优化。不必担心，今天只是讲了个基础。关于性能的超参数的具体用户和性能调优，我们会找一个时间单独讲解的。</p><h2 id="总结一下"><a aria-hidden="true" tabindex="-1" href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/07#总结一下"><span class="icon icon-link"></span></a>总结一下</h2><p>怎么样，构建强大的深度学习神经网络，并没有你想象得那么难吧？</p><p>在这一讲中，我带你去了一个非常好用的网站Kaggle，根据这个网站中的花朵图片数据集创建了Jupyter Notebook，下面几节课中，我们都需要利用Kaggle网站中的GPU等资源来加速网络模型的拟合速度。</p><p>我们这节课的重点在于了解卷积神经网络的结构以及它的搭建方法，它由输入层、一个或多个卷积层和全连接输出层组成。要构建出能够实现图像分类的CNN，我们通常需要把“卷积+池化”的组合重复搭建几次，形成深度卷积网络。在这个过程中，图片特征的尺寸通常会逐渐减小，而深度将逐渐加深。然后我们把它展平，之后通常接一个普通的全连接层，再接一个分类输出层。</p><p>这个过程特别像搭积木，全都是通过Keras的add API，添加layers中所提供的各种类型的层来完成的。如果你希望搭建更深层的神经网络，只要加入更多的卷积层，或者加入更多的全连接层就可以，这个过程并无一定之规，你可以随意尝试。</p><p>当然如果你的层与层之间组合有误，或者输入层所指定接收的张量格式和X特征集的形状不匹配，编译的时候就会报错。这也没什么大不了的，就像我们拿起了两个接口不一样乐高玩具，当然无法拼合在一起。你只要根据错误信息，按图索骥，找到合适的组合方案就可以了。</p><h2 id="思考题"><a aria-hidden="true" tabindex="-1" href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/07#思考题"><span class="icon icon-link"></span></a>思考题</h2><p>这节课到这里就讲完了，我来给你留一道练习题：</p><p>今天我们搭建出了一种形状的神经网络，我刚才也说了，在搭建网络结构的时候，我们就像个建筑师一样，可以自行组合层的数量和各层的样式。那么，现在请你改变一下网络的结构，自己搭建新的网络，比较一下性能。</p><p>提示：你可以在我们今天学的CNN网络的基础上：</p><ol><li><p>增加更多的卷积层、池化层组合；</p></li><li><p>增加或减少中间卷积层滤波器的个数（如64，128，256，512…）；</p></li><li><p>调整中间层中卷积和池化窗口的高度和宽度（如(5, 5)、(7, 7)…）</p><p>cnn.add(layers.Conv2D(256, (5, 5), activation=‘relu’)) # 卷积<br/>cnn.add(layers.MaxPooling2D((3, 3))) # 最大池化</p></li></ol><p>欢迎你积极留言提交属于你自己的神经网络模型的评估分数，看看谁的模型更棒！我们下一讲见！</p><p><img src="/blog-other/static/httpsstatic001geekbangorgresourceimageby12byyd94ec14a79486bdf3631e6a47d712.fd1cd453.jpg" alt=""/></p></div><div class="__dumi-default-layout-footer-meta"><a target="_blank" rel="noopener noreferrer" href="https://github.com/GGwujun/blog/edit/master/ssrc/零基础实战机器学习/03.业务场景闯关篇/07.md">在 GitHub 上编辑此页<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="__dumi-default-external-link-icon"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a><span data-updated-text="最后更新时间：">2023/9/23 21:58:31</span></div></div></div></div>
	<script>
  window.g_useSSR = true;
  window.g_initialProps = {};
	</script>

    <script>
      (function () {
        if (!location.port) {
          (function (i, s, o, g, r, a, m) {
            i["GoogleAnalyticsObject"] = r;
            (i[r] =
              i[r] ||
              function () {
                (i[r].q = i[r].q || []).push(arguments);
              }),
              (i[r].l = 1 * new Date());
            (a = s.createElement(o)), (m = s.getElementsByTagName(o)[0]);
            a.async = 1;
            a.src = g;
            m.parentNode.insertBefore(a, m);
          })(
            window,
            document,
            "script",
            "//www.google-analytics.com/analytics.js",
            "ga"
          );
          ga("create", "UA-149864185-1", "auto");
          ga("send", "pageview");
        }
      })();
    </script>
    <script src="/blog-other/umi.js"></script>
  </body>
</html>
