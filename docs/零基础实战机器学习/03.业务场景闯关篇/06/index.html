<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta
      name="viewport"
      content="width=device-width, initial-scale=1, maximum-scale=1, minimum-scale=1, user-scalable=no"
    />
    <link rel="shortcut icon" type="image/x-icon" href="/logo.png" />
    <link rel="stylesheet" href="/blog-other/umi.css" />
    <script>
      window.routerBase = "/blog-other";
    </script>
    <script>
      //! umi version: 3.5.41
    </script>
    <script>
      !(function () {
        var e =
            navigator.cookieEnabled && void 0 !== window.localStorage
              ? localStorage.getItem("dumi:prefers-color")
              : "auto",
          o = window.matchMedia("(prefers-color-scheme: dark)").matches,
          t = ["light", "dark", "auto"];
        document.documentElement.setAttribute(
          "data-prefers-color",
          e === t[2] ? (o ? t[1] : t[0]) : t.indexOf(e) > -1 ? e : t[0]
        );
      })();
    </script>
    <title>10｜模型优化（下）：交叉验证，同时寻找最优的参数 - 大师兄</title>
  </head>
  <body>
    <div id="root"><div class="__dumi-default-layout" data-route="/零基础实战机器学习/03.业务场景闯关篇/06" data-show-sidemenu="true" data-show-slugs="true" data-site-mode="true" data-gapless="false"><div class="__dumi-default-navbar" data-mode="site"><button class="__dumi-default-navbar-toggle"></button><a class="__dumi-default-navbar-logo" style="background-image:url(&#x27;/logo.png&#x27;)" href="/blog-other/">大师兄</a><nav><div class="__dumi-default-search"><input type="search" class="__dumi-default-search-input" value=""/><ul></ul></div><span>前端开发<ul><li><a href="/blog-other/说透低代码">说透低代码</a></li><li><a href="/blog-other/反爬虫兵法演绎20讲">反爬虫兵法演绎20讲</a></li></ul></span><span>产品与用户体验<ul><li><a href="/blog-other/大厂广告产品心法">大厂广告产品心法</a></li></ul></span><span>面试<ul><li><a href="/blog-other/技术面试官识人手册">技术面试官识人手册</a></li><li><a href="/blog-other/面试现场">面试现场</a></li></ul></span><span>杂谈<ul><li><a href="/blog-other/乔新亮的cto成长复盘">乔新亮的cto成长复盘</a></li><li><a href="/blog-other/互联网人的英语私教课">互联网人的英语私教课</a></li><li><a href="/blog-other/从0开始学游戏开发">从0开始学游戏开发</a></li><li><a href="/blog-other/全栈工程师修炼指南">全栈工程师修炼指南</a></li><li><a href="/blog-other/手机摄影">手机摄影</a></li><li><a href="/blog-other/物联网开发实战">物联网开发实战</a></li><li><a href="/blog-other/白话法律42讲">白话法律42讲</a></li><li><a href="/blog-other/说透5g">说透5g</a></li><li><a href="/blog-other/超级访谈对话张雪峰">超级访谈对话张雪峰</a></li><li><a aria-current="page" class="active" href="/blog-other/零基础实战机器学习">零基础实战机器学习</a></li></ul></span><div class="__dumi-default-navbar-tool"><div class="__dumi-default-dark"><div class="__dumi-default-dark-switch "></div></div></div></nav></div><div class="__dumi-default-menu" data-mode="site"><div class="__dumi-default-menu-inner"><div class="__dumi-default-menu-header"><a class="__dumi-default-menu-logo" style="background-image:url(&#x27;/logo.png&#x27;)" href="/blog-other/"></a><h1>大师兄</h1><p></p></div><div class="__dumi-default-menu-mobile-area"><ul class="__dumi-default-menu-nav-list"><li>前端开发<ul><li><a href="/blog-other/说透低代码">说透低代码</a></li><li><a href="/blog-other/反爬虫兵法演绎20讲">反爬虫兵法演绎20讲</a></li></ul></li><li>产品与用户体验<ul><li><a href="/blog-other/大厂广告产品心法">大厂广告产品心法</a></li></ul></li><li>面试<ul><li><a href="/blog-other/技术面试官识人手册">技术面试官识人手册</a></li><li><a href="/blog-other/面试现场">面试现场</a></li></ul></li><li>杂谈<ul><li><a href="/blog-other/乔新亮的cto成长复盘">乔新亮的cto成长复盘</a></li><li><a href="/blog-other/互联网人的英语私教课">互联网人的英语私教课</a></li><li><a href="/blog-other/从0开始学游戏开发">从0开始学游戏开发</a></li><li><a href="/blog-other/全栈工程师修炼指南">全栈工程师修炼指南</a></li><li><a href="/blog-other/手机摄影">手机摄影</a></li><li><a href="/blog-other/物联网开发实战">物联网开发实战</a></li><li><a href="/blog-other/白话法律42讲">白话法律42讲</a></li><li><a href="/blog-other/说透5g">说透5g</a></li><li><a href="/blog-other/超级访谈对话张雪峰">超级访谈对话张雪峰</a></li><li><a aria-current="page" class="active" href="/blog-other/零基础实战机器学习">零基础实战机器学习</a></li></ul></li></ul><div class="__dumi-default-dark"><div class="__dumi-default-dark-switch "><button title="Dark theme" class="__dumi-default-dark-moon "><svg viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="3854" width="22" height="22"><path d="M991.816611 674.909091a69.166545 69.166545 0 0 0-51.665455-23.272727 70.795636 70.795636 0 0 0-27.438545 5.585454A415.674182 415.674182 0 0 1 754.993338 698.181818c-209.594182 0-393.472-184.785455-393.472-395.636363 0-52.363636 38.539636-119.621818 69.515637-173.614546 4.887273-8.610909 9.634909-16.756364 14.103272-24.901818A69.818182 69.818182 0 0 0 384.631156 0a70.842182 70.842182 0 0 0-27.438545 5.585455C161.678429 90.298182 14.362065 307.898182 14.362065 512c0 282.298182 238.824727 512 532.38691 512a522.286545 522.286545 0 0 0 453.957818-268.334545A69.818182 69.818182 0 0 0 991.816611 674.909091zM546.679156 954.181818c-248.785455 0-462.941091-192-462.941091-442.181818 0-186.647273 140.637091-372.829091 300.939637-442.181818-36.817455 65.629091-92.578909 151.970909-92.578909 232.727273 0 250.181818 214.109091 465.454545 462.917818 465.454545a488.331636 488.331636 0 0 0 185.181091-46.545455 453.003636 453.003636 0 0 1-393.565091 232.727273z m103.656728-669.323636l-14.266182 83.781818a34.909091 34.909091 0 0 0 50.362182 36.770909l74.775272-39.563636 74.752 39.563636a36.142545 36.142545 0 0 0 16.174546 3.956364 34.909091 34.909091 0 0 0 34.210909-40.727273l-14.289455-83.781818 60.509091-59.345455a35.025455 35.025455 0 0 0-19.223272-59.578182l-83.61891-12.101818-37.376-76.101818a34.56 34.56 0 0 0-62.254545 0l-37.376 76.101818-83.618909 12.101818a34.909091 34.909091 0 0 0-19.246546 59.578182z m70.423272-64.698182a34.280727 34.280727 0 0 0 26.135273-19.083636l14.312727-29.090909 14.336 29.090909a34.257455 34.257455 0 0 0 26.135273 19.083636l32.046546 4.887273-23.272728 22.574545a35.234909 35.234909 0 0 0-10.007272 30.952727l5.46909 32.116364-28.625454-15.127273a34.490182 34.490182 0 0 0-32.302546 0l-28.695272 15.127273 5.469091-32.116364a35.141818 35.141818 0 0 0-9.984-30.952727l-23.272728-22.574545z" p-id="3855"></path></svg></button><button title="Light theme" class="__dumi-default-dark-sun "><svg viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="4026" width="22" height="22"><path d="M915.2 476.16h-43.968c-24.704 0-44.736 16-44.736 35.84s20.032 35.904 44.736 35.904H915.2c24.768 0 44.8-16.064 44.8-35.904s-20.032-35.84-44.8-35.84zM512 265.6c-136.704 0-246.464 109.824-246.464 246.4 0 136.704 109.76 246.464 246.464 246.464S758.4 648.704 758.4 512c0-136.576-109.696-246.4-246.4-246.4z m0 425.6c-99.008 0-179.2-80.128-179.2-179.2 0-98.944 80.192-179.2 179.2-179.2S691.2 413.056 691.2 512c0 99.072-80.192 179.2-179.2 179.2zM197.44 512c0-19.84-19.136-35.84-43.904-35.84H108.8c-24.768 0-44.8 16-44.8 35.84s20.032 35.904 44.8 35.904h44.736c24.768 0 43.904-16.064 43.904-35.904zM512 198.464c19.776 0 35.84-20.032 35.84-44.8v-44.8C547.84 84.032 531.84 64 512 64s-35.904 20.032-35.904 44.8v44.8c0 24.768 16.128 44.864 35.904 44.864z m0 627.136c-19.776 0-35.904 20.032-35.904 44.8v44.736C476.096 940.032 492.16 960 512 960s35.84-20.032 35.84-44.8v-44.736c0-24.768-16.064-44.864-35.84-44.864z m329.92-592.832c17.472-17.536 20.288-43.072 6.4-57.024-14.016-14.016-39.488-11.2-57.024 6.336-4.736 4.864-26.496 26.496-31.36 31.36-17.472 17.472-20.288 43.008-6.336 57.024 13.952 14.016 39.488 11.2 57.024-6.336 4.8-4.864 26.496-26.56 31.296-31.36zM213.376 759.936c-4.864 4.8-26.56 26.624-31.36 31.36-17.472 17.472-20.288 42.944-6.4 56.96 14.016 13.952 39.552 11.2 57.024-6.336 4.8-4.736 26.56-26.496 31.36-31.36 17.472-17.472 20.288-43.008 6.336-56.96-14.016-13.952-39.552-11.072-56.96 6.336z m19.328-577.92c-17.536-17.536-43.008-20.352-57.024-6.336-14.08 14.016-11.136 39.488 6.336 57.024 4.864 4.864 26.496 26.56 31.36 31.424 17.536 17.408 43.008 20.288 56.96 6.336 14.016-14.016 11.264-39.488-6.336-57.024-4.736-4.864-26.496-26.56-31.296-31.424z m527.168 628.608c4.864 4.864 26.624 26.624 31.36 31.424 17.536 17.408 43.072 20.224 57.088 6.336 13.952-14.016 11.072-39.552-6.4-57.024-4.864-4.8-26.56-26.496-31.36-31.36-17.472-17.408-43.072-20.288-57.024-6.336-13.952 14.016-11.008 39.488 6.336 56.96z" p-id="4027"></path></svg></button><button title="Default to system" class="__dumi-default-dark-auto "><svg viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="11002" width="22" height="22"><path d="M127.658667 492.885333c0-51.882667 10.24-101.717333 30.378666-149.162666s47.786667-88.064 81.92-122.538667 75.093333-61.781333 122.538667-81.92 96.938667-30.378667 149.162667-30.378667 101.717333 10.24 149.162666 30.378667 88.405333 47.786667 122.88 81.92 61.781333 75.093333 81.92 122.538667 30.378667 96.938667 30.378667 149.162666-10.24 101.717333-30.378667 149.162667-47.786667 88.405333-81.92 122.88-75.093333 61.781333-122.88 81.92-97.28 30.378667-149.162666 30.378667-101.717333-10.24-149.162667-30.378667-88.064-47.786667-122.538667-81.92-61.781333-75.093333-81.92-122.88-30.378667-96.938667-30.378666-149.162667z m329.045333 0c0 130.048 13.994667 244.394667 41.984 343.381334h12.970667c46.762667 0 91.136-9.216 133.461333-27.306667s78.848-42.666667 109.568-73.386667 54.954667-67.242667 73.386667-109.568 27.306667-86.698667 27.306666-133.461333c0-46.421333-9.216-90.794667-27.306666-133.12s-42.666667-78.848-73.386667-109.568-67.242667-54.954667-109.568-73.386667-86.698667-27.306667-133.461333-27.306666h-11.605334c-28.672 123.562667-43.349333 237.909333-43.349333 343.722666z" p-id="11003"></path></svg></button></div></div></div><ul class="__dumi-default-menu-list"><li><a href="/blog-other/零基础实战机器学习">零基础实战机器学习</a></li><li><a href="/blog-other/零基础实战机器学习/01.开篇词">01.开篇词</a><ul><li><a href="/blog-other/零基础实战机器学习/01.开篇词/01"><span>开篇词｜开发者为什么要从实战出发学机器学习？</span></a></li></ul></li><li><a href="/blog-other/零基础实战机器学习/02.准备篇">02.准备篇</a><ul><li><a href="/blog-other/零基础实战机器学习/02.准备篇/01"><span>01｜打好基础：到底什么是机器学习？</span></a></li><li><a href="/blog-other/零基础实战机器学习/02.准备篇/02"><span>02｜工具准备：安装并使用Jupyter Notebook</span></a></li><li><a href="/blog-other/零基础实战机器学习/02.准备篇/03"><span>03｜实战5步（上）：怎么定义问题和预处理数据？</span></a></li><li><a href="/blog-other/零基础实战机器学习/02.准备篇/04"><span>04｜ 实战5步（下）：怎么建立估计10万+软文点击率的模型？</span></a></li></ul></li><li><a aria-current="page" class="active" href="/blog-other/零基础实战机器学习/03.业务场景闯关篇">03.业务场景闯关篇</a><ul><li><a href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/01"><span>05 | 数据探索：怎样从数据中找到用户的RFM值？</span></a></li><li><a href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/02"><span>06 | 聚类分析：如何用RFM给电商用户做价值分组画像？</span></a></li><li><a href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/03"><span>07｜回归分析：怎样用模型预测用户的生命周期价值？</span></a></li><li><a href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/04"><span>08 | 模型优化（上）：怎么用特征工程提高模型效率？</span></a></li><li><a href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/05"><span>09｜模型优化（中）：防止过拟合，模型也不能太精细</span></a></li><li><a aria-current="page" class="active" href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/06"><span>10｜模型优化（下）：交叉验证，同时寻找最优的参数</span></a></li><li><a href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/07"><span>11｜深度学习（上）：用CNN带你认识深度学习</span></a></li><li><a href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/08"><span>12｜深度学习（中）：如何用RNN预测激活率走势？</span></a></li><li><a href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/09"><span>13｜深度学习（下）：3招提升神经网络预测准确率</span></a></li><li><a href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/10"><span>14｜留存分析：哪些因素会影响用户的留存率？</span></a></li><li><a href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/11"><span>15｜二元分类：怎么预测用户是否流失？从逻辑回归到深度学习</span></a></li><li><a href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/12"><span>16｜性能评估：不平衡数据集应该使用何种评估指标？</span></a></li><li><a href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/13"><span>17｜集成学习：机器学习模型如何“博采众长”?</span></a></li><li><a href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/14"><span>18 | 增长模型：用XGBoost评估裂变海报的最佳受众群体</span></a></li></ul></li><li><a href="/blog-other/零基础实战机器学习/04.持续赋能篇">04.持续赋能篇</a><ul><li><a href="/blog-other/零基础实战机器学习/04.持续赋能篇/01"><span>19 | 胸有成竹：如何快速定位合适的机器学习算法？</span></a></li><li><a href="/blog-other/零基础实战机器学习/04.持续赋能篇/02"><span>20 | 模型部署：怎么发布训练好的机器学习模型？</span></a></li><li><a href="/blog-other/零基础实战机器学习/04.持续赋能篇/03"><span>21｜持续精进：如何在机器学习领域中找准前进的方向？</span></a></li></ul></li><li><a href="/blog-other/零基础实战机器学习/05.结束语">05.结束语</a><ul><li><a href="/blog-other/零基础实战机器学习/05.结束语/01"><span>一套习题，测出你对机器学习的掌握程度</span></a></li><li><a href="/blog-other/零基础实战机器学习/05.结束语/02"><span>结束语 | 可以不完美，但重要的是马上开始</span></a></li></ul></li><li><a href="/blog-other/零基础实战机器学习/summary">零基础实战机器学习</a></li></ul></div></div><ul role="slug-list" class="__dumi-default-layout-toc"><li title="交叉验证：小数据集的资源复用" data-depth="2"><a href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/06#交叉验证小数据集的资源复用"><span>交叉验证：小数据集的资源复用</span></a></li><li title="网格搜索：直到找到最优的参数" data-depth="2"><a href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/06#网格搜索直到找到最优的参数"><span>网格搜索：直到找到最优的参数</span></a></li><li title="总结一下" data-depth="2"><a href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/06#总结一下"><span>总结一下</span></a></li><li title="思考题" data-depth="2"><a href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/06#思考题"><span>思考题</span></a></li></ul><div class="__dumi-default-layout-content"><div class="markdown"><h1 id="10模型优化下交叉验证同时寻找最优的参数"><a aria-hidden="true" tabindex="-1" href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/06#10模型优化下交叉验证同时寻找最优的参数"><span class="icon icon-link"></span></a>10｜模型优化（下）：交叉验证，同时寻找最优的参数</h1><p>你好，我是黄佳。</p><p>欢迎来到零基础实战机器学习。在前面几节课中，我们已经学习了两种优化机器学习模型的方法，一种是做各种特征工程，让特征集更适合模型；另一种是防止过拟合，让模型不用“那么”精确。</p><p>这两种方式的优化角度不同，特征工程是从数据预处理的角度，给出更高质量的数据，而防止过拟合则是在模型训练的过程中，控制模型的复杂度。其实，除此之外，我们还可以从模型的验证和评估环节入手，来优化模型性能。</p><h2 id="交叉验证小数据集的资源复用"><a aria-hidden="true" tabindex="-1" href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/06#交叉验证小数据集的资源复用"><span class="icon icon-link"></span></a>交叉验证：小数据集的资源复用</h2><p>你知道，在样本充足的情况下，我们会随机将数据分为3个部分：训练集、验证集和测试集。其中，训练集用来训练模型，验证集用来模型调优，测试集用来评估模型性能。</p><p>不过，你还记不记得我们在<a target="_blank" rel="noopener noreferrer" href="https://time.geekbang.org/column/article/413057">第1讲<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="__dumi-default-external-link-icon"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>中介绍监督学习的时候，我说过有标签的数据是非常难以获得的。本来就很有限的数据集还要被拆成训练集、测试集和验证集，真是让人特别舍不得。</p><p>而且，我们知道数据集越大，就越不容易出现过拟合的现象。那么，我们如何利用较小的数据集，从而达到较大数据集的效果呢？这就需要交叉验证。</p><p>交叉验证的基本思想是这样的：将训练数据集分为k等份，其中k-1份用作训练集，单独的那一份用作验证集，整个过程重复k次，这也通常称作k折。这样就最大程度重复地使用了训练集中的数据，每一个数据都既做了训练，又做了测试，从而在最大程度上提高模型性能的可信度。</p><p>这种交叉验证具体实现起来有4个步骤：</p><ol><li><p>随机清洗数据集，将数据集分为训练集和测试集，将测试集预留出来，放在一边。</p></li><li><p>将训练数据集分成k组（这个k值一般是随机设定，比如3，5，10，实操中以10折居多）。在这一步中，我们挑其中1组作为验证集，剩下的k-1组做训练集（这个过程要重复k次）。我们在这些训练集上拟合模型，可以得到k个不同的模型。然后再在对应的验证集上对这些模型进行评估，就能得到一系列模型的评估分数。最后，我们把这些评估分数进行平均，这个平均分数就是交叉验证的最终结果了。</p></li><li><p>按照步骤1、2，对多个算法进行交叉验证，比如可以针对线性回归、决策树、随机森林等算法。根据每个算法交叉验证的评估结果，从中挑选效果最好的算法模型。</p></li><li><p>使用测试集评估最终模型的分数。</p></li></ol><p>现在，你应该很清楚了：每个数据样本都有1次机会进入验证集中，并用于训练模型k-1次。这样一来，我们就拥有了更多的数据量。整个过程如下所示：</p><p><img src="/blog-other/static/httpsstatic001geekbangorgresourceimage1f271f97a858d3b5f4976a481b0e44210127.415974d2.png" alt="" title="K折交叉验证示意图\n"/></p><p>在交叉验证中，训练集和验证集的拆分可以通过sklearn.model_selection中的KFold函数实现。在这个函数中，有三个主要参数需要我们了解一下：</p><p><img src="/blog-other/static/httpsstatic001geekbangorgresourceimage062406cc789267e472b55125e52143b26f24.238d4617.jpg" alt=""/></p><p>下面，我们来看看交叉验证的实际用法。这里我们仍然借用<a target="_blank" rel="noopener noreferrer" href="https://time.geekbang.org/column/article/417479">第7讲<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="__dumi-default-external-link-icon"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>中预测用户LTV的线性回归模型model_lr，我们先用KFold.split对数据集进行拆分，然后对每一折循环，训练出不同的模型，最后给出一个验证分数。完整的代码你可以从<a target="_blank" rel="noopener noreferrer" href="https://github.com/huangjia2019/geektime/tree/main/%E5%8F%98%E7%8E%B0%E5%85%B310">这里<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="__dumi-default-external-link-icon"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>下载。</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">from sklearn.model_selection import KFold #导入K折工具</span></div><div class="token-line"><span class="token plain">    from sklearn.metrics import r2_score #导入R2分数评估工具</span></div><div class="token-line"><span class="token plain">    kf5 = KFold(n_splits=5, shuffle=False) #5折验证</span></div><div class="token-line"><span class="token plain">    i = 1 </span></div><div class="token-line"><span class="token plain">    for train_index, test_index in kf5.split(df_LTV): </span></div><div class="token-line"><span class="token plain">        X_train = df_LTV.iloc[train_index].drop([&#x27;年度LTV&#x27;],axis=1) #训练集X</span></div><div class="token-line"><span class="token plain">        X_test = df_LTV.iloc[test_index].drop([&#x27;年度LTV&#x27;],axis=1) #验证集X</span></div><div class="token-line"><span class="token plain">        y_train = df_LTV.iloc[train_index][&#x27;年度LTV&#x27;] #训练集y</span></div><div class="token-line"><span class="token plain">        y_test = df_LTV.loc[test_index][&#x27;年度LTV&#x27;] #验证集y </span></div><div class="token-line"><span class="token plain">        model_lr.fit(X_train, y_train) #训练模型</span></div><div class="token-line"><span class="token plain">        print(f&quot;第{i}折验证集R2分数：{r2_score(y_test, model_lr.predict(X_test))}&quot;) </span></div><div class="token-line"><span class="token plain">        i += 1</span></div></pre></div><p>输出如下：</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">第1折验证集R2分数：0.5143622747243847</span></div><div class="token-line"><span class="token plain">    第2折验证集R2分数：-0.16778272779470416</span></div><div class="token-line"><span class="token plain">    第3折验证集R2分数：0.23879516275929713</span></div><div class="token-line"><span class="token plain">    第4折验证集R2分数：0.2482389409435588</span></div><div class="token-line"><span class="token plain">    第5折验证集R2分数：0.03088299924007265</span></div></pre></div><p>在实际实战中，sklearn还提供了更简单的方式，我们不用进行上面的KFold拆分过程，只用一个cross_val_score函数就能直接完成模型的K折拆分、训练和验证，一次性得到交叉验证结果。</p><p>接下来，我们再用这种方式来评估一下刚才的线性回归模型model_lr：</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">from sklearn.model_selection import cross_val_score # 导入交叉验证工具</span></div><div class="token-line"><span class="token plain">    # from sklearn.metrics import mean_squared_error #平均绝对误差</span></div><div class="token-line"><span class="token plain">    model_lr = LinearRegression() #线性回归模型</span></div><div class="token-line"><span class="token plain">    scores = cross_val_score(model_lr, #线性回归</span></div><div class="token-line"><span class="token plain">                      X_train, #特征集</span></div><div class="token-line"><span class="token plain">                      y_train, #标签集</span></div><div class="token-line"><span class="token plain">                      cv=5, # 五折验证</span></div><div class="token-line"><span class="token plain">                      scoring = &#x27;neg_mean_absolute_error&#x27;) #平均绝对误差</span></div><div class="token-line"><span class="token plain">    for i, score in enumerate(scores):</span></div><div class="token-line"><span class="token plain">        print(f&quot;第{i+1}折验证集平均绝对误差： {-score}&quot;)</span></div></pre></div><p>这里我们把线性回归模型作为参数传入cross_val_score函数中，同时采用5折验证，计算出每一次验证的平均绝对误差，也就是预测值和真值之间的平均差异，误差绝对值越大，效果越不好。</p><p>输出的每一折平均绝对误差值如下：</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">第1折验证集平均绝对误差：3191.99882739</span></div><div class="token-line"><span class="token plain">    第2折验证集平均绝对误差：1402.45679102</span></div><div class="token-line"><span class="token plain">    第3折验证集平均绝对误差：1168.49187113</span></div><div class="token-line"><span class="token plain">    第4折验证集平均绝对误差：1546.15537555</span></div><div class="token-line"><span class="token plain">    第5折验证集平均绝对误差：1138.41271054</span></div></pre></div><p>看的出来，采用不同的训练集和验证集组合，得到的模型分数不同。最后，我们再把这5折的验证结果进行平均，得到5折交叉验证的平均分数。这个分数，将比仅拆分一次训练集/验证集得到的评估结果更为稳定。</p><p>我这里要强调的是，交叉验证虽然一直在用不同的数据拆分进行模型的拟合，但它实际上并不是在试图训练出新的模型，它只是我们对模型的一种评估方式而已。</p><p>好了，关于交叉验证，我们就说到这里，下面我讲一个对你来说非常实用的问题：如何调参。</p><h2 id="网格搜索直到找到最优的参数"><a aria-hidden="true" tabindex="-1" href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/06#网格搜索直到找到最优的参数"><span class="icon icon-link"></span></a>网格搜索：直到找到最优的参数</h2><p>一个复杂的机器学习模型，有可能有一大堆超参数，模型的性能很大程度上取决于超参数的值。什么超参数是最好的？那可不一定，因为针对不同的问题而言，最佳的参数一直在变化，而且基本上没有太多规律可循。那些机器学习老手很可能会告诉你：调参可是要靠感觉、靠直觉的，你调的多了，感觉也就出来了。</p><p>这样的答案会让咱们这种新手十分头疼，没有什么经验怎么针对当前机器学习任务和当前数据集找到最好的参数？难道要手工的一个一个尝试吗？我们之前学过的线性回归模型，只有两个主要超参数，而且是布尔型变量，组合起来是4种情况，这还可以调一调。但是像随机森林这种比较复杂的模型，参数非常多，怎么可能一个个去试呢？</p><p>你不用担心， <strong>scikit-learn中有一个GridSearchCV工具，中文叫做网格搜索，堪称是辅助我们自动调参的神器</strong>，它可以帮我们自动调参，轻松找到模型的最优参数。</p><p>那么，怎么用这个网格搜索呢？我们需要做的有这几步：</p><ul><li>第一步，明确你选择的模型有哪些可调的参数，这个你可以通过查看算法的说明文档来确定；</li><li>第二步，把模型中各超参数不同取值的排列组合尽可能多地列出来；</li><li>第三步，调用GridSearchCV工具，把可能的排列组合都传进去。</li></ul><p>完成这三步后，GridSearchCV会在后台创建出一大堆的并行进程，挨个执行各种超参数的组合，同时还会使用交叉验证的方法（名称中的CV，意思就是cross validation），来评估每个超参数组合的模型。最后，GridSearchCV会帮你选定哪个组合是给定模型的最佳超参数值。</p><p>好，下面我们就基于<a target="_blank" rel="noopener noreferrer" href="https://time.geekbang.org/column/article/417479">第7讲<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="__dumi-default-external-link-icon"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>中的LTV预测项目，看看怎么用GridSearchCV选出随机森林模型比较好的参数组合（在之前的实战中，模型的参数都选择的是默认值）。</p><p>在调用GridSearchCV调参之前，我们首先找出随机森林回归模型中有哪些参数，最好的方法还是去<a target="_blank" rel="noopener noreferrer" href="https://scikit-learn.org/stable/">sklearn官网<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="__dumi-default-external-link-icon"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>查看。我们在这儿拿出一些重要的超参数来调一下：</p><p><img src="/blog-other/static/httpsstatic001geekbangorgresourceimage68fa687c464e312272c66397ea795fa91efa.30eb142f.jpg" alt=""/></p><p>我们知道，随机森林是由多棵决策树集合而成的算法，所以，这些参数都和各决策树的生成和剪枝过程相关。上面这些参数，我们并不一定要完全理解它们的作用，因为我们的重点不是去详细了解每一个超参数，而是让GridSearchCV自动找到对于我们当前任务合适的超参数组合。</p><p>找出随机森林模型的参数后，接下来，我们需要在程序中定义一个字典对象，列出各个超参数，以及我们希望去尝试的值组合，你可以参考下面的代码。在这段代码中，我定义了rfr_param_grid字典对象，并在字典中指定了一系列参数值的组合，举例来说，对于n_estimators这个参数我就选择了100和300，当然你也可以尝试任意其它的值。</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">model_rfr = RandomForestClassifier() # 随机森林模型</span></div><div class="token-line"><span class="token plain">    # 对随机森林算法进行参数优化</span></div><div class="token-line"><span class="token plain">    rf_param_grid = {&quot;max_depth&quot;: [None],</span></div><div class="token-line"><span class="token plain">                      &quot;max_features&quot;: [3, 5, 12],</span></div><div class="token-line"><span class="token plain">                      &quot;min_samples_split&quot;: [2, 5, 10],</span></div><div class="token-line"><span class="token plain">                      &quot;min_samples_leaf&quot;: [3, 5, 10],</span></div><div class="token-line"><span class="token plain">                      &quot;bootstrap&quot;: [False],</span></div><div class="token-line"><span class="token plain">                      &quot;n_estimators&quot; :[100,300],</span></div><div class="token-line"><span class="token plain">                      &quot;criterion&quot;: [&quot;gini&quot;]}</span></div></pre></div><p>然后，在要调用GridSearchCV 来进行超参数搜索之前，我们先看看GridSearchCV这个函数本身有什么需要设定的参数。</p><p><img src="/blog-other/static/httpsstatic001geekbangorgresourceimagee153e1c2dc9127e70f050e3e2014d3b41853.f8279f67.jpg" alt=""/></p><p>下面我们来调用GridSearchCV这个函数：</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">from sklearn.model_selection import GridSearchCV # 导入网格搜索工具</span></div><div class="token-line"><span class="token plain">    model_rfr_gs = GridSearchCV(model_rfr,</span></div><div class="token-line"><span class="token plain">                                param_grid = rfr_param_grid, cv=3,</span></div><div class="token-line"><span class="token plain">                                scoring=&quot;r2&quot;, n_jobs= 10, verbose = 1)</span></div><div class="token-line"><span class="token plain">    model_rfr_gs.fit(X_train, y_train) # 用优化后的参数拟合训练数据集</span></div></pre></div><p>在上述代码中，我将GridSearchCV返回的最佳参数组合存储在了rfr_gs这个新的随机森林模型。</p><p>然后，系统就会自动计算每种超参数组合拟合出的模型的准确率/损失：</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">Fitting 3 folds for each of 432 candidates, totalling 1296 fits</span></div><div class="token-line"><span class="token plain">    [Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.</span></div><div class="token-line"><span class="token plain">    [Parallel(n_jobs=10)]: Done  30 tasks      | elapsed:   22.0s</span></div><div class="token-line"><span class="token plain">    [Parallel(n_jobs=10)]: Done 180 tasks      | elapsed:  2.0min</span></div><div class="token-line"><span class="token plain">    [Parallel(n_jobs=10)]: Done 430 tasks      | elapsed:  4.8min</span></div><div class="token-line"><span class="token plain">    [Parallel(n_jobs=10)]: Done 780 tasks      | elapsed:  8.7min</span></div><div class="token-line"><span class="token plain">    [Parallel(n_jobs=10)]: Done 1230 tasks      | elapsed: 12.6min</span></div><div class="token-line"><span class="token plain">    [Parallel(n_jobs=10)]: Done 1296 out of 1296 | elapsed: 13.2min finished</span></div></pre></div><p>你要注意的是，随机森林模型可能的超参数组合非常多，因此这个训练过程在我们的电脑上可能会持续很久很久，所以我特意没有设定太多的参数组合，而是选取了其中一部分。不过，这个训练过程也是花了十几分钟才搜索完。</p><p>经过GridSearchCV自动地换参、拟合并自动交叉验证评估后，最佳参数组合实际上已经被选出了，它就被存储在model_rfr_gs这个新的随机森林中，我们可以直接用它来做预测。这里，我们调用model_rfr_gs的best_params_属性，来看一下这个最优模型是由哪些超参数组合而成的：</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">print(&quot; 最佳参数组合:&quot;, model_rfr_gs.best_params_)</span></div></pre></div><p>输出如下：</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">最佳参数组合: {&#x27;bootstrap&#x27;: True, &#x27;max_depth&#x27;: 10, &#x27;max_features&#x27;: &#x27;sqrt&#x27;, &#x27;min_samples_leaf&#x27;: 2, &#x27;min_samples_split&#x27;: 2, &#x27;n_estimators&#x27;: 50}</span></div></pre></div><p>然后，我们看看 GridSearchCV 模型的准确性。</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">from sklearn.metrics import r2_score,   median_absolute_error #导入Sklearn评估模块</span></div><div class="token-line"><span class="token plain">    print(&#x27;训练集上的R平方分数-调参后的随机森林: %0.4f&#x27; % r2_score(y_train, model_rfr_gs.predict(X_train)))</span></div><div class="token-line"><span class="token plain">    print(&#x27;测试集上的R平方分数-调参后的随机森林: %0.4f&#x27; % r2_score(y_valid, model_rfr_gs.predict(X_valid)))</span></div></pre></div><p>输出如下：</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">训练集上的R平方分数-随机森林: 0.7729</span></div><div class="token-line"><span class="token plain">    测试集上的R平方分数-随机森林: 0.6523</span></div></pre></div><p>这个分数需要和以前只调用随机森林模型默认参数的结果进行比较，所以，在这里我对这个模型训练了两次：一次不使用 GridsearchCV（使用默认超参数）；另一次我们使用 GridSearchCV 找到超参数最佳值。下面我们比较一下这两次的分数：</p><p><img src="data:image/png;base64,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" alt=""/></p><p>结果显示，经过网格搜索参数调优之后，虽然训练集上的分数降低了，但是在验证集上面的分数提升了，真棒！</p><p>学到这里，你可能会认为上面这一组参数是随机森林回归模型超参数的最佳值。但事实并非如此，上述超参数对于我们正在处理的数据集可能是最佳选择，但是对其他数据集未必适用。</p><p>到这里，我们就学完了两个优化技巧，再加上我们在前面两讲中学的特征工程和正则化技术，你在机器学习性能调优这块，就有了基本的理论和实践知识。恭喜你正式闯过“变现关”！</p><h2 id="总结一下"><a aria-hidden="true" tabindex="-1" href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/06#总结一下"><span class="icon icon-link"></span></a>总结一下</h2><p>这一讲中，我们学了两个和模型优化相关的方法，分别是交叉验证和网格搜索。</p><p>交叉验证是机器学习训练和验证模型时有效利用数据的方法，它的基本思路就是重复的使用数据，把样本数据进行切分，然后重组为不同的训练集和验证集。 在这个过程中，某次训练集中的某个样本在下次就可能成为验证集中的样本，所以被称作“交叉”。</p><p>网格搜索是帮我们优化模型超参数的技术，它在本质上是一种穷举法。对于每个超参数，我们都会指定一些可能的值。然后，GridSearchCV会组合这些参数值得到若干组超参数，并使用每组超参数来训练模型，最后挑选出验证集上误差最小的超参数，来作为该模型的最优超参数。</p><p>这两个工具使用起来非常简单，你可以通过代码反复演练它们，尝试各种不同的验证折数和模型超参数。</p><p>那截止到这节课，我们实际上已经学习了四个提升机器学习模型效率的法宝，它们都特别重要。在这里我也帮你复习一下：</p><ol><li><strong>特征工程</strong>：目标是提高数据特征与模型的匹配度，我们总结了特征选择、特征变换和特征构建三个思路来帮助你解决具体问题。</li><li><strong>防过拟合</strong>：过拟合就是模型针对训练集，拟合程度过高，失去了在新数据集上泛化的能力。我们的模型要在拟合和泛化之间保持一个平衡。</li><li><strong>交叉验证</strong>：交叉验证可以帮我们利用好有限的数据集。你要注意，我们说的过拟合也有可能不是模型导致的，而可能是因为数据集划分不合理造成的，这在比较小的数据集上尤为明显。所以，交叉验证所得到的多次评估结果，能够避免某一次数据集划分不合理所带来的偏差。</li><li><strong>参数调优</strong>：每一种算法都有属于自己的一系列可调超参数（外部参数），你要尽力找到对于当前数据集而言最好的一套参数。</li></ol><p>在下一讲中，我们将开启激活关，让我们一起期待吧！</p><h2 id="思考题"><a aria-hidden="true" tabindex="-1" href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/06#思考题"><span class="icon icon-link"></span></a>思考题</h2><p>这节课就到这里了，最后，我想给你留三个思考题：</p><ol><li>除了最简单的交叉验证函数cross_val_score之外，sklearn还提供另外一个函数cross_validate，这个函数和cross_val_score的区别有两点：一是它允许指定多个评估指标；二是它返回的信息更丰富，除评估分数之外，它还返回一个包含拟合时间、分数时间、以及可选的训练集分数和拟合模型的字典。请你尝试使用这个函数，并分析它返回的信息。</li></ol><p>提示：</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">scores = cross_validate(lasso, X, y, cv=3,</span></div><div class="token-line"><span class="token plain">                                 scoring=(&#x27;r2&#x27;, &#x27;neg_mean_squared_error&#x27;),</span></div><div class="token-line"><span class="token plain">                                return_train_score=True)</span></div></pre></div><ol start="2"><li>除了普通的KFold方法之外，还有重复K折RepeatedKFold、留一法分折LeaveOneOut、留多法分折LeavePOut等变体，也可以为数据分折，那么。请你尝试用这些方法来拆分数据，做交叉验证。</li></ol><p>提示：</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">from sklearn.model_selection import RepeatedKFold</span></div><div class="token-line"><span class="token plain">    from sklearn.model_selection import LeaveOneOut</span></div><div class="token-line"><span class="token plain">    from sklearn.model_selection import LeavePOut</span></div><div class="token-line"><span class="token plain">    ... </span></div><div class="token-line"><span class="token plain">    &gt;&gt;&gt; loo = LeaveOneOut()</span></div><div class="token-line"><span class="token plain">    &gt;&gt;&gt; for train, test in loo.split(X):</span></div><div class="token-line"><span class="token plain">    ...     print(&quot;%s %s&quot; % (train, test))</span></div></pre></div><ol start="3"><li>除GridSearchCV之外，sklearn还提供了另一个网格搜索API，叫RandomizedSearchCV，中文名是随机搜索。对于完全相同的参数空间，随机搜索运行时间比起网格搜索会大大降低，这是因为它采用的是随机参数组合。不过，随机搜索返回的模型性能可能会稍差，这就是时间和最优性能的一种权衡。请你尝试使用RandomizedSearchCV进行搜索，找到比较好的超参数。</li></ol><p>提示：</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">from sklearn.model_selection import RandomizedSearchCV</span></div><div class="token-line"><span class="token plain">    random_search = RandomizedSearchCV(clf, param_distributions=param_dist,</span></div><div class="token-line"><span class="token plain">                                       n_iter=n_iter_search)</span></div></pre></div><p>欢迎你在留言区分享你的想法和收获，我在留言区等你。如果这节课帮到了你，也欢迎你把这节课分享给自己的朋友。我们下一讲再见！</p><p><img src="/blog-other/static/httpsstatic001geekbangorgresourceimagef123f16f468d8e15018923564b9e7a784a23.7094a061.jpg" alt=""/></p></div><div class="__dumi-default-layout-footer-meta"><a target="_blank" rel="noopener noreferrer" href="https://github.com/GGwujun/blog/edit/master/ssrc/零基础实战机器学习/03.业务场景闯关篇/06.md">在 GitHub 上编辑此页<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="__dumi-default-external-link-icon"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a><span data-updated-text="最后更新时间：">2023/9/23 21:58:31</span></div></div></div></div>
	<script>
  window.g_useSSR = true;
  window.g_initialProps = {};
	</script>

    <script>
      (function () {
        if (!location.port) {
          (function (i, s, o, g, r, a, m) {
            i["GoogleAnalyticsObject"] = r;
            (i[r] =
              i[r] ||
              function () {
                (i[r].q = i[r].q || []).push(arguments);
              }),
              (i[r].l = 1 * new Date());
            (a = s.createElement(o)), (m = s.getElementsByTagName(o)[0]);
            a.async = 1;
            a.src = g;
            m.parentNode.insertBefore(a, m);
          })(
            window,
            document,
            "script",
            "//www.google-analytics.com/analytics.js",
            "ga"
          );
          ga("create", "UA-149864185-1", "auto");
          ga("send", "pageview");
        }
      })();
    </script>
    <script src="/blog-other/umi.js"></script>
  </body>
</html>
