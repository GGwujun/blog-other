<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta
      name="viewport"
      content="width=device-width, initial-scale=1, maximum-scale=1, minimum-scale=1, user-scalable=no"
    />
    <link rel="shortcut icon" type="image/x-icon" href="/logo.png" />
    <link rel="stylesheet" href="/blog-other/umi.css" />
    <script>
      window.routerBase = "/blog-other";
    </script>
    <script>
      //! umi version: 3.5.41
    </script>
    <script>
      !(function () {
        var e =
            navigator.cookieEnabled && void 0 !== window.localStorage
              ? localStorage.getItem("dumi:prefers-color")
              : "auto",
          o = window.matchMedia("(prefers-color-scheme: dark)").matches,
          t = ["light", "dark", "auto"];
        document.documentElement.setAttribute(
          "data-prefers-color",
          e === t[2] ? (o ? t[1] : t[0]) : t.indexOf(e) > -1 ? e : t[0]
        );
      })();
    </script>
    <title>17｜集成学习：机器学习模型如何“博采众长”? - 大师兄</title>
  </head>
  <body>
    <div id="root"><div class="__dumi-default-layout" data-route="/零基础实战机器学习/03.业务场景闯关篇/13" data-show-sidemenu="true" data-show-slugs="true" data-site-mode="true" data-gapless="false"><div class="__dumi-default-navbar" data-mode="site"><button class="__dumi-default-navbar-toggle"></button><a class="__dumi-default-navbar-logo" style="background-image:url(&#x27;/logo.png&#x27;)" href="/blog-other/">大师兄</a><nav><div class="__dumi-default-search"><input type="search" class="__dumi-default-search-input" value=""/><ul></ul></div><span>前端开发<ul><li><a href="/blog-other/说透低代码">说透低代码</a></li><li><a href="/blog-other/反爬虫兵法演绎20讲">反爬虫兵法演绎20讲</a></li></ul></span><span>产品与用户体验<ul><li><a href="/blog-other/大厂广告产品心法">大厂广告产品心法</a></li></ul></span><span>面试<ul><li><a href="/blog-other/技术面试官识人手册">技术面试官识人手册</a></li><li><a href="/blog-other/面试现场">面试现场</a></li></ul></span><span>杂谈<ul><li><a href="/blog-other/乔新亮的cto成长复盘">乔新亮的cto成长复盘</a></li><li><a href="/blog-other/互联网人的英语私教课">互联网人的英语私教课</a></li><li><a href="/blog-other/从0开始学游戏开发">从0开始学游戏开发</a></li><li><a href="/blog-other/全栈工程师修炼指南">全栈工程师修炼指南</a></li><li><a href="/blog-other/手机摄影">手机摄影</a></li><li><a href="/blog-other/物联网开发实战">物联网开发实战</a></li><li><a href="/blog-other/白话法律42讲">白话法律42讲</a></li><li><a href="/blog-other/说透5g">说透5g</a></li><li><a href="/blog-other/超级访谈对话张雪峰">超级访谈对话张雪峰</a></li><li><a aria-current="page" class="active" href="/blog-other/零基础实战机器学习">零基础实战机器学习</a></li></ul></span><div class="__dumi-default-navbar-tool"><div class="__dumi-default-dark"><div class="__dumi-default-dark-switch "></div></div></div></nav></div><div class="__dumi-default-menu" data-mode="site"><div class="__dumi-default-menu-inner"><div class="__dumi-default-menu-header"><a class="__dumi-default-menu-logo" style="background-image:url(&#x27;/logo.png&#x27;)" href="/blog-other/"></a><h1>大师兄</h1><p></p></div><div class="__dumi-default-menu-mobile-area"><ul class="__dumi-default-menu-nav-list"><li>前端开发<ul><li><a href="/blog-other/说透低代码">说透低代码</a></li><li><a href="/blog-other/反爬虫兵法演绎20讲">反爬虫兵法演绎20讲</a></li></ul></li><li>产品与用户体验<ul><li><a href="/blog-other/大厂广告产品心法">大厂广告产品心法</a></li></ul></li><li>面试<ul><li><a href="/blog-other/技术面试官识人手册">技术面试官识人手册</a></li><li><a href="/blog-other/面试现场">面试现场</a></li></ul></li><li>杂谈<ul><li><a href="/blog-other/乔新亮的cto成长复盘">乔新亮的cto成长复盘</a></li><li><a href="/blog-other/互联网人的英语私教课">互联网人的英语私教课</a></li><li><a href="/blog-other/从0开始学游戏开发">从0开始学游戏开发</a></li><li><a href="/blog-other/全栈工程师修炼指南">全栈工程师修炼指南</a></li><li><a href="/blog-other/手机摄影">手机摄影</a></li><li><a href="/blog-other/物联网开发实战">物联网开发实战</a></li><li><a href="/blog-other/白话法律42讲">白话法律42讲</a></li><li><a href="/blog-other/说透5g">说透5g</a></li><li><a href="/blog-other/超级访谈对话张雪峰">超级访谈对话张雪峰</a></li><li><a aria-current="page" class="active" href="/blog-other/零基础实战机器学习">零基础实战机器学习</a></li></ul></li></ul><div class="__dumi-default-dark"><div class="__dumi-default-dark-switch "><button title="Dark theme" class="__dumi-default-dark-moon "><svg viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="3854" width="22" height="22"><path d="M991.816611 674.909091a69.166545 69.166545 0 0 0-51.665455-23.272727 70.795636 70.795636 0 0 0-27.438545 5.585454A415.674182 415.674182 0 0 1 754.993338 698.181818c-209.594182 0-393.472-184.785455-393.472-395.636363 0-52.363636 38.539636-119.621818 69.515637-173.614546 4.887273-8.610909 9.634909-16.756364 14.103272-24.901818A69.818182 69.818182 0 0 0 384.631156 0a70.842182 70.842182 0 0 0-27.438545 5.585455C161.678429 90.298182 14.362065 307.898182 14.362065 512c0 282.298182 238.824727 512 532.38691 512a522.286545 522.286545 0 0 0 453.957818-268.334545A69.818182 69.818182 0 0 0 991.816611 674.909091zM546.679156 954.181818c-248.785455 0-462.941091-192-462.941091-442.181818 0-186.647273 140.637091-372.829091 300.939637-442.181818-36.817455 65.629091-92.578909 151.970909-92.578909 232.727273 0 250.181818 214.109091 465.454545 462.917818 465.454545a488.331636 488.331636 0 0 0 185.181091-46.545455 453.003636 453.003636 0 0 1-393.565091 232.727273z m103.656728-669.323636l-14.266182 83.781818a34.909091 34.909091 0 0 0 50.362182 36.770909l74.775272-39.563636 74.752 39.563636a36.142545 36.142545 0 0 0 16.174546 3.956364 34.909091 34.909091 0 0 0 34.210909-40.727273l-14.289455-83.781818 60.509091-59.345455a35.025455 35.025455 0 0 0-19.223272-59.578182l-83.61891-12.101818-37.376-76.101818a34.56 34.56 0 0 0-62.254545 0l-37.376 76.101818-83.618909 12.101818a34.909091 34.909091 0 0 0-19.246546 59.578182z m70.423272-64.698182a34.280727 34.280727 0 0 0 26.135273-19.083636l14.312727-29.090909 14.336 29.090909a34.257455 34.257455 0 0 0 26.135273 19.083636l32.046546 4.887273-23.272728 22.574545a35.234909 35.234909 0 0 0-10.007272 30.952727l5.46909 32.116364-28.625454-15.127273a34.490182 34.490182 0 0 0-32.302546 0l-28.695272 15.127273 5.469091-32.116364a35.141818 35.141818 0 0 0-9.984-30.952727l-23.272728-22.574545z" p-id="3855"></path></svg></button><button title="Light theme" class="__dumi-default-dark-sun "><svg viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="4026" width="22" height="22"><path d="M915.2 476.16h-43.968c-24.704 0-44.736 16-44.736 35.84s20.032 35.904 44.736 35.904H915.2c24.768 0 44.8-16.064 44.8-35.904s-20.032-35.84-44.8-35.84zM512 265.6c-136.704 0-246.464 109.824-246.464 246.4 0 136.704 109.76 246.464 246.464 246.464S758.4 648.704 758.4 512c0-136.576-109.696-246.4-246.4-246.4z m0 425.6c-99.008 0-179.2-80.128-179.2-179.2 0-98.944 80.192-179.2 179.2-179.2S691.2 413.056 691.2 512c0 99.072-80.192 179.2-179.2 179.2zM197.44 512c0-19.84-19.136-35.84-43.904-35.84H108.8c-24.768 0-44.8 16-44.8 35.84s20.032 35.904 44.8 35.904h44.736c24.768 0 43.904-16.064 43.904-35.904zM512 198.464c19.776 0 35.84-20.032 35.84-44.8v-44.8C547.84 84.032 531.84 64 512 64s-35.904 20.032-35.904 44.8v44.8c0 24.768 16.128 44.864 35.904 44.864z m0 627.136c-19.776 0-35.904 20.032-35.904 44.8v44.736C476.096 940.032 492.16 960 512 960s35.84-20.032 35.84-44.8v-44.736c0-24.768-16.064-44.864-35.84-44.864z m329.92-592.832c17.472-17.536 20.288-43.072 6.4-57.024-14.016-14.016-39.488-11.2-57.024 6.336-4.736 4.864-26.496 26.496-31.36 31.36-17.472 17.472-20.288 43.008-6.336 57.024 13.952 14.016 39.488 11.2 57.024-6.336 4.8-4.864 26.496-26.56 31.296-31.36zM213.376 759.936c-4.864 4.8-26.56 26.624-31.36 31.36-17.472 17.472-20.288 42.944-6.4 56.96 14.016 13.952 39.552 11.2 57.024-6.336 4.8-4.736 26.56-26.496 31.36-31.36 17.472-17.472 20.288-43.008 6.336-56.96-14.016-13.952-39.552-11.072-56.96 6.336z m19.328-577.92c-17.536-17.536-43.008-20.352-57.024-6.336-14.08 14.016-11.136 39.488 6.336 57.024 4.864 4.864 26.496 26.56 31.36 31.424 17.536 17.408 43.008 20.288 56.96 6.336 14.016-14.016 11.264-39.488-6.336-57.024-4.736-4.864-26.496-26.56-31.296-31.424z m527.168 628.608c4.864 4.864 26.624 26.624 31.36 31.424 17.536 17.408 43.072 20.224 57.088 6.336 13.952-14.016 11.072-39.552-6.4-57.024-4.864-4.8-26.56-26.496-31.36-31.36-17.472-17.408-43.072-20.288-57.024-6.336-13.952 14.016-11.008 39.488 6.336 56.96z" p-id="4027"></path></svg></button><button title="Default to system" class="__dumi-default-dark-auto "><svg viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="11002" width="22" height="22"><path d="M127.658667 492.885333c0-51.882667 10.24-101.717333 30.378666-149.162666s47.786667-88.064 81.92-122.538667 75.093333-61.781333 122.538667-81.92 96.938667-30.378667 149.162667-30.378667 101.717333 10.24 149.162666 30.378667 88.405333 47.786667 122.88 81.92 61.781333 75.093333 81.92 122.538667 30.378667 96.938667 30.378667 149.162666-10.24 101.717333-30.378667 149.162667-47.786667 88.405333-81.92 122.88-75.093333 61.781333-122.88 81.92-97.28 30.378667-149.162666 30.378667-101.717333-10.24-149.162667-30.378667-88.064-47.786667-122.538667-81.92-61.781333-75.093333-81.92-122.88-30.378667-96.938667-30.378666-149.162667z m329.045333 0c0 130.048 13.994667 244.394667 41.984 343.381334h12.970667c46.762667 0 91.136-9.216 133.461333-27.306667s78.848-42.666667 109.568-73.386667 54.954667-67.242667 73.386667-109.568 27.306667-86.698667 27.306666-133.461333c0-46.421333-9.216-90.794667-27.306666-133.12s-42.666667-78.848-73.386667-109.568-67.242667-54.954667-109.568-73.386667-86.698667-27.306667-133.461333-27.306666h-11.605334c-28.672 123.562667-43.349333 237.909333-43.349333 343.722666z" p-id="11003"></path></svg></button></div></div></div><ul class="__dumi-default-menu-list"><li><a href="/blog-other/零基础实战机器学习">零基础实战机器学习</a></li><li><a href="/blog-other/零基础实战机器学习/01.开篇词">01.开篇词</a><ul><li><a href="/blog-other/零基础实战机器学习/01.开篇词/01"><span>开篇词｜开发者为什么要从实战出发学机器学习？</span></a></li></ul></li><li><a href="/blog-other/零基础实战机器学习/02.准备篇">02.准备篇</a><ul><li><a href="/blog-other/零基础实战机器学习/02.准备篇/01"><span>01｜打好基础：到底什么是机器学习？</span></a></li><li><a href="/blog-other/零基础实战机器学习/02.准备篇/02"><span>02｜工具准备：安装并使用Jupyter Notebook</span></a></li><li><a href="/blog-other/零基础实战机器学习/02.准备篇/03"><span>03｜实战5步（上）：怎么定义问题和预处理数据？</span></a></li><li><a href="/blog-other/零基础实战机器学习/02.准备篇/04"><span>04｜ 实战5步（下）：怎么建立估计10万+软文点击率的模型？</span></a></li></ul></li><li><a aria-current="page" class="active" href="/blog-other/零基础实战机器学习/03.业务场景闯关篇">03.业务场景闯关篇</a><ul><li><a href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/01"><span>05 | 数据探索：怎样从数据中找到用户的RFM值？</span></a></li><li><a href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/02"><span>06 | 聚类分析：如何用RFM给电商用户做价值分组画像？</span></a></li><li><a href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/03"><span>07｜回归分析：怎样用模型预测用户的生命周期价值？</span></a></li><li><a href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/04"><span>08 | 模型优化（上）：怎么用特征工程提高模型效率？</span></a></li><li><a href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/05"><span>09｜模型优化（中）：防止过拟合，模型也不能太精细</span></a></li><li><a href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/06"><span>10｜模型优化（下）：交叉验证，同时寻找最优的参数</span></a></li><li><a href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/07"><span>11｜深度学习（上）：用CNN带你认识深度学习</span></a></li><li><a href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/08"><span>12｜深度学习（中）：如何用RNN预测激活率走势？</span></a></li><li><a href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/09"><span>13｜深度学习（下）：3招提升神经网络预测准确率</span></a></li><li><a href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/10"><span>14｜留存分析：哪些因素会影响用户的留存率？</span></a></li><li><a href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/11"><span>15｜二元分类：怎么预测用户是否流失？从逻辑回归到深度学习</span></a></li><li><a href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/12"><span>16｜性能评估：不平衡数据集应该使用何种评估指标？</span></a></li><li><a aria-current="page" class="active" href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/13"><span>17｜集成学习：机器学习模型如何“博采众长”?</span></a></li><li><a href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/14"><span>18 | 增长模型：用XGBoost评估裂变海报的最佳受众群体</span></a></li></ul></li><li><a href="/blog-other/零基础实战机器学习/04.持续赋能篇">04.持续赋能篇</a><ul><li><a href="/blog-other/零基础实战机器学习/04.持续赋能篇/01"><span>19 | 胸有成竹：如何快速定位合适的机器学习算法？</span></a></li><li><a href="/blog-other/零基础实战机器学习/04.持续赋能篇/02"><span>20 | 模型部署：怎么发布训练好的机器学习模型？</span></a></li><li><a href="/blog-other/零基础实战机器学习/04.持续赋能篇/03"><span>21｜持续精进：如何在机器学习领域中找准前进的方向？</span></a></li></ul></li><li><a href="/blog-other/零基础实战机器学习/05.结束语">05.结束语</a><ul><li><a href="/blog-other/零基础实战机器学习/05.结束语/01"><span>一套习题，测出你对机器学习的掌握程度</span></a></li><li><a href="/blog-other/零基础实战机器学习/05.结束语/02"><span>结束语 | 可以不完美，但重要的是马上开始</span></a></li></ul></li><li><a href="/blog-other/零基础实战机器学习/summary">零基础实战机器学习</a></li></ul></div></div><ul role="slug-list" class="__dumi-default-layout-toc"><li title="定义问题" data-depth="2"><a href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/13#定义问题"><span>定义问题</span></a></li><li title="数据可视化和预处理" data-depth="2"><a href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/13#数据可视化和预处理"><span>数据可视化和预处理</span></a></li><li title="算法选择：集成学习" data-depth="2"><a href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/13#算法选择集成学习"><span>算法选择：集成学习</span></a></li><li title="降低偏差：Boosting方法" data-depth="2"><a href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/13#降低偏差boosting方法"><span>降低偏差：Boosting方法</span></a></li><li title="1. AdaBoost算法" data-depth="3"><a href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/13#1-adaboost算法"><span>1. AdaBoost算法</span></a></li><li title="2. GBDT算法" data-depth="3"><a href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/13#2-gbdt算法"><span>2. GBDT算法</span></a></li><li title="3. XGBoost算法" data-depth="3"><a href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/13#3-xgboost算法"><span>3. XGBoost算法</span></a></li><li title="降低方差：Bagging方法" data-depth="2"><a href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/13#降低方差bagging方法"><span>降低方差：Bagging方法</span></a></li><li title="1. 决策树的Bagging" data-depth="3"><a href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/13#1-决策树的bagging"><span>1. 决策树的Bagging</span></a></li><li title="2. 随机森林算法" data-depth="3"><a href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/13#2-随机森林算法"><span>2. 随机森林算法</span></a></li><li title="3. 极端随机森林算法" data-depth="3"><a href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/13#3-极端随机森林算法"><span>3. 极端随机森林算法</span></a></li><li title="总结一下" data-depth="2"><a href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/13#总结一下"><span>总结一下</span></a></li><li title="思考题" data-depth="2"><a href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/13#思考题"><span>思考题</span></a></li></ul><div class="__dumi-default-layout-content"><div class="markdown"><h1 id="17集成学习机器学习模型如何博采众长"><a aria-hidden="true" tabindex="-1" href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/13#17集成学习机器学习模型如何博采众长"><span class="icon icon-link"></span></a>17｜集成学习：机器学习模型如何“博采众长”?</h1><p>你好，我是黄佳。恭喜你连闯４关，成功来到最后一关“裂变关”。</p><p>回忆一下这一路的旅程，在获客关中，我们给用户分组画像；在变现关中，我们关注用户的生命周期价值；在激活关中，我们预测了App的激活数字；在留存关中，我们分析了与用户流失相关的因素。</p><p><img src="/blog-other/static/httpsstatic001geekbangorgresourceimage8c958ce98a4187cc752f3ab9d7ebb988da95.41c9336d.jpg" alt=""/></p><p>那么在裂变关中，我们将从数据中寻找蛛丝马迹，发现“易速鲜花”运营中最佳的“裂变方案”。不过，除了介绍运营中的裂变方案外，今天，我们还要好好讲一讲集成学习。</p><p>为什么要专门拿出一讲来谈集成学习呢？我们在<a target="_blank" rel="noopener noreferrer" href="https://time.geekbang.org/column/article/419218">第9讲<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="__dumi-default-external-link-icon"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>说过，我们用机器学习建模的过程，就是和过拟合现象持续作斗争的过程。而集成学习在机器学习中是很特别的一类方法，能够处理回归和分类问题，而且它对于避免模型中的过拟合问题，具有天然的优势。那么，集成学习的优势是怎么形成的？学习了今天的课程后你就会找到答案。</p><h2 id="定义问题"><a aria-hidden="true" tabindex="-1" href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/13#定义问题"><span class="icon icon-link"></span></a>定义问题</h2><p>老规矩，我们先来定义今天要解决的问题。</p><p>说起裂变，你可能并不会感到陌生。裂变是让产品自循环、自传播的重要工具。像邀请新人得红包、分享App领优惠券、友情助力拿赠品、朋友圈打卡退学费等等，都是裂变的玩法。</p><p>最近，“易速鲜花”运营部门提出了两个裂变思路。方案一是选择一批热销商品，让老用户邀请朋友扫码下载App并成功注册，朋友越多，折扣越大。我们把这个方案命名为“疯狂打折”，它走的是友情牌。方案二是找到一个朋友一起购买，第二件商品就可以免费赠送，这叫“买一送一”。</p><p>提出两个裂变方案之后，运营部门收集了<a target="_blank" rel="noopener noreferrer" href="https://github.com/huangjia2019/geektime/tree/main/%E8%A3%82%E5%8F%98%E5%85%B317">转化数据<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="__dumi-default-external-link-icon"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>。那么，我们今天的目标就是<strong>根据这个数据集，来判断一个特定用户在特定的裂变促销之下，是否会转化。</strong></p><p><img src="data:image/png;base64,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" alt=""/></p><p>这个问题和我们之前预测用户是否会流失非常相似，也是一个二元分类问题。</p><p>下面我们就导入相关的包，并读入数据：</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">import pandas as pd #导入Pandas</span></div><div class="token-line"><span class="token plain">    import numpy as np #导入NumPy</span></div><div class="token-line"><span class="token plain">    df_fission = pd.read_csv(&#x27;易速鲜花裂变转化.csv&#x27;) #载入数据</span></div><div class="token-line"><span class="token plain">    df_fission.head() #显示数据</span></div></pre></div><p>输出如下：</p><p><img src="/blog-other/static/httpsstatic001geekbangorgresourceimagedbf7db26f6b958f0493277d021e598324df7.1d0368d2.png" alt=""/></p><p>在这个数据集中，共有10000个数据样本，也就是10000个用户的信息。其他字段都很好理解，我们重点来看看“裂变方案”字段。这个字段表示的是该用户所导流到的裂变类型，一个用户看到的是“疯狂打折”优惠页，还是“买一送一”优惠页，是随机分配的结果。对于一个用户，二者只能属于其一。而与之对应的“是否转化”字段就<strong>是我们用来预测转化率的标签<strong><strong>了</strong></strong>。</strong></p><p>下面我们进入数据可视化和预处理的环节。</p><h2 id="数据可视化和预处理"><a aria-hidden="true" tabindex="-1" href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/13#数据可视化和预处理"><span class="icon icon-link"></span></a>数据可视化和预处理</h2><p>在数据可视化部分，我只想看一看转化和未转化的比例，也就是购买产品和未购买产品的比例。看这个比例是为了看这个数据集中的各类别样本数是否平衡。</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">import matplotlib.pyplot as plt #导入pyplot模块</span></div><div class="token-line"><span class="token plain">    import seaborn as sns #导入Seaborn</span></div><div class="token-line"><span class="token plain">    fig = sns.countplot(&#x27;是否转化&#x27;, data=df_fission) #创建柱状计数图</span></div><div class="token-line"><span class="token plain">    fig.set_ylabel(&quot;数目&quot;) #Y轴标题</span></div><div class="token-line"><span class="token plain">    plt.show() #显示图像</span></div></pre></div><p>输入如下：</p><p><img src="data:image/png;base64,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" alt=""/></p><p>结果显示，在10000个用户中，大概有2000个用户购买了产品，转化率大概在20%。说明运营人员给我们的是一个并不平衡的分类数据集。这个结论将为我们后续的算法选择做出指导。</p><p>下面，我们把数据集中的类别变量，转变为机器学习模型能够读取的虚拟变量（也叫哑编码或哑变量）：</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain"># 把二元类别文本数字化</span></div><div class="token-line"><span class="token plain">    df_fission[&#x27;性别&#x27;].replace(&quot;女&quot;,0,inplace = True)</span></div><div class="token-line"><span class="token plain">    df_fission[&#x27;性别&#x27;].replace(&quot;男&quot;,1,inplace=True)</span></div><div class="token-line"><span class="token plain">    # 显示数字类别</span></div><div class="token-line"><span class="token plain">    print(&quot;Gender unique values&quot;,df_fission[&#x27;性别&#x27;].unique())</span></div><div class="token-line"><span class="token plain">    # 把多元类别转换成多个二元哑变量，然后贴回原始数据集</span></div><div class="token-line"><span class="token plain">    df_fission = pd.get_dummies(df_fission, drop_first = True)</span></div><div class="token-line"><span class="token plain">    df_fission # 显示数据集</span></div></pre></div><p>输出如下：</p><p><img src="data:image/png;base64,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" alt=""/></p><p>然后，我们再来构建标签和特征数据集，并拆分出训练集和测试集，最后对特征进行归一化缩放。我们对这些步骤已经非常熟悉了，我就不需再过多解释了：</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">X = df_fission.drop([&#x27;用户码&#x27;,&#x27;是否转化&#x27;], axis = 1) # 构建特征集</span></div><div class="token-line"><span class="token plain">    y = df_fission.是否转化.values # 构建标签集</span></div><div class="token-line"><span class="token plain">    from sklearn.model_selection import train_test_split</span></div><div class="token-line"><span class="token plain">    X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.2)</span></div><div class="token-line"><span class="token plain">    from sklearn.preprocessing import MinMaxScaler #导入归一化缩放器</span></div><div class="token-line"><span class="token plain">    scaler = MinMaxScaler() #创建归一化缩放器</span></div><div class="token-line"><span class="token plain">    X_train = scaler.fit_transform(X_train) #拟合并转换训练集数据</span></div><div class="token-line"><span class="token plain">    X_test = scaler.transform(X_test) #转换测试集数据</span></div></pre></div><p>这样，数据集就准备好啦，现在，我们进入算法选择环节。</p><h2 id="算法选择集成学习"><a aria-hidden="true" tabindex="-1" href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/13#算法选择集成学习"><span class="icon icon-link"></span></a>算法选择：集成学习</h2><p>我们前面说，判断一个特定用户在特定的裂变促销之下是否会转化，属于二元分类问题。对于二分类问题，我们在<a target="_blank" rel="noopener noreferrer" href="https://time.geekbang.org/column/article/423893">第15讲<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="__dumi-default-external-link-icon"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>中也提到过，它不仅可以用逻辑回归解决，还可以通过SVM、集成学习、神经网络等多种模型完成。现在，我们就借助这一讲的项目，着重来了解一下集成学习方法的原理和应用。</p><p><strong>集成学习(ensemble learning)，是通过构建出多个模型（这些模型可以是比较弱的模型），然后将它们组合起来完成任务的机器学习算法</strong>。所以，它实际上并不是一种机器学习算法，而是一个机器学习算法的家族。通常情况下，集成学习将几个表现一般的模型集成在一起，就能大幅提升模型的性能，这就是集成学习的天然优势。</p><p>在这个算法家族中，很多算法都是“网红”算法，比如随机森林、梯度提升机（英文叫GB或GBDT）和极限梯度提升（eXtreme Gradient Boosting，即XGBoost，有时候简称XGB）等，这些都是非常流行的机器学习算法，在很多许多领域都取得了成功，并且还是很多人赢得各种机器学习竞赛的主要方法。</p><p>那么，为什么几个表现一般的模型集成在一起，性能会大幅提升？下面，我们来探究一下。首先，请你回忆一下，我们在<a target="_blank" rel="noopener noreferrer" href="https://time.geekbang.org/column/article/419218">第9讲<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="__dumi-default-external-link-icon"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>中讲过，机器学习在训练时有一个从欠拟合到过拟合的过程：</p><p><img src="/blog-other/static/httpsstatic001geekbangorgresourceimage5537557e4ff908038d3d43e5653903e1ee37.621e37be.png" alt="" title="从欠拟合到过拟合"/></p><p>如果结合我们已经比较熟悉的损失曲线，就可以用下面这张图来描述这一过程：</p><p><img src="/blog-other/static/httpsstatic001geekbangorgresourceimage1de11d4032ed253404d751383fa3df6a9ee1.06afdb74.png" alt="" title="损失、偏差、方差与模型复杂度之间的关系"/></p><p>我们说，当给定一个学习任务，在训练初期，模型对训练集的拟合还未完善，训练集和测试集上面的损失也都比较大，这时候的模型处于欠拟合状态。由于模型的拟合能力还不强，数据集的改变是无法使模型的效率产生显著变化的，所以，如果我们把此时的模型应用于训练集和测试集的数据，都会出现“<strong>高偏差</strong>”。</p><p>随着训练次数增多，模型的拟合能力在调整优化的过程中会变得越来越强，训练集上和测试集上的损失也都会不断下降。</p><p>当充分训练之后，模型已经完全拟合了训练集数据，训练集上的损失也变得非常小。但是，这时候的模型很容易受数据的影响，数据的轻微扰动都会导致模型发生显著变化。这时候，如果我们把模型应用于不同的数据集（包括测试集），会出现<strong>很高的方差</strong>，也就是过拟合的状态。</p><p>总的来说就是，模型在欠拟合状态会出现“高偏差”，在过拟合状态会出现“高方差”，这都不符合我们的预期。只有在拟合刚刚好的时候，模型才是相对成功的。这时候，模型的偏差和方差处于平衡态，均不会太高。</p><p>你可能注意到，在上面的讲述中，我引入了“方差”和“偏差”这两个新概念。方差，是从统计学中引用过来的概念，它表示的是一组数据距离其均值的离散程度。而“偏差”是机器学习里概念，用来衡量模型的准确程度。</p><p>在机器学习中，“低偏差”和“低方差”是我们希望达到的效果。可是，一般来说, 低偏差与低方差是鱼与熊掌不可兼得的，这被称作偏差-方差窘境 (bias-variance dilemma)。下面这张打靶图，就形象地说明了这一点：<br/><img src="/blog-other/static/httpsstatic001geekbangorgresourceimage1b651b4846d4f28a0954b7e8eecc38b0f265.359178a7.png" alt="" title="方差和偏差对预测结果所造成的影响"/></p><p>其实，机器学习性能优化领域的最核心问题，就是不断地在“欠拟合-过拟合”之间，也就是“偏差-方差”之间，探求最佳平衡点，换句话说，就是训练集优化和测试集泛化的平衡点。而机器学习的性能优化是有顺序的，我们一般是先减小偏差，再聚焦于降低方差。</p><p>那说了这么多，你也许有点不耐烦了：这些内容和集成学习到底有什么关系呢？</p><p>其实啊，集成学习的优点就在于，它可以通过组合一些比较简单的算法，来保留这些算法训练出的模型“方差低”的优势；在此基础之上，集成学习又能引入复杂的模型，来扩展简单算法的预测空间。所以，集成学习是同时减小方差和偏差的大招。</p><p>集成学习的核心思想是训练出多个模型并将这些模型进行组合。根据分类器的训练方式和组合预测的方法，集成学习中两种最重要的方法就是：降低偏差的Boosting和降低方差的Bagging。</p><p>下面，我们就一边讲解这两种方法，一边用它们来解决“特定用户在特定的裂变促销之下是否会转化成功”的预测问题。</p><p>我们先来看Boosting。</p><h2 id="降低偏差boosting方法"><a aria-hidden="true" tabindex="-1" href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/13#降低偏差boosting方法"><span class="icon icon-link"></span></a>降低偏差：Boosting方法</h2><p>Boosting方法是把梯度下降的思想应用在了机器学习算法的优化上，让弱模型对数据的拟合逐渐增强。它的基本思路就是：持续地通过新模型来优化同一个基模型（基模型，也就是Boosting开始时的初始模型），当一个新的弱模型加入进来的时候，Boosting就在原有模型的基础上整合这个新模型，然后形成新的基模型。而对这个新的基模型的训练，则会一直聚集于之前模型的误差点（也就是原模型预测出错的样本）上，这样做的目标是不断减小模型的预测误差。</p><p>在Boosting方法中，有三种很受欢迎的算法，分别是AdaBoost、GBDT 和XGBoost。其中，AdaBoost会对样本进行加权；GBDT在AdaBoost的基础上，还会定义一个损失函数，通过梯度下降来优化模型；而XGBoost则在GBDT的基础上，进一步优化了梯度下降的方式。</p><p>这三种算法都可以用来解决我们这一讲的分类问题（其实也可以用于回归问题）。下面，我们来逐一做个讲解。</p><h3 id="1-adaboost算法"><a aria-hidden="true" tabindex="-1" href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/13#1-adaboost算法"><span class="icon icon-link"></span></a>1. AdaBoost算法</h3><p>我们先来使用AdaBoost算法。在处理分类问题时，AdaBoost 会先给不同的样本分配不同的权重，被分错的样本的权重在Boosting 过程中会增大，新模型会因此更加关注这些被分错的样本；反之，被分正确的样本的权重会减小。接着，AdaBoost会将修改过权重的新数据集输入到新模型进行训练，产生新的基模型。最后，AdaBoost会把每次得到的基模型组合起来，并根据其分类错误率对模型赋予权重，集成为最终的模型。</p><p>下面，我们用AdaBoost算法来预测一下用户在特定的裂变促销之下是否会转化，并给出评估分数：</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">from sklearn.ensemble import AdaBoostClassifier # 导入AdaBoost 模型</span></div><div class="token-line"><span class="token plain">    dt = DecisionTreeClassifier() # 选择决策树分类器作为AdaBoost 的基准算法</span></div><div class="token-line"><span class="token plain">    ada = AdaBoostClassifier(dt) # AdaBoost 模型</span></div><div class="token-line"><span class="token plain">    ada.fit(X_train, y_train) # 拟合模型</span></div><div class="token-line"><span class="token plain">    y_pred = ada.predict(X_test) # 进行预测</span></div><div class="token-line"><span class="token plain">    print(&quot;AdaBoost 测试准确率: {:.2f}%&quot;.format(ada.score(X_test, y_test)*100))</span></div><div class="token-line"><span class="token plain">    print(&quot;AdaBoost 测试F1分数: {:.2f}%&quot;.format(f1_score(y_test, y_pred)*100))</span></div></pre></div><p>输出如下：</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">AdaBoost 测试准确率: 78.75%</span></div><div class="token-line"><span class="token plain">    AdaBoost 测试F1分数: 50.18%</span></div></pre></div><p>结果显示，AdaBoost算法测试准确率是78.75%，F1分数为50.18%。这个F1分数并不是很理想，我们需要考虑一下有没有更优的算法。而下面要介绍的GBDT算法就对AdaBoost算法做出了进一步的改进。</p><h3 id="2-gbdt算法"><a aria-hidden="true" tabindex="-1" href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/13#2-gbdt算法"><span class="icon icon-link"></span></a>2. GBDT算法</h3><p>GBDT算法也叫梯度提升（Granding Boosting）算法，它是梯度下降和Boosting方法结合的产物。因为常见的梯度提升都是基于决策树模型（机器学习中就把决策树模型简称为树）的，所以我们这里会把它称作是GBDT，即梯度提升决策树（Granding Boosting Decision Tree）。</p><p>我们知道，前面的AdaBoost算法只是对样本进行加权，但GBDT 算法与之不同，它还会定义一个损失函数，并对损失和机器学习模型所形成的函数进行求导，每次生成的模型都是沿着前面模型的负梯度方向（一阶导数）进行优化，直到发现全局最优解。也就是说，在GBDT的每一次迭代中，当前的树所学习的内容是之前所有树的结论和损失，在学习中，GBDT会拟合得到一棵新的树，而这棵新的树就相当于是之前每一棵树的效果累加。</p><p>下面，我们用GBDT算法来预测用户是否转化，并给出评估分数：</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">from sklearn.ensemble import GradientBoostingClassifier # 导入梯度提升模型</span></div><div class="token-line"><span class="token plain">    gb = GradientBoostingClassifier() # 梯度提升模型</span></div><div class="token-line"><span class="token plain">    gb.fit(X_train, y_train) # 拟合模型</span></div><div class="token-line"><span class="token plain">    y_pred = gb.predict(X_test) # 进行预测</span></div><div class="token-line"><span class="token plain">    print(&quot; 梯度提升测试准确率: {:.2f}%&quot;.format(gb.score(X_test, y_test)*100))</span></div><div class="token-line"><span class="token plain">    print(&quot; 梯度提升测试F1分数: {:.2f}%&quot;.format(f1_score(y_test, y_pred)*100))</span></div></pre></div><p>输出如下：</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">梯度提升测试准确率: 87.00%</span></div><div class="token-line"><span class="token plain">    梯度提升测试F1 分数: 61.19%</span></div></pre></div><p>结果显示，GBDT算法的测试准确率是87.00%，F1分数为61.19%。F1分数果然大幅提升，看来GBDT算法还不错。其实，还有比GBDT更厉害的集成学习算法，它就是算法XGBoost算法。</p><h3 id="3-xgboost算法"><a aria-hidden="true" tabindex="-1" href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/13#3-xgboost算法"><span class="icon icon-link"></span></a>3. XGBoost算法</h3><p>XGBoost算法也叫极端梯度提升（eXtreme Gradient Boosting），有时候也直接叫作XGB。它和GBDT 类似，也会定义一个损失函数。不过，不同的是，GBDT 只用到一阶导数信息，而XGBoost会利用泰勒展开式把损失函数展开到二阶后求导。由于利用了二阶导数信息，XGBoost在训练集上的收敛会更快。</p><p>在使用XGBoost之前，我们需要通过pip语句安装XGBoost包，当然，你也可以在Anaconda的Environments（环境）界面中，直接搜索并安装XGBoost包：</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">pip install xgboost</span></div></pre></div><p>下面，我们用XGBoost算法来预测用户是否转化，并给出评估分数：</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">from xgboost import XGBClassifier # 导入XGB 模型</span></div><div class="token-line"><span class="token plain">    xgb = XGBClassifier() # XGB 模型</span></div><div class="token-line"><span class="token plain">    xgb.fit(X_train, y_train) # 拟合模型</span></div><div class="token-line"><span class="token plain">    y_pred = xgb.predict(X_test) # 进行预测</span></div><div class="token-line"><span class="token plain">    print(&quot;XGB 测试准确率: {:.2f}%&quot;.format(xgb.score(X_test, y_test)*100))</span></div><div class="token-line"><span class="token plain">    print(&quot;XGB 测试F1分数: {:.2f}%&quot;.format(f1_score(y_test, y_pred)*100))</span></div></pre></div><p>输出如下：</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">XGB 测试准确率: 87.00%</span></div><div class="token-line"><span class="token plain">    XGB 测试F1分数: 63.17%</span></div></pre></div><p>结果显示，XGBoost算法的测试准确率是87.00%，F1分数为63.17%。</p><p>可以看出，在上述三种算法中，XGBoost算法的性能是最佳的。虽然它的预测准确率和GBDT相同，但是它的F1分数高，而F1分数是我们更重视的指标。</p><p>下面，我们再来介绍并使用能降低方差的Bagging方法。</p><h2 id="降低方差bagging方法"><a aria-hidden="true" tabindex="-1" href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/13#降低方差bagging方法"><span class="icon icon-link"></span></a>降低方差：Bagging方法</h2><p>Bagging 是Bootstrap Aggregating 的缩写，有人把它翻译为套袋法、装袋法，或者自助聚合，到现在，还没有一个统一的叫法。所以，我们就直接用它的英文名称Bagging。</p><p>Bagging算法的基本思想是从原始的数据集中抽取数据，形成K个随机的新训练集，然后训练出K个不同的模型。</p><p>具体来讲，Bagging算法首先会在原始样本集中随机抽取K轮，每轮抽取n个训练样本作为一个训练集。这时候，有些样本可能被多次抽取，而有些样本可能一次都没有被抽取，这叫做有放回的抽取）。在抽取K轮之后，就会形成K个训练集，注意，这K个训练集是彼此独立的。这个过程也叫作bootstrap（可译为“自举”或“自助采样”）。</p><p>接着，Bagging算法会每次使用一个训练集，并通过相同的机器学习算法（如决策树、神经网络等）得到一个模型。因为有K个训练集，所以一共可以得到K个模型。我们把这些模型称为“基模型”（base estimator）或者“基学习器”。</p><p>最后，对于这K个模型，Bagging算法会用不同的方式得到基模型的集成结果：如果是分类问题，Bagging算法会对K个模型投票，进而得到分类结果；如果是回归问题，Bagging算法会计算K个模型的均值，将其作为最后的结果。</p><p>因为随机抽取数据的方法能减少可能的数据干扰，所以经过Bagging 的模型将会具有“低方差””。一般来说，Bagging有三种常见的算法：决策树的Bagging、随机森林算法和极端随机森林。</p><h3 id="1-决策树的bagging"><a aria-hidden="true" tabindex="-1" href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/13#1-决策树的bagging"><span class="icon icon-link"></span></a>1. 决策树的Bagging</h3><p>多数情况下的Bagging，都是基于决策树的。构造随机森林的第一步，其实就是对多棵决策树进行Bagging，我们把它称为树的聚合（Bagging of Tree）。</p><p>决策树这种模型，具有显著的低偏差、高方差的特点。也就是说，决策树模型受数据的影响特别大，一不小心，训练集准确率就接近100% 了，而这种效果又不能移植到其他的数据集上，所以，这是很明显的过拟合现象。集成学习的Bagging算法就是从决策树模型开始，着手解决它太过于精准，又不易泛化的问题。当然，Bagging的原理并不仅限于决策树，它还可以扩展到其他机器学习算法。</p><p>下面，我们用决策树的Bagging算法来预测用户是否转化，并给出评估分数：</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">from sklearn.ensemble import BaggingClassifier # 导入Bagging 分类器</span></div><div class="token-line"><span class="token plain">    from sklearn.tree import DecisionTreeClassifier # 导入决策树分类器</span></div><div class="token-line"><span class="token plain">    from sklearn.metrics import (f1_score, confusion_matrix) # 导入评估指标</span></div><div class="token-line"><span class="token plain">    dt = BaggingClassifier(DecisionTreeClassifier()) # 只使用一棵决策树</span></div><div class="token-line"><span class="token plain">    dt.fit(X_train, y_train) # 拟合模型</span></div><div class="token-line"><span class="token plain">    y_pred = dt.predict(X_test) # 进行预测</span></div><div class="token-line"><span class="token plain">    print(&quot; 决策树测试准确率: {:.2f}%&quot;.format(dt.score(X_test, y_test)*100))</span></div><div class="token-line"><span class="token plain">    print(&quot; 决策树测试F1 分数: {:.2f}%&quot;.format(f1_score(y_test, y_pred)*100))</span></div><div class="token-line"><span class="token plain">    bdt = BaggingClassifier(DecisionTreeClassifier()) # 树的Bagging</span></div><div class="token-line"><span class="token plain">    bdt.fit(X_train, y_train) # 拟合模型</span></div><div class="token-line"><span class="token plain">    y_pred = bdt.predict(X_test) # 进行预测</span></div><div class="token-line"><span class="token plain">    print(&quot; 决策树Bagging 测试准确率: {:.2f}%&quot;.format(bdt.score(X_test, y_test)*100))</span></div><div class="token-line"><span class="token plain">    print(&quot; 决策树Bagging 测试F1分数: {:.2f}%&quot;.format(f1_score(y_test, y_pred)*100))</span></div></pre></div><p>输出如下：</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">决策树测试准确率: 85.10%</span></div><div class="token-line"><span class="token plain">    决策树测试F1分数: 58.17%</span></div><div class="token-line"><span class="token plain">    决策树Bagging 测试准确率: 85.55%</span></div><div class="token-line"><span class="token plain">    决策树Bagging 测试F1 分数: 58.66%</span></div></pre></div><p>结果显示，对于这个数据集来说，决策树Bagging的测试集F1分数有提升，但是优势不明显。不过没关系，我们可以试一下更常见的随机森林算法，它其实是经过改进的“决策树Bagging算法”。</p><h3 id="2-随机森林算法"><a aria-hidden="true" tabindex="-1" href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/13#2-随机森林算法"><span class="icon icon-link"></span></a>2. 随机森林算法</h3><p>当我们说到集成学习，最关键的一点是：各个基模型的相关度要小，差异性要大。模型间差异越大（也就是异质性越强），集成的效果越好。两个准确率为99% 的模型，如果其预测结果都一致，也就没有提高的余地了。因此，对决策树做集成，关键就在于各棵树的差异性是否够大。</p><p>为了实现基模型差异化的目标，随机森林在树分叉时，增加了对特征选择的随机性，而并不总是考量全部的特征。这个小小的改进，就进一步提高了各棵树的差异。</p><p>下面，我们用随机森林算法来预测用户是否转化，并给出评估分数：</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">from sklearn.model_selectifrom sklearn.ensemble import RandomForestClassifier # 导入随机森林模型</span></div><div class="token-line"><span class="token plain">    rf = RandomForestClassifier() # 随机森林模型</span></div><div class="token-line"><span class="token plain">    rf.fit(X_train, y_train) # 拟合模型</span></div><div class="token-line"><span class="token plain">    y_pred = rf.predict(X_test) # 进行预测</span></div><div class="token-line"><span class="token plain">    print(&quot; 随机森林测试准确率: {:.2f}%&quot;.format(rf.score(X_test, y_test)*100))</span></div><div class="token-line"><span class="token plain">    print(&quot; 随机森林测试F1分数: {:.2f}%&quot;.format(f1_score(y_test, y_pred)*100))</span></div></pre></div><p>输出如下：</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">随机森林测试准确率: 87.20%</span></div><div class="token-line"><span class="token plain">     随机森林测试F1分数: 61.79%</span></div></pre></div><p>可以看到，随机森林测试F1分数很明显地高于决策树模型和决策树的Bagging。</p><h3 id="3-极端随机森林算法"><a aria-hidden="true" tabindex="-1" href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/13#3-极端随机森林算法"><span class="icon icon-link"></span></a>3. 极端随机森林算法</h3><p>最后，我们再来看极端随机森林算法。极端森林算法在随机森林的基础上，又增加了进一步的随机性。</p><p>随机森林算法在树分叉时会随机选取m个特征作为考量，对于每一次分叉，它还会遍历所有的分支，然后选择基于这些特征的最优分支。这在本质上仍属于贪心算法（greedy algorithm），即在每一步选择中都采取在当前状态下最优的选择。而极端随机森林算法则不同，它一点也不“贪心”，它甚至不回去考量所有的分支，而是随机选择一些分支，从中拿到一个最优解。</p><p>下面，我们用极端随机森林算法来预测用户是否转化，并给出评估分数：</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">from sklearn.ensemble import ExtraTreesClassifier # 导入极端随机森林模型</span></div><div class="token-line"><span class="token plain">    ext = ExtraTreesClassifier() # 极端随机森林模型</span></div><div class="token-line"><span class="token plain">    ext.fit(X_train, y_train) # 拟合模型</span></div><div class="token-line"><span class="token plain">    y_pred = ext.predict(X_test) # 进行预测</span></div><div class="token-line"><span class="token plain">    print(&quot; 极端随机森林测试准确率: {:.2f}%&quot;.format(ext.score(X_test, y_test)*100))</span></div><div class="token-line"><span class="token plain">    print(&quot; 极端随机森林测试F1分数: {:.2f}%&quot;.format(f1_score(y_test, y_pred)*100))</span></div></pre></div><p>输出如下：</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">极端随机森林测试准确率: 87.05%</span></div><div class="token-line"><span class="token plain">     极端随机森林测试F1分数: 60.58%</span></div></pre></div><p>结果显示，对于“预测一个特定用户在特定的裂变促销下是否会转化”这个问题来说，极端随机森林测试F1分数，要高于决策树和树的Bagging，但是低于随机森林算法。</p><p>最后，我们可以把上述各个集成学习算法的得分，都显示在一张图中，来比较一下它们在这个问题上的优劣。</p><p><img src="data:image/png;base64,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" alt=""/></p><p>图中可以看出，对于这个问题，XGBoost、随机森林和极端随机森林，都是比较好的选择。</p><h2 id="总结一下"><a aria-hidden="true" tabindex="-1" href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/13#总结一下"><span class="icon icon-link"></span></a>总结一下</h2><p>好，到这里，我们关于集成学习的介绍就结束了，我们来做个总结。</p><p>集成学习模型是将多种同质或者异质的模型集成组合在一起，来形成更优的模型。而在这个过程的目标就是，减少机器学习模型的方差和偏差，找到机器学习模型在欠拟合和过拟合之间的最佳平衡点。</p><p>那么，怎么降低偏差呢？我们可以用Boosting方法，把梯度下降的思想应用在机器学习算法的优化上，使弱模型对数据的拟合逐渐增强。Boosting也常应用于决策树算法上，其中的GBDT 和XGBoost算法都非常受欢迎。</p><p>那怎么降低方差呢？这就要借助Bagging方法了。Bagging方法通常基于决策树，在随机生成数据集上训练出各种各样不同的树。其中的随机森林算法是在树分叉时，增加了对特征选择的随机性。随机森林在很多问题上都是一个很强的算法。我们可以把它作为一个基准，如果找到了比随机森林还优秀的模型，你就可以很欣慰了。</p><p>那么最后，如果让我在集成学习家族的算法里，给你推荐两种常用且效果好的算法，基于我个人的经验，我会觉得XGBoost、GBDT和随机森林是优于其它几种的。</p><h2 id="思考题"><a aria-hidden="true" tabindex="-1" href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/13#思考题"><span class="icon icon-link"></span></a>思考题</h2><p>好，在这一讲的最后，我给你留3个思考题：</p><ol><li>我在使用这些集成学习算法时，都只使用了默认参数，请你用GridSearchCV进行参数的网格搜索，找出针对这个问题更优的参数，训练出更好的模型；</li><li>请你绘出上述各个算法的混淆矩阵；</li><li>请你使用深度神经网络解决这个问题，看看是深层网络的性能好，还是集成学习的性能好？</li></ol><p>欢迎你在留言区和我分享你的观点，如果你认为这节课的内容有收获，也欢迎把它分享给你的朋友，我们下一讲再见！</p><p><img src="/blog-other/static/httpsstatic001geekbangorgresourceimagefe83fe84199aa2a33ef737b51a0809b3a183.da18e665.jpg" alt=""/></p></div><div class="__dumi-default-layout-footer-meta"><a target="_blank" rel="noopener noreferrer" href="https://github.com/GGwujun/blog/edit/master/ssrc/零基础实战机器学习/03.业务场景闯关篇/13.md">在 GitHub 上编辑此页<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="__dumi-default-external-link-icon"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a><span data-updated-text="最后更新时间：">2023/9/23 21:58:31</span></div></div></div></div>
	<script>
  window.g_useSSR = true;
  window.g_initialProps = {};
	</script>

    <script>
      (function () {
        if (!location.port) {
          (function (i, s, o, g, r, a, m) {
            i["GoogleAnalyticsObject"] = r;
            (i[r] =
              i[r] ||
              function () {
                (i[r].q = i[r].q || []).push(arguments);
              }),
              (i[r].l = 1 * new Date());
            (a = s.createElement(o)), (m = s.getElementsByTagName(o)[0]);
            a.async = 1;
            a.src = g;
            m.parentNode.insertBefore(a, m);
          })(
            window,
            document,
            "script",
            "//www.google-analytics.com/analytics.js",
            "ga"
          );
          ga("create", "UA-149864185-1", "auto");
          ga("send", "pageview");
        }
      })();
    </script>
    <script src="/blog-other/umi.js"></script>
  </body>
</html>
