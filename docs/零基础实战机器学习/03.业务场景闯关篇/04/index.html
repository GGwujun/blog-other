<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta
      name="viewport"
      content="width=device-width, initial-scale=1, maximum-scale=1, minimum-scale=1, user-scalable=no"
    />
    <link rel="shortcut icon" type="image/x-icon" href="/logo.png" />
    <link rel="stylesheet" href="/blog-other/umi.css" />
    <script>
      window.routerBase = "/blog-other";
    </script>
    <script>
      //! umi version: 3.5.41
    </script>
    <script>
      !(function () {
        var e =
            navigator.cookieEnabled && void 0 !== window.localStorage
              ? localStorage.getItem("dumi:prefers-color")
              : "auto",
          o = window.matchMedia("(prefers-color-scheme: dark)").matches,
          t = ["light", "dark", "auto"];
        document.documentElement.setAttribute(
          "data-prefers-color",
          e === t[2] ? (o ? t[1] : t[0]) : t.indexOf(e) > -1 ? e : t[0]
        );
      })();
    </script>
    <title>08 | 模型优化（上）：怎么用特征工程提高模型效率？ - 大师兄</title>
  </head>
  <body>
    <div id="root"><div class="__dumi-default-layout" data-route="/零基础实战机器学习/03.业务场景闯关篇/04" data-show-sidemenu="true" data-show-slugs="true" data-site-mode="true" data-gapless="false"><div class="__dumi-default-navbar" data-mode="site"><button class="__dumi-default-navbar-toggle"></button><a class="__dumi-default-navbar-logo" style="background-image:url(&#x27;/logo.png&#x27;)" href="/blog-other/">大师兄</a><nav><div class="__dumi-default-search"><input type="search" class="__dumi-default-search-input" value=""/><ul></ul></div><span>前端开发<ul><li><a href="/blog-other/说透低代码">说透低代码</a></li><li><a href="/blog-other/反爬虫兵法演绎20讲">反爬虫兵法演绎20讲</a></li></ul></span><span>产品与用户体验<ul><li><a href="/blog-other/大厂广告产品心法">大厂广告产品心法</a></li></ul></span><span>面试<ul><li><a href="/blog-other/技术面试官识人手册">技术面试官识人手册</a></li><li><a href="/blog-other/面试现场">面试现场</a></li></ul></span><span>杂谈<ul><li><a href="/blog-other/乔新亮的cto成长复盘">乔新亮的cto成长复盘</a></li><li><a href="/blog-other/互联网人的英语私教课">互联网人的英语私教课</a></li><li><a href="/blog-other/从0开始学游戏开发">从0开始学游戏开发</a></li><li><a href="/blog-other/全栈工程师修炼指南">全栈工程师修炼指南</a></li><li><a href="/blog-other/手机摄影">手机摄影</a></li><li><a href="/blog-other/物联网开发实战">物联网开发实战</a></li><li><a href="/blog-other/白话法律42讲">白话法律42讲</a></li><li><a href="/blog-other/说透5g">说透5g</a></li><li><a href="/blog-other/超级访谈对话张雪峰">超级访谈对话张雪峰</a></li><li><a aria-current="page" class="active" href="/blog-other/零基础实战机器学习">零基础实战机器学习</a></li></ul></span><div class="__dumi-default-navbar-tool"><div class="__dumi-default-dark"><div class="__dumi-default-dark-switch "></div></div></div></nav></div><div class="__dumi-default-menu" data-mode="site"><div class="__dumi-default-menu-inner"><div class="__dumi-default-menu-header"><a class="__dumi-default-menu-logo" style="background-image:url(&#x27;/logo.png&#x27;)" href="/blog-other/"></a><h1>大师兄</h1><p></p></div><div class="__dumi-default-menu-mobile-area"><ul class="__dumi-default-menu-nav-list"><li>前端开发<ul><li><a href="/blog-other/说透低代码">说透低代码</a></li><li><a href="/blog-other/反爬虫兵法演绎20讲">反爬虫兵法演绎20讲</a></li></ul></li><li>产品与用户体验<ul><li><a href="/blog-other/大厂广告产品心法">大厂广告产品心法</a></li></ul></li><li>面试<ul><li><a href="/blog-other/技术面试官识人手册">技术面试官识人手册</a></li><li><a href="/blog-other/面试现场">面试现场</a></li></ul></li><li>杂谈<ul><li><a href="/blog-other/乔新亮的cto成长复盘">乔新亮的cto成长复盘</a></li><li><a href="/blog-other/互联网人的英语私教课">互联网人的英语私教课</a></li><li><a href="/blog-other/从0开始学游戏开发">从0开始学游戏开发</a></li><li><a href="/blog-other/全栈工程师修炼指南">全栈工程师修炼指南</a></li><li><a href="/blog-other/手机摄影">手机摄影</a></li><li><a href="/blog-other/物联网开发实战">物联网开发实战</a></li><li><a href="/blog-other/白话法律42讲">白话法律42讲</a></li><li><a href="/blog-other/说透5g">说透5g</a></li><li><a href="/blog-other/超级访谈对话张雪峰">超级访谈对话张雪峰</a></li><li><a aria-current="page" class="active" href="/blog-other/零基础实战机器学习">零基础实战机器学习</a></li></ul></li></ul><div class="__dumi-default-dark"><div class="__dumi-default-dark-switch "><button title="Dark theme" class="__dumi-default-dark-moon "><svg viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="3854" width="22" height="22"><path d="M991.816611 674.909091a69.166545 69.166545 0 0 0-51.665455-23.272727 70.795636 70.795636 0 0 0-27.438545 5.585454A415.674182 415.674182 0 0 1 754.993338 698.181818c-209.594182 0-393.472-184.785455-393.472-395.636363 0-52.363636 38.539636-119.621818 69.515637-173.614546 4.887273-8.610909 9.634909-16.756364 14.103272-24.901818A69.818182 69.818182 0 0 0 384.631156 0a70.842182 70.842182 0 0 0-27.438545 5.585455C161.678429 90.298182 14.362065 307.898182 14.362065 512c0 282.298182 238.824727 512 532.38691 512a522.286545 522.286545 0 0 0 453.957818-268.334545A69.818182 69.818182 0 0 0 991.816611 674.909091zM546.679156 954.181818c-248.785455 0-462.941091-192-462.941091-442.181818 0-186.647273 140.637091-372.829091 300.939637-442.181818-36.817455 65.629091-92.578909 151.970909-92.578909 232.727273 0 250.181818 214.109091 465.454545 462.917818 465.454545a488.331636 488.331636 0 0 0 185.181091-46.545455 453.003636 453.003636 0 0 1-393.565091 232.727273z m103.656728-669.323636l-14.266182 83.781818a34.909091 34.909091 0 0 0 50.362182 36.770909l74.775272-39.563636 74.752 39.563636a36.142545 36.142545 0 0 0 16.174546 3.956364 34.909091 34.909091 0 0 0 34.210909-40.727273l-14.289455-83.781818 60.509091-59.345455a35.025455 35.025455 0 0 0-19.223272-59.578182l-83.61891-12.101818-37.376-76.101818a34.56 34.56 0 0 0-62.254545 0l-37.376 76.101818-83.618909 12.101818a34.909091 34.909091 0 0 0-19.246546 59.578182z m70.423272-64.698182a34.280727 34.280727 0 0 0 26.135273-19.083636l14.312727-29.090909 14.336 29.090909a34.257455 34.257455 0 0 0 26.135273 19.083636l32.046546 4.887273-23.272728 22.574545a35.234909 35.234909 0 0 0-10.007272 30.952727l5.46909 32.116364-28.625454-15.127273a34.490182 34.490182 0 0 0-32.302546 0l-28.695272 15.127273 5.469091-32.116364a35.141818 35.141818 0 0 0-9.984-30.952727l-23.272728-22.574545z" p-id="3855"></path></svg></button><button title="Light theme" class="__dumi-default-dark-sun "><svg viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="4026" width="22" height="22"><path d="M915.2 476.16h-43.968c-24.704 0-44.736 16-44.736 35.84s20.032 35.904 44.736 35.904H915.2c24.768 0 44.8-16.064 44.8-35.904s-20.032-35.84-44.8-35.84zM512 265.6c-136.704 0-246.464 109.824-246.464 246.4 0 136.704 109.76 246.464 246.464 246.464S758.4 648.704 758.4 512c0-136.576-109.696-246.4-246.4-246.4z m0 425.6c-99.008 0-179.2-80.128-179.2-179.2 0-98.944 80.192-179.2 179.2-179.2S691.2 413.056 691.2 512c0 99.072-80.192 179.2-179.2 179.2zM197.44 512c0-19.84-19.136-35.84-43.904-35.84H108.8c-24.768 0-44.8 16-44.8 35.84s20.032 35.904 44.8 35.904h44.736c24.768 0 43.904-16.064 43.904-35.904zM512 198.464c19.776 0 35.84-20.032 35.84-44.8v-44.8C547.84 84.032 531.84 64 512 64s-35.904 20.032-35.904 44.8v44.8c0 24.768 16.128 44.864 35.904 44.864z m0 627.136c-19.776 0-35.904 20.032-35.904 44.8v44.736C476.096 940.032 492.16 960 512 960s35.84-20.032 35.84-44.8v-44.736c0-24.768-16.064-44.864-35.84-44.864z m329.92-592.832c17.472-17.536 20.288-43.072 6.4-57.024-14.016-14.016-39.488-11.2-57.024 6.336-4.736 4.864-26.496 26.496-31.36 31.36-17.472 17.472-20.288 43.008-6.336 57.024 13.952 14.016 39.488 11.2 57.024-6.336 4.8-4.864 26.496-26.56 31.296-31.36zM213.376 759.936c-4.864 4.8-26.56 26.624-31.36 31.36-17.472 17.472-20.288 42.944-6.4 56.96 14.016 13.952 39.552 11.2 57.024-6.336 4.8-4.736 26.56-26.496 31.36-31.36 17.472-17.472 20.288-43.008 6.336-56.96-14.016-13.952-39.552-11.072-56.96 6.336z m19.328-577.92c-17.536-17.536-43.008-20.352-57.024-6.336-14.08 14.016-11.136 39.488 6.336 57.024 4.864 4.864 26.496 26.56 31.36 31.424 17.536 17.408 43.008 20.288 56.96 6.336 14.016-14.016 11.264-39.488-6.336-57.024-4.736-4.864-26.496-26.56-31.296-31.424z m527.168 628.608c4.864 4.864 26.624 26.624 31.36 31.424 17.536 17.408 43.072 20.224 57.088 6.336 13.952-14.016 11.072-39.552-6.4-57.024-4.864-4.8-26.56-26.496-31.36-31.36-17.472-17.408-43.072-20.288-57.024-6.336-13.952 14.016-11.008 39.488 6.336 56.96z" p-id="4027"></path></svg></button><button title="Default to system" class="__dumi-default-dark-auto "><svg viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="11002" width="22" height="22"><path d="M127.658667 492.885333c0-51.882667 10.24-101.717333 30.378666-149.162666s47.786667-88.064 81.92-122.538667 75.093333-61.781333 122.538667-81.92 96.938667-30.378667 149.162667-30.378667 101.717333 10.24 149.162666 30.378667 88.405333 47.786667 122.88 81.92 61.781333 75.093333 81.92 122.538667 30.378667 96.938667 30.378667 149.162666-10.24 101.717333-30.378667 149.162667-47.786667 88.405333-81.92 122.88-75.093333 61.781333-122.88 81.92-97.28 30.378667-149.162666 30.378667-101.717333-10.24-149.162667-30.378667-88.064-47.786667-122.538667-81.92-61.781333-75.093333-81.92-122.88-30.378667-96.938667-30.378666-149.162667z m329.045333 0c0 130.048 13.994667 244.394667 41.984 343.381334h12.970667c46.762667 0 91.136-9.216 133.461333-27.306667s78.848-42.666667 109.568-73.386667 54.954667-67.242667 73.386667-109.568 27.306667-86.698667 27.306666-133.461333c0-46.421333-9.216-90.794667-27.306666-133.12s-42.666667-78.848-73.386667-109.568-67.242667-54.954667-109.568-73.386667-86.698667-27.306667-133.461333-27.306666h-11.605334c-28.672 123.562667-43.349333 237.909333-43.349333 343.722666z" p-id="11003"></path></svg></button></div></div></div><ul class="__dumi-default-menu-list"><li><a href="/blog-other/零基础实战机器学习">零基础实战机器学习</a></li><li><a href="/blog-other/零基础实战机器学习/01.开篇词">01.开篇词</a><ul><li><a href="/blog-other/零基础实战机器学习/01.开篇词/01"><span>开篇词｜开发者为什么要从实战出发学机器学习？</span></a></li></ul></li><li><a href="/blog-other/零基础实战机器学习/02.准备篇">02.准备篇</a><ul><li><a href="/blog-other/零基础实战机器学习/02.准备篇/01"><span>01｜打好基础：到底什么是机器学习？</span></a></li><li><a href="/blog-other/零基础实战机器学习/02.准备篇/02"><span>02｜工具准备：安装并使用Jupyter Notebook</span></a></li><li><a href="/blog-other/零基础实战机器学习/02.准备篇/03"><span>03｜实战5步（上）：怎么定义问题和预处理数据？</span></a></li><li><a href="/blog-other/零基础实战机器学习/02.准备篇/04"><span>04｜ 实战5步（下）：怎么建立估计10万+软文点击率的模型？</span></a></li></ul></li><li><a aria-current="page" class="active" href="/blog-other/零基础实战机器学习/03.业务场景闯关篇">03.业务场景闯关篇</a><ul><li><a href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/01"><span>05 | 数据探索：怎样从数据中找到用户的RFM值？</span></a></li><li><a href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/02"><span>06 | 聚类分析：如何用RFM给电商用户做价值分组画像？</span></a></li><li><a href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/03"><span>07｜回归分析：怎样用模型预测用户的生命周期价值？</span></a></li><li><a aria-current="page" class="active" href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/04"><span>08 | 模型优化（上）：怎么用特征工程提高模型效率？</span></a></li><li><a href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/05"><span>09｜模型优化（中）：防止过拟合，模型也不能太精细</span></a></li><li><a href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/06"><span>10｜模型优化（下）：交叉验证，同时寻找最优的参数</span></a></li><li><a href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/07"><span>11｜深度学习（上）：用CNN带你认识深度学习</span></a></li><li><a href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/08"><span>12｜深度学习（中）：如何用RNN预测激活率走势？</span></a></li><li><a href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/09"><span>13｜深度学习（下）：3招提升神经网络预测准确率</span></a></li><li><a href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/10"><span>14｜留存分析：哪些因素会影响用户的留存率？</span></a></li><li><a href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/11"><span>15｜二元分类：怎么预测用户是否流失？从逻辑回归到深度学习</span></a></li><li><a href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/12"><span>16｜性能评估：不平衡数据集应该使用何种评估指标？</span></a></li><li><a href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/13"><span>17｜集成学习：机器学习模型如何“博采众长”?</span></a></li><li><a href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/14"><span>18 | 增长模型：用XGBoost评估裂变海报的最佳受众群体</span></a></li></ul></li><li><a href="/blog-other/零基础实战机器学习/04.持续赋能篇">04.持续赋能篇</a><ul><li><a href="/blog-other/零基础实战机器学习/04.持续赋能篇/01"><span>19 | 胸有成竹：如何快速定位合适的机器学习算法？</span></a></li><li><a href="/blog-other/零基础实战机器学习/04.持续赋能篇/02"><span>20 | 模型部署：怎么发布训练好的机器学习模型？</span></a></li><li><a href="/blog-other/零基础实战机器学习/04.持续赋能篇/03"><span>21｜持续精进：如何在机器学习领域中找准前进的方向？</span></a></li></ul></li><li><a href="/blog-other/零基础实战机器学习/05.结束语">05.结束语</a><ul><li><a href="/blog-other/零基础实战机器学习/05.结束语/01"><span>一套习题，测出你对机器学习的掌握程度</span></a></li><li><a href="/blog-other/零基础实战机器学习/05.结束语/02"><span>结束语 | 可以不完美，但重要的是马上开始</span></a></li></ul></li><li><a href="/blog-other/零基础实战机器学习/summary">零基础实战机器学习</a></li></ul></div></div><ul role="slug-list" class="__dumi-default-layout-toc"><li title="对数值型特征的缩放" data-depth="2"><a href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/04#对数值型特征的缩放"><span>对数值型特征的缩放</span></a></li><li title="对类别型特征的变换：虚拟变量和独热编码" data-depth="2"><a href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/04#对类别型特征的变换虚拟变量和独热编码"><span>对类别型特征的变换：虚拟变量和独热编码</span></a></li><li title="对数值型特征的离散化：分桶" data-depth="2"><a href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/04#对数值型特征的离散化分桶"><span>对数值型特征的离散化：分桶</span></a></li></ul><div class="__dumi-default-layout-content"><div class="markdown"><h1 id="08--模型优化上怎么用特征工程提高模型效率"><a aria-hidden="true" tabindex="-1" href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/04#08--模型优化上怎么用特征工程提高模型效率"><span class="icon icon-link"></span></a>08 | 模型优化（上）：怎么用特征工程提高模型效率？</h1><p>你好，我是黄佳。欢迎来到零基础实战机器学习。</p><p>经历过了前面几个项目实战，你是不是想告诉我说，佳哥，机器学习的流程也很简单，似乎只要选个模型并重复5个步骤，就可以搞定任何数据集。</p><p>看起来是这样，不过也没有这么简单。模型，谁都可以构建，但是，如何让模型的性能更优，才是我们真正的考验。今天，我们就来谈一个与模型优化相关的重要内容，也就是特征工程。</p><p>人们常说，<strong>数据和特征决定了机器学习的上限，而模型和算法只是无限逼近这个上限而已</strong>。请你想一想，在那些给定数据集的机器学习竞赛中，高手们为什么能在数据集相同、模型也类似的前提下，让模型达到一个很高的预测准确率？其实，就是因为他们大都通过漂亮的特征工程，提高了机器学习的上限。</p><p>特征工程说起来很简单，就是指**优化数据集的特征，使机器学习算法更起作用的过程，**但用好特征工程并不容易。对于很多初学者来说，常常感觉特征工程实现起来种类繁多，五花八门，不知道怎么下手。今天这节课我就来带你解决这一难题。</p><p>根据我这么多年的经验和理解，特征工程其实是有章可循的。总结起来，几乎所有的特征工程，都逃不开三个基本的思路：**特征选择，特征变换和特征构建。**只要你掌握了它们，以后每拿到一个新的问题和新的数据集时，都可以从这三个维度去分析。这样，你就不至于无从下手，你的特征工程也不会有大的偏差。</p><p>那你肯定很想了解它们都是怎么回事儿，别着急，现在我就跟你一一道来。</p><h1 id="特征选择"><a aria-hidden="true" tabindex="-1" href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/04#特征选择"><span class="icon icon-link"></span></a>特征选择</h1><p>其实，在一个数据集中，每个特征在标签预测或分类过程中发挥的作用其实都不同。对于那些没作用和作用小的数据，我们就可以删掉，来降低数据的维度，节省模型拟合时的计算空间。这就是特征选择。</p><p>那么，怎么看哪个特征作用大，哪个作用小？我给你介绍一种常用的方法：相关性热力图。就拿我们上节课的项目来说，在我们预测LTV的数据集中，一共有3个特征，分别是“R值”、“F值”和“M值”，还有1个标签“LTV”。这时候，我们就可以通过相关性热力图来看看，哪些特征和标签的相关性更高。</p><p>具体的实现过程，就是用corr()方法求出数据集中所有字段之间的相关性，然后用seaborn的heatmap方法，将它以热力图的形式呈现出来：</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain"># 对所有的标签和特征两两显示其相关性热力图(heatmap)</span></div><div class="token-line"><span class="token plain">    import seaborn as sns</span></div><div class="token-line"><span class="token plain">    sns.heatmap(df_LTV.corr(), cmap=&quot;YlGnBu&quot;, annot = True)</span></div></pre></div><p>输出如下：</p><p><img src="/blog-other/static/httpsstatic001geekbangorgresourceimage86fe869fe6d5eb03a8b3014dafa8c12b39fe.2ba689bb.jpg" alt=""/></p><p>那么怎么去看这个相关性热力图呢？</p><p>首先，我们只要聚焦于LTV标签和R、F、M三个特征之间的关系就可以了，用户码这个字段和LTV肯定是不相关的。</p><p>然后我们再来看这张图中方格里的数字，这类数字叫做皮尔逊相关系数，表示两个变量间的线性相关性，数值越接近1，就代表相关性越大。那么，自己和自己的相关性当然就是1了。</p><p>接下来，你需要知道的是，相关性是有正负的。正值说明是正相关，负值说明是负相关，从图中我们看到，R值和年度LTV的相关性为-0.23，就表明这个数据集中新进度（R）数字越大，年度LTV就越小。你可以想一想这是为什么。</p><p>此外，我们还会发现，M值、F值和LTV的相关度比较高，而R值和LTV的相关度比较低。这时候，我们就可以选择丢弃“R值”这个字段。这就是一个特征选择。</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">X_train_less_feature = X_train.drop([&#x27;R值&#x27;], axis=1) #特征训练集</span></div><div class="token-line"><span class="token plain">    X_valid_less_feature = X_valid.drop([&#x27;R值&#x27;], axis=1) #特征验证集</span></div><div class="token-line"><span class="token plain">    model_lr_less_feature = LinearRegression() #创建线性回归模型</span></div><div class="token-line"><span class="token plain">    model_lr_less_feature.fit(X_train_less_feature, y_train) #拟合线性回归模型</span></div><div class="token-line"><span class="token plain">    print(&#x27;测试集上的R平方分数-线性回归: %0.4f&#x27; % r2_score(y_valid, model_lr.predict(X_valid)))</span></div><div class="token-line"><span class="token plain">    print(&#x27;测试集上的R平方分数-少R值特征的线性回归: %0.4f&#x27; % r2_score(y_valid, model_lr_less_feature.predict(X_valid_less_feature)))</span></div></pre></div><p>输出结果如下：</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">测试集上的R平方分数-线性回归: 0.4410</span></div><div class="token-line"><span class="token plain">    测试集上的R平方分数-少R值特征的线性回归: 0.4356</span></div></pre></div><p>在这段代码中，我们用同样的线性回归模型进行拟合、评估，唯一的区别就是特征减少了一个R值。你会发现，在这种情况下训练出来的模型，得分会低一点点，不过变化并不太显著，这就说明“R值”这个特征对函数最终的性能影响确实不大。但是，如果你丢掉的是F值或M值，那么模型的分数将显著降低。</p><p>尽管如此，我还是要说明一下，在这个项目的模型训练中，我并不建议你进行这样的特征选择。因为原始的特征数目已经很少了，要是再把R值这样的特征丢弃，显然不合逻辑。我刚才做这样的尝试，只是想为你展示特征选择的思路。</p><p>在上面的过程中，我们通过“相关性热力图”，观察了每个特征和标签之间的关系，并手工选择了特征。那么你可能会问，难道没有工具可以帮我们自动进行特征选择吗？当然有。</p><p>在sklearn的feature_selection模块中，有很多自动特征选择工具。这里我给你介绍一个常用的单变量特征选择工具，SelectKBest。SelectKBest的原理和使用都非常简单，它是对每个特征和标签之间进行统计检验，根据X 和 y 之间的相关性统计结果，来选择最好的K个特征，并返回。</p><p>对于我们的LTV预测数据集来说，我们可以这样调用SelectKBest来选择特征。</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">from sklearn.feature_selection import SelectKBest, mutual_info_regression  #导入特征选择工具</span></div><div class="token-line"><span class="token plain">    selector = SelectKBest(mutual_info_regression, k = 2) #选择最重要的两个特征</span></div><div class="token-line"><span class="token plain">    selector.fit(X, y) #用特征选择模型拟合数据集</span></div><div class="token-line"><span class="token plain">    X.columns[selector.get_support()] #输出选中的两个特征</span></div></pre></div><p>输出如下：</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">Index([&#x27;F值&#x27;, &#x27;M值&#x27;], dtype=&#x27;object&#x27;)</span></div></pre></div><p>在调用SelectKBest的过程中，我们是指定了参数score_func = mutual_info_regression，其中，mutual_info_regression是用于对连续型标签进行特征评分。如果标签是离散型的，那么就是分类问题，我们就要用过mutual_info_classif来评分了。</p><p>从输出的结果来看，F值和M值的分数比R值高。所以，在K=2的情况下，我们就需要在这3个特征中舍弃一个，这时候R值就要被舍弃。这个结果和我们前面观察到的一致。</p><p>总体来说，单变量特征选择比较直接，速度快，并且独立于模型。但是，你有没有想过这种做法可能会有一个问题？那就是，如果一个特征表面上和标签不大相关，但是在与另一个特征组合之后，才会具有信息量，那么上面的做法可能会让你错误地舍弃这个特征。</p><p>那么，有没有一种考虑了各个特征之间的组合后，才做出特征选择的工具呢？有。不过，这样的多变量组合型特征选择工具必须结合具体的模型存在，也就是说，当所有特征都被输入模型进行拟合时，在这个过程中才能评估出最不重要的特征，然后再进行特征选择。</p><p>在sklearn的feature_selection里，有下列几种在拟合特定模型时进行特征选择的工具，你可以选择使用：</p><p><img src="/blog-other/static/httpsstatic001geekbangorgresourceimage2a722ayy82ffecbe26bce60ec753f2463672.07d7db4b.jpg" alt=""/></p><p>除了这些特征选择工具，我认为“数据降维”也可以归入到特征选择中。当然，也有人把降维视为一种独立的特征工程类型。</p><p>那什么是数据降维呢? 其实就是通过特定算法，把多维特征压缩成低维的特征，也就是通过算法实现特征选择，减少特征的数目。常见的降维算法有两种：主成分分析法（PCA）和线性判别分析（LDA）。PCA是一种无监督的降维方法，而LDA是一种有监督的降维方法。出于咱们的课程定位，这些降维算法我们并不会过多涉及。</p><p>另外，还有一种方式，就是用深度学习来进行特征选择，这在计算机视觉领域十分普遍。因为深度学习具有自动学习特征的能力。就拿图片识别来说，当图片被输入到卷积神经网络后，网络会自动形成一条条特征通道，选择提取有用的信息来进行最终的目标模型训练。</p><p>不过，神经网络中的这些特征通道是怎么形成的，我们目前还没有很好的方式用数学手段去推导、确定，它对于我们来说就像一个黑箱。</p><p>总而言之，特征选择的目标是，尽量保持对模型训练有效的信息，与此同时减少数据集的特征数量。</p><p>除了特征选择外，还有一种特征工程是在原有特征的基础上进行加工，没有减少特征数，这就是特征变换。</p><h1 id="特征变换"><a aria-hidden="true" tabindex="-1" href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/04#特征变换"><span class="icon icon-link"></span></a>特征变换</h1><p>特征变换的整体目标是让原始特征变得机器学习模型可用，甚至是更好用。</p><p>要搞清楚特征变换，我们就得先了解一下特征的类型。其实，特征和标签一样，也分为连续和离散两类。像分数、点击量这些，就属于连续特征（continuous feature）；而离散特征（discrete feature），也叫类别特征（categorical feature），像男生、女生，或者说北京、上海、深圳、广州等等，这些都属于离散特征。</p><p>不同的特征类型，有不同的特征变换方式。对连续特征来说，我们最常见的特征变换就是特征缩放（feature scaling），也就是改变特征的分布或者压缩特征的区间。因为有很多模型都喜欢范围比较小、分布有规律的数据，比如采用梯度下降方法求解最优化的模型，较小的数值分布区间能够提升收敛速度，还有SVM、KNN、神经网络等模型，都要求对特征进行缩放。</p><h2 id="对数值型特征的缩放"><a aria-hidden="true" tabindex="-1" href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/04#对数值型特征的缩放"><span class="icon icon-link"></span></a>对数值型特征的缩放</h2><p>在sklearn中，特征缩放方法很多：</p><p><img src="/blog-other/static/httpsstatic001geekbangorgresourceimageb5d6b5083f1d8e253120b8c27bd940597bd6.889ddd8b.jpg" alt=""/></p><p>下面是各个特征缩放方法从原始特征到新特征的缩放效果图，你可以看看：</p><p><img src="/blog-other/static/httpsstatic001geekbangorgresourceimage55a655a8yy57a5e66f82171b0f53b17d50a6.10258724.png" alt="" title="四种特征缩放器效果图"/></p><p>下面，我们选择其中最常见的两个特征缩放工具StandardScaler和MinMaxScaler，来预测用户LTV，比较一下它们的优劣。你要注意，这里所谓的优劣，仅针对于这个特定数据集和特定问题而言。</p><p>由于大部分的代码和实战中介绍过的相同，我这里就不再重复了。下面我只是展示和特征工程相关的代码，你可以在<a target="_blank" rel="noopener noreferrer" href="https://github.com/huangjia2019/geektime/tree/main/%E5%8F%98%E7%8E%B0%E5%85%B308">这里<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="__dumi-default-external-link-icon"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>下载到完整的代码。</p><p>首先，我们调用StandardScaler，进行数值特征的标准化缩放，这个缩放将形成正态分布的新特征。</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">from sklearn.preprocessing import StandardScaler #导入标准化缩放器</span></div><div class="token-line"><span class="token plain">    scaler = StandardScaler() #创建标准化缩放器</span></div><div class="token-line"><span class="token plain">    X_train_standard = scaler.fit_transform(X_train) #拟合并转换训练集数据</span></div><div class="token-line"><span class="token plain">    X_valid_standard = scaler.transform(X_valid) #转换验证集数据</span></div><div class="token-line"><span class="token plain">    X_test_standard = scaler.transform(X_test) #转换测试集数据</span></div></pre></div><p>在上面的代码中，你要特别注意，在创建标准化缩放器之后，我们对于训练集使用了fit_transform这个API，这是fit和transform两个API的整合，它的意思是先根据训练集拟合数据，找到合适的标准化参数，然后再把参数应用在训练集上，给数据做缩放。</p><p>而在验证集和测试集上，我们只使用transform这个API，来通过从训练集中得到的参数，来转换数据，这个步骤中就没有fit的过程，这是因为对于模型来说，验证集和测试集是新的看不见的数据，因此在训练之前或训练期间它是不应该被访问的，使用来自验证集和测试集的任何信息都属于数据泄露，会导致评估性能的潜在偏差。</p><p>这也就是为什么特征缩放必须在拆分完训练集和测试集后进行，因为它的参数只能来自训练集的数据。</p><p>然后，我们用缩放后的特征训练模型，得到一个随机森林模型model_rfr_standard。这里的rfr是一个缩写，代表random forest refressor，也就是随机森林回归。</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">model_rfr_standard = RandomForestRegressor() #创建随机森林回归模型</span></div><div class="token-line"><span class="token plain">    model_rfr_standard.fit(X_train_standard, y_train) #拟合随机森林模型</span></div></pre></div><p>讲完了StandardScaler，我们再用MinMaxScaler来预测用户LTV。进行数值特征的归一化缩放。所谓“归一化”，就是把特征的值压缩到给定的最小值和最大值，比如0-1之间。如果有负值的话，那就是-1到1之间。</p><p>与标准化的过程相同，在对验证集和测试集进行归一化时，我们也应该按原样，使用先前从训练集中获得的归一化参数，而不是在验证集和测试集上重新计算它们。</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">from sklearn.preprocessing import MinMaxScaler #导入归一化缩放器</span></div><div class="token-line"><span class="token plain">    scaler = MinMaxScaler() #创建归一化缩放器</span></div><div class="token-line"><span class="token plain">    X_train_minmax = scaler.fit_transform(X_train) #拟合并转换训练集数据</span></div><div class="token-line"><span class="token plain">    X_valid_minmax = scaler.transform(X_valid) #转换验证集数据</span></div><div class="token-line"><span class="token plain">    X_test_minmax = scaler.transform(X_test) #转换测试集数据</span></div></pre></div><p>然后，我们用缩放之后的特征训练模型，得到一个随机森林模型model_rfr_minmax。</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">model_rfr_minmax = RandomForestRegressor() #创建随机森林回归模型</span></div><div class="token-line"><span class="token plain">    model_rfr_minmax.fit(X_train_minmax, y_train) #拟合随机森林模型</span></div></pre></div><p>那到这里，我们就得到了两个随机森林模型：model_rfr_standard和model_rfr_minmax。我们拿这两个模型，和不使用特征缩放训练出来的模型，整体做一个对比，看看这三种模型在验证集上的分数怎么样。这里我把评估的结果用柱状图来展示了（对应的代码你可以参见这个<a target="_blank" rel="noopener noreferrer" href="https://github.com/huangjia2019/geektime/tree/main/%E5%8F%98%E7%8E%B0%E5%85%B308">链接<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="__dumi-default-external-link-icon"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>）：</p><p><img src="data:image/png;base64,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" alt=""/></p><p>可以看到，对于预测用户LTV这个项目来说，采用特征缩放，尤其是MinMaxScaler，模型在验证集上会得到较优的结果。</p><p>你也许会问，数值型特征常见的变换是特征缩放，那么类别型特征呢？其实对于类别型特征来讲，最常见的变换方式是通过虚拟变量（也叫哑编码或者哑变量）把机器不能读取的类别文本，转换成一个个的0、1值。</p><h2 id="对类别型特征的变换虚拟变量和独热编码"><a aria-hidden="true" tabindex="-1" href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/04#对类别型特征的变换虚拟变量和独热编码"><span class="icon icon-link"></span></a>对类别型特征的变换：虚拟变量和独热编码</h2><p>把类别特征转换成机器可以读取的编码，也非常简单。如果数据表中的字段值是“男”、“女”这样的数据，我们就用下面的代码直接转换成0、1值即可。</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">df[&#x27;性别&#x27;].replace(to_replace=&#x27;女&#x27;, value=0, inplace=True)</span></div><div class="token-line"><span class="token plain">    df[&#x27;性别&#x27;].replace(to_replace=&#x27;男&#x27;, value=1, inplace=True)</span></div></pre></div><p>对于两个以上的分类，pandas编码有一种非常简单的方法，就是get_dummies函数。get_dummies函数会自动变换所有具有对象类型（比如字符串）的列或所有分类的列，而分类特征的每个可能取值都会被扩展为一个新特征，并且每一个新特征只有0、1两种取值。这个过程就是虚拟变量的生成过程，你看看这张图就会比较清楚了。</p><p><img src="/blog-other/static/httpsstatic001geekbangorgresourceimage236023d727fc9715919d7ebd40678af92d60.f2ab2b0c.png" alt="" title="对于自然语言处理中的分词过程，这样的编码转换是必须的"/></p><p>下面我们就把上一个项目中的订单数据集里的“城市”转化为虚拟变量。对于这一步，其实我在之前的课程中给你留过作业，并给出了“提示”，这里我就用和提示不大一样的代码，来实现相同的功能。</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain"># 把多分类字段转换为二分类虚拟变量 </span></div><div class="token-line"><span class="token plain">    category_features = [&#x27;城市&#x27;] #要转换的特征列表</span></div><div class="token-line"><span class="token plain">    df_sales = pd.get_dummies(df_sales, drop_first=True, columns=category_features) #创建哑变量</span></div><div class="token-line"><span class="token plain">    df_sales #显示数据</span></div></pre></div><p>输出如下：</p><p><img src="/blog-other/static/httpsstatic001geekbangorgresourceimage100510742aa69896ebd349121ae93b50dd05.f6a70811.png" alt=""/></p><p>可以看到，原来的城市字段，变成了多个二分类字段，比如城市_北京、城市_成都等，并且每个字段只有0、1值，这样的编码格式就可以被机器识别。</p><p>这里呢，我要请你特别注意一下drop_first这个参数。这个参数实际上控制着get_dummies函数返回的结果，值为True返回结果是虚拟变量（Dummy Variable），值为False则返回独热编码（ One Hot Encoding）。</p><p>独热编码与虚拟变量非常相似，它们的不同之处在于：在虚拟编码方案中，当特征具有 m 个不同类别标签时，我们将得到 m-1 个二进制特征，作为基准的特征被完全忽略；而在独热编码方案中，我们将得到 m 个二进制特征。因此，你仔细观察上面get_dummies的结果，就会发现“城市_上海”这个特征没有被生成。而如果你把drop_first设为False，“城市_上海”就会出现。</p><p>那么，为什么要有这样的区别呢？主要有两个原因。第一个原因是，如果有N个特征，并且前N-1个特征的值是已知的，那么第N个特征的值也就知道了。因此，独热编码有冗余，虚拟变量没有冗余。举个例子，对于用户来说，如果其它所有城市的值都是0，唯独“上海”这个字段的值不知道，我们自然就能推知这个用户是属于上海这个城市，因为这是仅有的可能性了。</p><p>第二个原因是，独热编码的这种冗余会导致共线性问题，也就是自变量之间存在高度相关关系，不总是相互独立的，从而使模型参数估计不准确。不过，这也意味着，独热编码可以直接从“１”值看出所对应的类别，而虚拟变量需要进行推理。因此独热编码比较直观，虚拟变量没有那么直观。</p><p>那我们应该在什么时候使用虚拟变量，在什么时候使用独热编码呢？如果线性模型有截距项，就使用虚拟变量；如果线性模型无截距项，那么使用独热编码。</p><p>此外，在线性模型有截距项的情况下，如果使用正则化，那么也推荐使用独热编码，因为正则化能处理多余的自由度，可以约束参数；如果不使用正则化，那么就使用虚拟变量，这样多余的自由度都被统摄到截距项intercept里去了。关于正则化的进一步说明，我会在下一讲详细介绍。</p><p>上面所说的虚拟变量和独热编码是对类别型特征的处理，不过在某些情况下，我们还需要把数值型特征离散化。</p><h2 id="对数值型特征的离散化分桶"><a aria-hidden="true" tabindex="-1" href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/04#对数值型特征的离散化分桶"><span class="icon icon-link"></span></a>对数值型特征的离散化：分桶</h2><p>你可能会奇怪为什么要对特征做离散化处理？这是因为，当特征的数量级跨度过大，而且与标签的关系又非线性的时候，模型可能只对大数量级的特征值敏感，也就是说模型可能会向大特征值的那一侧倾斜。另外，模型的运算速度也会受到影响。</p><p>比如说，一个特征的数据值为[3.5, 2.7, 16.9, 5.5, 98]，这里的“98”明显偏离其他数据，很容易影响到模型的效果。这时候我们就可以把这些数值做个离散化，比如把小于5的值记为“0”，大于5且小于10的值记为“1”，大于10的值记为“2”，那么[3.5, 2.7, 16.9, 5.5, 98]就可以变成0、1、2这样的离散值，也就是[0，0，2，1，2]，这不仅能减弱像“98”这样的异常数据的权重，还能提高模型的运算速度。</p><p>我们在这里用的方式呢，就叫做分桶，分桶也叫分箱，就是指将连续型特征离散化为一系列的离散值。而这里的0、1、2呢，就是我们说的“桶”或者“箱”了。</p><p>对数值进行分桶，我们首先要确定两点：一是桶的数量，二是把什么范围的数据分成一个桶，也就是桶的宽度是多少。在这个过程中，常规的做法有三种：</p><ol><li><p>等距分桶：每个桶的宽度固定，如 0-99，100-199，200-299等。这种方式适合样本分布比较均匀的情况，如果样本分布不均，就容易出现有的桶多、有的桶少的情况。</p></li><li><p>等频分桶：每个桶有一样多的样本，但可能出现数值相差很大的样本放在同一个桶的情况。</p></li><li><p>模型分桶：利用模型找到最佳分桶。比如决策树模型，它本身就具有对连续型特征切分的能力，因此我们可以利用分割点进行特征离散化。再比如聚类模型，可以将连续性特征分成多个类别。在之前的用户画像项目中，我们对R值、F值、M值进行聚类，就是一种模型分桶操作，即把连续的数值切分成这三维度的离散类别。</p></li></ol><p>到这里，我们就了解了两种特征工的基本思路，一种是通过特征选择减少特征的维度，另一种是通过特征变换加工原始特征。你可能会问我，有没有什么方法能根据原始数据创造出新的特征呢？</p><p>自然是有的，这就是第三种特征工程类型：特征构建。</p><h1 id="特征构建"><a aria-hidden="true" tabindex="-1" href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/04#特征构建"><span class="icon icon-link"></span></a>特征构建</h1><p>特征构建是整个特征工程领域最具创造力的部分，也是我觉得在数据预处理环节中最有意思的地方。因为它完全没有一定之规，全凭借你的经验、领域知识和创造力。就像我们在获客关的项目实战里，从原始的订单数据集中，我们经过整理和组合原始数据，求出了三个完全不存在于原始数据集中的新值：R值、F值和M值，<strong>这就是一个典型的特征构建</strong>。</p><p>为什么我们知道要构建这三个值？就是因为我们具有运营领域的经验和相关知识，知道R值、F值和M值对用户分组画像是重要的因子，能够输入到聚类模型和回归模型中去。</p><p>所以，要想把原始数据集中的特征工程做好，就要不断积累经验和知识，展开自己的想象力，看看可以构建出什么样有用的新特征，能让机器学习模型学得更好。</p><p>这里我再给你举一个例子。假设我们现在有一个航班的旅客订单信息数据集，记录了几年内每一天航班的旅客订票情况。通过这个数据集，我们要帮航空公司构建一个模型，来预测未来某天的客流量。那么，你能想到什么特征工程方法，有可能提高模型的效率？</p><p>其实，我们可以根据“订单日期”这个字段，再人工添加一个新字段，来<strong>标明每一天的具体航班是在国家公休假日的之前、之中还是之后，或并不靠近公休假日</strong>。这个方法，其实是把与预测客流量这个任务的相关先验知识编码到了特征中，以辅助机器学习算法理解为什么流量会出现可能的波动。</p><p>当然，添加一个新特征并不意味着机器学习算法肯定会用到它，即使模型发现假日信息和客流量没啥关联，那也无伤大雅。但是，如果真的有关联，这个新特征就会提高模型的预测准确率，尤其是当预测未来公休假日附近的客流量时，会更准。</p><p>为了让你进一步理解特征构建的作用，我再用一个例子，通过程序代码和示意图来直观地给你进行展示。这次，我们读入一个简单的数据集“特征构建示意数据集”（你可以在<a target="_blank" rel="noopener noreferrer" href="https://github.com/huangjia2019/geektime/tree/main/%E5%8F%98%E7%8E%B0%E5%85%B308">这里<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="__dumi-default-external-link-icon"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>下载数据集），来看看特征X和标签Y之间的关系，然后思索一下怎么拟合二者。</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">import pandas as pd #导入Pandas</span></div><div class="token-line"><span class="token plain">    import numpy as np #导入NumPy</span></div><div class="token-line"><span class="token plain">    import matplotlib.pyplot as plt #导入绘图工具</span></div><div class="token-line"><span class="token plain">    df = pd.read_csv(&#x27;特征构建示意数据集.csv&#x27;) #导入数据</span></div><div class="token-line"><span class="token plain">    plt.scatter(df.X, df.Y) #X，Y散点图</span></div></pre></div><p>输出显示，这个数据集中的特征X和标签y呈现一种符合回归模型的趋向。</p><p><img src="data:image/png;base64,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" alt=""/></p><p>如果我们用线性回归进行建模，就会得到一个线性回归模型：</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">from sklearn.model_selection import train_test_split #导入train_test_split </span></div><div class="token-line"><span class="token plain">    df_x = df[&#x27;X&#x27;].to_frame() #特征集</span></div><div class="token-line"><span class="token plain">    df_y = df[&#x27;Y&#x27;] #标签集</span></div><div class="token-line"><span class="token plain">    X_train, X_test, y_train, y_test = train_test_split(df_x,df_y,test_size=0.3, random_state = 0) #拆分数据集</span></div><div class="token-line"><span class="token plain">    from sklearn.linear_model import LinearRegression #导入LinearRegression</span></div><div class="token-line"><span class="token plain">    model = LinearRegression() #创建模型</span></div><div class="token-line"><span class="token plain">    model.fit(X_train, y_train) #拟合模型</span></div><div class="token-line"><span class="token plain">    plt.scatter(df.X, df.Y) #散点图</span></div><div class="token-line"><span class="token plain">    plt.plot(X_test, model.predict(X_test),linestyle=&#x27;--&#x27;, color = &#x27;red&#x27;) #显示拟合曲线</span></div></pre></div><p>输出这个模型，可以看到这个回归线并不能很好地拟合从X到Y的关系：</p><p><img src="data:image/png;base64,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" alt=""/></p><p>那怎么办呢？其实，我们从图中可以观察到，X-Y之间的关系其实更接近多项式回归（polynomial regression）中的二项式回归，也就是说，Y是X的二次函数。那么，我们就在X的基础上做个平方，构建出一个新特征。</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">X2_train = X_train.copy() #新特征训练集</span></div><div class="token-line"><span class="token plain">    X2_test = X_test.copy() #新特征测试集</span></div><div class="token-line"><span class="token plain">    X2_train[&#x27;X2&#x27;] = X2_train[&#x27;X&#x27;]**2 #构建新特征X2</span></div><div class="token-line"><span class="token plain">    X2_test[&#x27;X2&#x27;] = X2_test[&#x27;X&#x27;]**2 #构建新特征X2</span></div><div class="token-line"><span class="token plain">    model2 = LinearRegression() #创建新模型</span></div><div class="token-line"><span class="token plain">    model2.fit(X2_train, y_train) #拟合新模型</span></div><div class="token-line"><span class="token plain">    plt.scatter(df.X, df.Y) #散点图</span></div><div class="token-line"><span class="token plain">    plt.scatter(X_test, model2.predict(X2_test), linestyle=&#x27;--&#x27;, color = &#x27;red&#x27;) #新拟合函数曲线</span></div></pre></div><p>这里，我们还是用一样的模型来拟合，并显示原始特征X和预测值之间的关系。这时候我们发现，拟合曲线更趋近于X和Y的真实关系：</p><p><img src="/blog-other/static/httpsstatic001geekbangorgresourceimage3eyy3edaa26d8236d26a594d0dc216928cyy.f92c0385.png" alt=""/></p><p>是不是很奇妙呢？希望通过这个小例子，你能理解：在实践中，我们所使用的特征，以及特征与方法之间的匹配，通常都是让机器学习模型能够有良好表现的最重要因素。</p><h1 id="总结一下"><a aria-hidden="true" tabindex="-1" href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/04#总结一下"><span class="icon icon-link"></span></a>总结一下</h1><p>好了，这节课到这里就结束了，我给你总结了三类重要的特征工程。其中，特征选择可以减少特征的维度，特征变换则能把原始特征塑造的更容易被机器学习模型使用，特征构建则需要你激发极大的创造力，以原始数据为基础去发现对建模有用的新特征。</p><p><img src="/blog-other/static/httpsstatic001geekbangorgresourceimage8db68df9c3f583cd31d341f2053349ac75b6.b8425451.jpg" alt=""/></p><p>在这一讲中，我特别为你示范了不少精巧的特征工程小示例，所有的代码你都可以在<a target="_blank" rel="noopener noreferrer" href="https://github.com/huangjia2019/geektime/tree/main/%E5%8F%98%E7%8E%B0%E5%85%B308">这里<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="__dumi-default-external-link-icon"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>找到。不过师傅领进门，修行在个人，更多特征工程的知识和应用，还有待于你在实践中去继续挖掘。</p><h1 id="思考题"><a aria-hidden="true" tabindex="-1" href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/04#思考题"><span class="icon icon-link"></span></a>思考题</h1><p>那么，这一讲我给你留三道思考题：</p><p>1.我在前面使用了StandardScaler工具和MinMaxScaler工具做特征缩放，请你用一下别的特征缩放器，看看适不适合我们这个数据集。</p><p>2.Sklearn的OneHotEncoder工具和Pandas的get_dummies类似，也可以把整个数据集的字段或者指定的特征字段转换为虚拟变量。请你试一试这个工具。</p><p><strong>提示</strong>：这个题目较难，涉及数组形状变换。如果遇到麻烦，可以试着上网搜索一下解决方案。</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">from sklearn.preprocessing import OneHotEncoder #导入OneHotEncoder工具</span></div><div class="token-line"><span class="token plain">    encoder = OneHotEncoder(sparse=False)</span></div><div class="token-line"><span class="token plain">    ...</span></div><div class="token-line"><span class="token plain">    df_city = pd.DataFrame(df_city, columns=encoder.get_feature_names())</span></div><div class="token-line"><span class="token plain">    ...</span></div></pre></div><p>OneHotEncoder输出的结果：</p><p><img src="data:image/png;base64,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" alt=""/></p><p>3.你在工作中用特征工程构建过新特征吗？有没有比较巧妙的特征工程可以给大家分享呢？如果你还没有做过特征工程，那么请你谈一谈学了这节课之后，你对特征工程有怎样的理解。</p><p>欢迎你在留言区分享你的想法和收获，我在留言区等你。如果这节课帮到了你，也欢迎你把这节课分享给自己的朋友。我们下一讲再见！</p><p><img src="/blog-other/static/httpsstatic001geekbangorgresourceimage4d144d4505f3261a8f69dc4c8b0d44d31514.44cc6a90.jpg" alt=""/></p></div><div class="__dumi-default-layout-footer-meta"><a target="_blank" rel="noopener noreferrer" href="https://github.com/GGwujun/blog/edit/master/ssrc/零基础实战机器学习/03.业务场景闯关篇/04.md">在 GitHub 上编辑此页<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="__dumi-default-external-link-icon"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a><span data-updated-text="最后更新时间：">2023/9/23 21:58:31</span></div></div></div></div>
	<script>
  window.g_useSSR = true;
  window.g_initialProps = {};
	</script>

    <script>
      (function () {
        if (!location.port) {
          (function (i, s, o, g, r, a, m) {
            i["GoogleAnalyticsObject"] = r;
            (i[r] =
              i[r] ||
              function () {
                (i[r].q = i[r].q || []).push(arguments);
              }),
              (i[r].l = 1 * new Date());
            (a = s.createElement(o)), (m = s.getElementsByTagName(o)[0]);
            a.async = 1;
            a.src = g;
            m.parentNode.insertBefore(a, m);
          })(
            window,
            document,
            "script",
            "//www.google-analytics.com/analytics.js",
            "ga"
          );
          ga("create", "UA-149864185-1", "auto");
          ga("send", "pageview");
        }
      })();
    </script>
    <script src="/blog-other/umi.js"></script>
  </body>
</html>
