<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta
      name="viewport"
      content="width=device-width, initial-scale=1, maximum-scale=1, minimum-scale=1, user-scalable=no"
    />
    <link rel="shortcut icon" type="image/x-icon" href="/logo.png" />
    <link rel="stylesheet" href="/blog-other/umi.css" />
    <script>
      window.routerBase = "/blog-other";
    </script>
    <script>
      //! umi version: 3.5.41
    </script>
    <script>
      !(function () {
        var e =
            navigator.cookieEnabled && void 0 !== window.localStorage
              ? localStorage.getItem("dumi:prefers-color")
              : "auto",
          o = window.matchMedia("(prefers-color-scheme: dark)").matches,
          t = ["light", "dark", "auto"];
        document.documentElement.setAttribute(
          "data-prefers-color",
          e === t[2] ? (o ? t[1] : t[0]) : t.indexOf(e) > -1 ? e : t[0]
        );
      })();
    </script>
    <title>16｜性能评估：不平衡数据集应该使用何种评估指标？ - 大师兄</title>
  </head>
  <body>
    <div id="root"><div class="__dumi-default-layout" data-route="/零基础实战机器学习/03.业务场景闯关篇/12" data-show-sidemenu="true" data-show-slugs="true" data-site-mode="true" data-gapless="false"><div class="__dumi-default-navbar" data-mode="site"><button class="__dumi-default-navbar-toggle"></button><a class="__dumi-default-navbar-logo" style="background-image:url(&#x27;/logo.png&#x27;)" href="/blog-other/">大师兄</a><nav><div class="__dumi-default-search"><input type="search" class="__dumi-default-search-input" value=""/><ul></ul></div><span>前端开发<ul><li><a href="/blog-other/说透低代码">说透低代码</a></li><li><a href="/blog-other/反爬虫兵法演绎20讲">反爬虫兵法演绎20讲</a></li></ul></span><span>产品与用户体验<ul><li><a href="/blog-other/大厂广告产品心法">大厂广告产品心法</a></li></ul></span><span>面试<ul><li><a href="/blog-other/技术面试官识人手册">技术面试官识人手册</a></li><li><a href="/blog-other/面试现场">面试现场</a></li></ul></span><span>杂谈<ul><li><a href="/blog-other/乔新亮的cto成长复盘">乔新亮的cto成长复盘</a></li><li><a href="/blog-other/互联网人的英语私教课">互联网人的英语私教课</a></li><li><a href="/blog-other/从0开始学游戏开发">从0开始学游戏开发</a></li><li><a href="/blog-other/全栈工程师修炼指南">全栈工程师修炼指南</a></li><li><a href="/blog-other/手机摄影">手机摄影</a></li><li><a href="/blog-other/物联网开发实战">物联网开发实战</a></li><li><a href="/blog-other/白话法律42讲">白话法律42讲</a></li><li><a href="/blog-other/说透5g">说透5g</a></li><li><a href="/blog-other/超级访谈对话张雪峰">超级访谈对话张雪峰</a></li><li><a aria-current="page" class="active" href="/blog-other/零基础实战机器学习">零基础实战机器学习</a></li></ul></span><div class="__dumi-default-navbar-tool"><div class="__dumi-default-dark"><div class="__dumi-default-dark-switch "></div></div></div></nav></div><div class="__dumi-default-menu" data-mode="site"><div class="__dumi-default-menu-inner"><div class="__dumi-default-menu-header"><a class="__dumi-default-menu-logo" style="background-image:url(&#x27;/logo.png&#x27;)" href="/blog-other/"></a><h1>大师兄</h1><p></p></div><div class="__dumi-default-menu-mobile-area"><ul class="__dumi-default-menu-nav-list"><li>前端开发<ul><li><a href="/blog-other/说透低代码">说透低代码</a></li><li><a href="/blog-other/反爬虫兵法演绎20讲">反爬虫兵法演绎20讲</a></li></ul></li><li>产品与用户体验<ul><li><a href="/blog-other/大厂广告产品心法">大厂广告产品心法</a></li></ul></li><li>面试<ul><li><a href="/blog-other/技术面试官识人手册">技术面试官识人手册</a></li><li><a href="/blog-other/面试现场">面试现场</a></li></ul></li><li>杂谈<ul><li><a href="/blog-other/乔新亮的cto成长复盘">乔新亮的cto成长复盘</a></li><li><a href="/blog-other/互联网人的英语私教课">互联网人的英语私教课</a></li><li><a href="/blog-other/从0开始学游戏开发">从0开始学游戏开发</a></li><li><a href="/blog-other/全栈工程师修炼指南">全栈工程师修炼指南</a></li><li><a href="/blog-other/手机摄影">手机摄影</a></li><li><a href="/blog-other/物联网开发实战">物联网开发实战</a></li><li><a href="/blog-other/白话法律42讲">白话法律42讲</a></li><li><a href="/blog-other/说透5g">说透5g</a></li><li><a href="/blog-other/超级访谈对话张雪峰">超级访谈对话张雪峰</a></li><li><a aria-current="page" class="active" href="/blog-other/零基础实战机器学习">零基础实战机器学习</a></li></ul></li></ul><div class="__dumi-default-dark"><div class="__dumi-default-dark-switch "><button title="Dark theme" class="__dumi-default-dark-moon "><svg viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="3854" width="22" height="22"><path d="M991.816611 674.909091a69.166545 69.166545 0 0 0-51.665455-23.272727 70.795636 70.795636 0 0 0-27.438545 5.585454A415.674182 415.674182 0 0 1 754.993338 698.181818c-209.594182 0-393.472-184.785455-393.472-395.636363 0-52.363636 38.539636-119.621818 69.515637-173.614546 4.887273-8.610909 9.634909-16.756364 14.103272-24.901818A69.818182 69.818182 0 0 0 384.631156 0a70.842182 70.842182 0 0 0-27.438545 5.585455C161.678429 90.298182 14.362065 307.898182 14.362065 512c0 282.298182 238.824727 512 532.38691 512a522.286545 522.286545 0 0 0 453.957818-268.334545A69.818182 69.818182 0 0 0 991.816611 674.909091zM546.679156 954.181818c-248.785455 0-462.941091-192-462.941091-442.181818 0-186.647273 140.637091-372.829091 300.939637-442.181818-36.817455 65.629091-92.578909 151.970909-92.578909 232.727273 0 250.181818 214.109091 465.454545 462.917818 465.454545a488.331636 488.331636 0 0 0 185.181091-46.545455 453.003636 453.003636 0 0 1-393.565091 232.727273z m103.656728-669.323636l-14.266182 83.781818a34.909091 34.909091 0 0 0 50.362182 36.770909l74.775272-39.563636 74.752 39.563636a36.142545 36.142545 0 0 0 16.174546 3.956364 34.909091 34.909091 0 0 0 34.210909-40.727273l-14.289455-83.781818 60.509091-59.345455a35.025455 35.025455 0 0 0-19.223272-59.578182l-83.61891-12.101818-37.376-76.101818a34.56 34.56 0 0 0-62.254545 0l-37.376 76.101818-83.618909 12.101818a34.909091 34.909091 0 0 0-19.246546 59.578182z m70.423272-64.698182a34.280727 34.280727 0 0 0 26.135273-19.083636l14.312727-29.090909 14.336 29.090909a34.257455 34.257455 0 0 0 26.135273 19.083636l32.046546 4.887273-23.272728 22.574545a35.234909 35.234909 0 0 0-10.007272 30.952727l5.46909 32.116364-28.625454-15.127273a34.490182 34.490182 0 0 0-32.302546 0l-28.695272 15.127273 5.469091-32.116364a35.141818 35.141818 0 0 0-9.984-30.952727l-23.272728-22.574545z" p-id="3855"></path></svg></button><button title="Light theme" class="__dumi-default-dark-sun "><svg viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="4026" width="22" height="22"><path d="M915.2 476.16h-43.968c-24.704 0-44.736 16-44.736 35.84s20.032 35.904 44.736 35.904H915.2c24.768 0 44.8-16.064 44.8-35.904s-20.032-35.84-44.8-35.84zM512 265.6c-136.704 0-246.464 109.824-246.464 246.4 0 136.704 109.76 246.464 246.464 246.464S758.4 648.704 758.4 512c0-136.576-109.696-246.4-246.4-246.4z m0 425.6c-99.008 0-179.2-80.128-179.2-179.2 0-98.944 80.192-179.2 179.2-179.2S691.2 413.056 691.2 512c0 99.072-80.192 179.2-179.2 179.2zM197.44 512c0-19.84-19.136-35.84-43.904-35.84H108.8c-24.768 0-44.8 16-44.8 35.84s20.032 35.904 44.8 35.904h44.736c24.768 0 43.904-16.064 43.904-35.904zM512 198.464c19.776 0 35.84-20.032 35.84-44.8v-44.8C547.84 84.032 531.84 64 512 64s-35.904 20.032-35.904 44.8v44.8c0 24.768 16.128 44.864 35.904 44.864z m0 627.136c-19.776 0-35.904 20.032-35.904 44.8v44.736C476.096 940.032 492.16 960 512 960s35.84-20.032 35.84-44.8v-44.736c0-24.768-16.064-44.864-35.84-44.864z m329.92-592.832c17.472-17.536 20.288-43.072 6.4-57.024-14.016-14.016-39.488-11.2-57.024 6.336-4.736 4.864-26.496 26.496-31.36 31.36-17.472 17.472-20.288 43.008-6.336 57.024 13.952 14.016 39.488 11.2 57.024-6.336 4.8-4.864 26.496-26.56 31.296-31.36zM213.376 759.936c-4.864 4.8-26.56 26.624-31.36 31.36-17.472 17.472-20.288 42.944-6.4 56.96 14.016 13.952 39.552 11.2 57.024-6.336 4.8-4.736 26.56-26.496 31.36-31.36 17.472-17.472 20.288-43.008 6.336-56.96-14.016-13.952-39.552-11.072-56.96 6.336z m19.328-577.92c-17.536-17.536-43.008-20.352-57.024-6.336-14.08 14.016-11.136 39.488 6.336 57.024 4.864 4.864 26.496 26.56 31.36 31.424 17.536 17.408 43.008 20.288 56.96 6.336 14.016-14.016 11.264-39.488-6.336-57.024-4.736-4.864-26.496-26.56-31.296-31.424z m527.168 628.608c4.864 4.864 26.624 26.624 31.36 31.424 17.536 17.408 43.072 20.224 57.088 6.336 13.952-14.016 11.072-39.552-6.4-57.024-4.864-4.8-26.56-26.496-31.36-31.36-17.472-17.408-43.072-20.288-57.024-6.336-13.952 14.016-11.008 39.488 6.336 56.96z" p-id="4027"></path></svg></button><button title="Default to system" class="__dumi-default-dark-auto "><svg viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="11002" width="22" height="22"><path d="M127.658667 492.885333c0-51.882667 10.24-101.717333 30.378666-149.162666s47.786667-88.064 81.92-122.538667 75.093333-61.781333 122.538667-81.92 96.938667-30.378667 149.162667-30.378667 101.717333 10.24 149.162666 30.378667 88.405333 47.786667 122.88 81.92 61.781333 75.093333 81.92 122.538667 30.378667 96.938667 30.378667 149.162666-10.24 101.717333-30.378667 149.162667-47.786667 88.405333-81.92 122.88-75.093333 61.781333-122.88 81.92-97.28 30.378667-149.162666 30.378667-101.717333-10.24-149.162667-30.378667-88.064-47.786667-122.538667-81.92-61.781333-75.093333-81.92-122.88-30.378667-96.938667-30.378666-149.162667z m329.045333 0c0 130.048 13.994667 244.394667 41.984 343.381334h12.970667c46.762667 0 91.136-9.216 133.461333-27.306667s78.848-42.666667 109.568-73.386667 54.954667-67.242667 73.386667-109.568 27.306667-86.698667 27.306666-133.461333c0-46.421333-9.216-90.794667-27.306666-133.12s-42.666667-78.848-73.386667-109.568-67.242667-54.954667-109.568-73.386667-86.698667-27.306667-133.461333-27.306666h-11.605334c-28.672 123.562667-43.349333 237.909333-43.349333 343.722666z" p-id="11003"></path></svg></button></div></div></div><ul class="__dumi-default-menu-list"><li><a href="/blog-other/零基础实战机器学习">零基础实战机器学习</a></li><li><a href="/blog-other/零基础实战机器学习/01.开篇词">01.开篇词</a><ul><li><a href="/blog-other/零基础实战机器学习/01.开篇词/01"><span>开篇词｜开发者为什么要从实战出发学机器学习？</span></a></li></ul></li><li><a href="/blog-other/零基础实战机器学习/02.准备篇">02.准备篇</a><ul><li><a href="/blog-other/零基础实战机器学习/02.准备篇/01"><span>01｜打好基础：到底什么是机器学习？</span></a></li><li><a href="/blog-other/零基础实战机器学习/02.准备篇/02"><span>02｜工具准备：安装并使用Jupyter Notebook</span></a></li><li><a href="/blog-other/零基础实战机器学习/02.准备篇/03"><span>03｜实战5步（上）：怎么定义问题和预处理数据？</span></a></li><li><a href="/blog-other/零基础实战机器学习/02.准备篇/04"><span>04｜ 实战5步（下）：怎么建立估计10万+软文点击率的模型？</span></a></li></ul></li><li><a aria-current="page" class="active" href="/blog-other/零基础实战机器学习/03.业务场景闯关篇">03.业务场景闯关篇</a><ul><li><a href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/01"><span>05 | 数据探索：怎样从数据中找到用户的RFM值？</span></a></li><li><a href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/02"><span>06 | 聚类分析：如何用RFM给电商用户做价值分组画像？</span></a></li><li><a href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/03"><span>07｜回归分析：怎样用模型预测用户的生命周期价值？</span></a></li><li><a href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/04"><span>08 | 模型优化（上）：怎么用特征工程提高模型效率？</span></a></li><li><a href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/05"><span>09｜模型优化（中）：防止过拟合，模型也不能太精细</span></a></li><li><a href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/06"><span>10｜模型优化（下）：交叉验证，同时寻找最优的参数</span></a></li><li><a href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/07"><span>11｜深度学习（上）：用CNN带你认识深度学习</span></a></li><li><a href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/08"><span>12｜深度学习（中）：如何用RNN预测激活率走势？</span></a></li><li><a href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/09"><span>13｜深度学习（下）：3招提升神经网络预测准确率</span></a></li><li><a href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/10"><span>14｜留存分析：哪些因素会影响用户的留存率？</span></a></li><li><a href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/11"><span>15｜二元分类：怎么预测用户是否流失？从逻辑回归到深度学习</span></a></li><li><a aria-current="page" class="active" href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/12"><span>16｜性能评估：不平衡数据集应该使用何种评估指标？</span></a></li><li><a href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/13"><span>17｜集成学习：机器学习模型如何“博采众长”?</span></a></li><li><a href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/14"><span>18 | 增长模型：用XGBoost评估裂变海报的最佳受众群体</span></a></li></ul></li><li><a href="/blog-other/零基础实战机器学习/04.持续赋能篇">04.持续赋能篇</a><ul><li><a href="/blog-other/零基础实战机器学习/04.持续赋能篇/01"><span>19 | 胸有成竹：如何快速定位合适的机器学习算法？</span></a></li><li><a href="/blog-other/零基础实战机器学习/04.持续赋能篇/02"><span>20 | 模型部署：怎么发布训练好的机器学习模型？</span></a></li><li><a href="/blog-other/零基础实战机器学习/04.持续赋能篇/03"><span>21｜持续精进：如何在机器学习领域中找准前进的方向？</span></a></li></ul></li><li><a href="/blog-other/零基础实战机器学习/05.结束语">05.结束语</a><ul><li><a href="/blog-other/零基础实战机器学习/05.结束语/01"><span>一套习题，测出你对机器学习的掌握程度</span></a></li><li><a href="/blog-other/零基础实战机器学习/05.结束语/02"><span>结束语 | 可以不完美，但重要的是马上开始</span></a></li></ul></li><li><a href="/blog-other/零基础实战机器学习/summary">零基础实战机器学习</a></li></ul></div></div><ul role="slug-list" class="__dumi-default-layout-toc"><li title="精确率和召回率" data-depth="2"><a href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/12#精确率和召回率"><span>精确率和召回率</span></a></li><li title="F1分数" data-depth="2"><a href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/12#f1分数"><span>F1分数</span></a></li><li title="ROC曲线和AUC" data-depth="2"><a href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/12#roc曲线和auc"><span>ROC曲线和AUC</span></a></li><li title="总结一下" data-depth="2"><a href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/12#总结一下"><span>总结一下</span></a></li><li title="思考题" data-depth="2"><a href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/12#思考题"><span>思考题</span></a></li></ul><div class="__dumi-default-layout-content"><div class="markdown"><h1 id="16性能评估不平衡数据集应该使用何种评估指标"><a aria-hidden="true" tabindex="-1" href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/12#16性能评估不平衡数据集应该使用何种评估指标"><span class="icon icon-link"></span></a>16｜性能评估：不平衡数据集应该使用何种评估指标？</h1><p>你好，我是黄佳。欢迎来到零基础实战机器学习。</p><p>上一讲中，我们通过逻辑回归和深度学习神经网络两种模型，判断了会员流失的可能性，准确率大概在78%左右。我想考一考你，这个准确率是否能够反映出模型的分类性能？</p><p>也许你会回答，看起来没什么问题啊。但是，如果我告诉你，对于这个数据集来说，即使不用任何机器学习模型，我闭着眼睛也能够达到70%以上的预测准确率。你会不会吓一跳，说，这怎么可能呢？</p><p>其实，如果你仔细观察一下这个数据集已经流失和留存下来的会员比例，就会发现，在这个数据集中，留下的会员是73%，而已经离开的会员占27%。</p><p><img src="/blog-other/static/httpsstatic001geekbangorgresourceimage1c721ca4d96d0bc5bf49a2bdyy6883028672.d8eaa042.jpg" alt="" title="流失与否？"/></p><p>这也就是说，如果我直接提出一个模型，<strong>判断所有的会员都会留存，<strong><strong>那</strong></strong>我这个模型的预测准确率就是73%</strong>。所以说，要达到70%以上的预测准确率，真的是没有什么难度。</p><p>我再举一个极端一点的例子，在银行客户欺诈行为的检测系统中，存在欺诈行为的客户可能不到万分之一。那么，一个模型只要预测所有的客户都没有欺诈行为，这个模型的准确率就能达99.999%。</p><p>然而，这样的模型没有任何意义。因为**我们的目标不是判断出这9999个正常客户，而是要想法设法找出那万分之一的异常客户。**所以，对于我们这个问题来说，如何精确定位那23%的可能流失的客户，才是关键所在。</p><p>因此，<strong>评估分类模型要比评估回归模型的难度大很多，评估的方法也更为多样化，尤其是对于各类别中样本数量并不平衡的数据集来说，<strong><strong>我们</strong></strong>绝对不能单用准确率这一个方面作为考量的标准</strong>。</p><p>那么，什么指标才更合适呢？这里，我给你介绍四个重要的分类评估方法。这四个分类评估方法和分类准确率一样，可以广泛适用于几乎所有的分类问题，尤其是对于样本类别不平衡的问题来说，这些方法比准确率更为客观。</p><h1 id="混淆矩阵"><a aria-hidden="true" tabindex="-1" href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/12#混淆矩阵"><span class="icon icon-link"></span></a>混淆矩阵</h1><p>在认识第一种评估方法“混淆矩阵”（Confusion Matrix）之前，我们先来看一个例子。假设“易速鲜花”一共有100个会员（举个例子而已），其中73个留存了下来，27个流失了。那么，我们就可以这样表示这个数据集的真值：</p><p><img src="/blog-other/static/httpsstatic001geekbangorgresourceimaged39fd3b2cc3d6f2db186e44a3af9e40ef69f.b5967a33.jpg" alt=""/></p><p>如果这时候有一个模型A，它的预测结果是77个留存，23个流失。那么，上面这张表就会变成这样：</p><p><img src="/blog-other/static/httpsstatic001geekbangorgresourceimage57yy578731a274e6f5a609105f76da9705yy.8692631c.jpg" alt=""/></p><p>要想知道这个模型A预测得准不准，我们就要看一下在这77个留存用户和23个流失用户中，有多少是预测正确的，多少是错误的。但是，在现有的表格中，我们并不能了解到。所以现在，我们不妨引入这样一个矩阵：</p><p><img src="/blog-other/static/httpsstatic001geekbangorgresourceimageffeeff82061b7f6b762d38668577df6123ee.cb3f6ae0.jpg" alt=""/></p><p>这是一个由预测值和真值共同组成的矩阵，四个象限从上到下，从左到右分别为：</p><ul><li><strong>真负</strong>：真值为负、预测为负，即True Negative，缩写为TN；</li><li><strong>假正</strong>：真值为负，预测为正，即False Positive，缩写为FP；</li><li><strong>假负</strong>：真值为正，预测为负，即False Negative，缩写为FN；</li><li><strong>真正</strong>：真值为正，预测为正，即True Positive，缩写为TP。</li></ul><p>这个矩阵就是混淆矩阵，这里的“真”“假”就代表实际值（真值）和预测值一致与否；而“正”“负”就代表预测出来的值是1还是0。所以，对于“预测用户是留存还是流失”这个问题来说：</p><ul><li>真负(TN)，代表被模型判断为留存的留存用户数：70；</li><li>假正(FP)，代表被模型判断为流失的留存用户数：3；</li><li>假负(FN)，代表被模型判断为留存的流失用户数： 7；</li><li>真正(TP)，代表被模型判断为流失的流失用户数： 20。</li></ul><p>这样矩阵就能反应出模型预测的真实情况了。对于模型A来说，在73个留存用户中，它预测对了70个；在27个流失用户中，它预测对了20个。所以，它整体的准确率就是：</p><p>$$模型A的整体准确率=\frac<!-- -->{<!-- -->70+20<!-- -->}<!-- -->{<!-- -->100<!-- -->}<!-- -->=90\%$$</p><p>当然，对于我们<a target="_blank" rel="noopener noreferrer" href="https://time.geekbang.org/column/article/423893">上一讲<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="__dumi-default-external-link-icon"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>的项目来说，<strong>在这个矩阵中，我们最看重的应该是“真正”这个象限的数字，因为它代表了模型找出了多少个即将流失的用户。只有这个数字，才能对“易速鲜花”的运营状况产生正面促进。</strong></p><p>这时候，如果还有另一个模型B，它的预测结果和模型A的一样，也是77个留存用户，23个流失用户，那我想，你应该不会轻易认为模型B的准确率和模型A的一样了，因为它的混淆矩阵很可能是这样的：</p><p><img src="/blog-other/static/httpsstatic001geekbangorgresourceimage7a527a0bc49f9ee3a6da6c79ea17a7c81052.d4206b16.jpg" alt=""/></p><p>在75个留存用户中，模型B预测准了55个，还算勉强可以。但是对于23个流失客户来说，模型B只预测出5个。所以，这个模型B预测的整体准确率为：</p><p>$$模型B的整体准确率=\frac<!-- -->{<!-- -->55+5<!-- -->}<!-- -->{<!-- -->100<!-- -->}<!-- -->=60\%$$</p><p>由于我们真正的目的是找到流失客户，从这个目的来讲，模型B的准确率还不到20%呢。</p><p>到这里，我想你应该感受到混淆矩阵的威力了。那对于<a target="_blank" rel="noopener noreferrer" href="https://time.geekbang.org/column/article/423893">上一讲<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="__dumi-default-external-link-icon"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>里“预测哪些客户流失风险比较高”这个项目，我们就可以借助混淆矩阵，来评估三个模型（逻辑回归模型、未做归一化的DNN神经网络，以及归一化之后的DNN神经网络）的优劣了。</p><p>要计算这三个模型的混淆矩阵，我们可以用sklearn中的confusion_matrix工具。不过，我们还需要定义一个用来显示混淆矩阵的函数，我把它命名为show_matrix（这里我们不重复数据导入和预处理以及模型训练的代码），完整代码请在<a target="_blank" rel="noopener noreferrer" href="https://github.com/huangjia2019/geektime/tree/main/%E7%95%99%E5%AD%98%E5%85%B316">这里<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="__dumi-default-external-link-icon"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>下载：</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">from sklearn.metrics import confusion_matrix # 导入混淆矩阵</span></div><div class="token-line"><span class="token plain">    import seaborn as sns #导入seaborn画图工具箱</span></div><div class="token-line"><span class="token plain">    def show_matrix(y_test, y_pred): # 定义一个函数显示混淆矩阵</span></div><div class="token-line"><span class="token plain">        cm = confusion_matrix(y_test,y_pred) # 调用混淆矩阵</span></div><div class="token-line"><span class="token plain">        plt.title(&quot;混淆矩阵&quot;) # 标题</span></div><div class="token-line"><span class="token plain">        sns.heatmap(cm,annot=True,cmap=&quot;Blues&quot;,fmt=&quot;d&quot;,cbar=False) # 热力图</span></div><div class="token-line"><span class="token plain">        plt.show() # 显示混淆矩阵</span></div></pre></div><p>然后，我们调用show_matrix函数，先来显示逻辑回归模型的混淆矩阵：</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">show_matrix(y_test, y_pred) # 逻辑回归</span></div></pre></div><p>输出如下：</p><p><img src="/blog-other/static/httpsstatic001geekbangorgresourceimage3ad43ab52cd01b3c1db9966cae2ca823a6d4.0930460f.jpg" alt=""/></p><p>接着，我们再显示DNN神经网络做归一化之前和归一化之后的混淆矩阵。注意，<strong>我这样做目的，是为了向你展示，两个分类准确率看起来近似的模型，它们的混淆矩阵内容可能会很不一样哦！</strong></p><p>此外，我还要说明一点，我们在这一讲中跑出来的预测结果，很可能和上一讲中的预测结果不完全一致。因为神经网络每次训练时是随机拆分数据集的，而且梯度下降的随机性和局部最低点也将导致每次的模型结果会有所不同。</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">y_pred = ann.predict(X_test,batch_size=10) # 预测测试集的标签</span></div><div class="token-line"><span class="token plain">    y_pred = np.round(y_pred) # 将分类概率值转换成0/1整数值</span></div><div class="token-line"><span class="token plain">    show_matrix(y_test, y_pred) #神经网络</span></div></pre></div><p>输出如下：</p><p><img src="/blog-other/static/httpsstatic001geekbangorgresourceimage724e72c50c784861024bf5ff2418e32f6f4e.dfa27fdf.jpg" alt=""/><br/><img src="/blog-other/static/httpsstatic001geekbangorgresourceimage655365af36cf08a5eb7a82527d242b505a53.d7c7c6ff.jpg" alt=""/></p><p>有了这几个混淆矩阵之后，我们才能够真正看出每个模型的优劣。请你注意，我们第一眼要看的是右下角的“真正”值，也就是模型到底抓出来了多少“真的可能会流失”的付费会员。</p><p>结果显示，在361个流失会员中，逻辑回归模型抓出了171人，DNN神经网络归一化之后的模型抓出了199人（这其实不错了），而未做归一化的DNN神经网络仅仅抓到了50人。哪个模型更靠谱？我想你心里已经有答案了。</p><p>到这里，你应该更加理解为什么整体准确率不足以反映出模型的真正分类情况。不过，你可能会问，混淆矩阵虽然直观，但它不是一个分数性的指标，如果我老板就是喜欢像“准确率”这样的分数型指标，怎么办？</p><p>很简单，我们可以在混淆矩阵的基础之上，引入“精确率”（也叫查准率）和“召回率”（也叫查全率）两个指标。</p><h2 id="精确率和召回率"><a aria-hidden="true" tabindex="-1" href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/12#精确率和召回率"><span class="icon icon-link"></span></a>精确率和召回率</h2><p>我们先说精确率。精确率也叫查准率，它的意义是：<strong>在被分为正例的示例中，实际为正例的比例</strong>。我们可以这样计算精确率：</p><p>$$精确率（Precision） = \frac<!-- -->{<!-- -->被模型预测为正的正样本<!-- -->}<!-- -->{<!-- -->(被模型预测为正的正样本 + 被模型预测为正的负样本)<!-- -->}<!-- -->$$</p><p>其中，“被模型预测为正的正样本”就是混淆矩阵中的“真正”，也就是TP；“被模型预测为正的负样本”则是混淆矩阵中的“假正”，也就是FP 。所以，这个公式就是：</p><p>$$精确率（Precision） = \frac<!-- -->{<!-- -->TP<!-- -->}<!-- -->{<!-- -->(TP + FP)<!-- -->}<!-- -->$$</p><p>现在，我们拿刚才这个DNN神经网络归一化后的混淆矩阵为例：</p><p><img src="/blog-other/static/httpsstatic001geekbangorgresourceimage655365af36cf08a5eb7a82527d242b505a53.d7c7c6ff.jpg" alt=""/></p><p>就流失的用户而言：</p><ul><li>真负(TN)：被模型判断为留存的留存用户数：899;</li><li>假正(FP)：被模型判断为流失的留存用户数：149;</li><li>假负(FN)：被模型判断为留存的流失用户数： 162;</li><li>真正(TP)：被模型判断为流失的流失用户数： 199.</li></ul><p>所以，流失会员的<strong>精确率为：</strong></p><p>$$流失会员的精确率（Precision） = \frac<!-- -->{<!-- -->199<!-- -->}<!-- -->{<!-- -->(199 + 149)<!-- -->}<!-- -->=57\%$$</p><p>可以看到，虽然这个归一化后的DNN神经网络模型整体上的准确率为78%，但是它基于流失用户的精确率只有57%，说明它仍有提升的空间。</p><p>当然，我们也可以基于留存的用户来判断这个模型的精确率：</p><ul><li>真负(TN)：被模型判断为流失的流失用户数：199;</li><li>假正(FP)：被模型判断为留存的流失用户数： 162;</li><li>假负(FN)：被模型判断为流失的留存用户数： 149;</li><li>真正(TP)：被模型判断为留存的留存用户数： 899.</li></ul><p>这个模型基于留存用户的精确率为：</p><p>$$留存会员的精确率（Precision） = \frac<!-- -->{<!-- -->899<!-- -->}<!-- -->{<!-- -->(899 + 162)<!-- -->}<!-- -->=85\%$$</p><p>这是评判模型的另外一个视角。当然，从解决运营人员问题的角度出发，我们还是要基于流失用户来看模型的精确率，这样才能帮助运营人员进行有针对性的留客活动。</p><p>除了精确率，还有另一个标准是<strong>召回率</strong>，也叫<strong>查全率</strong>。你应该听说过“召回”这个词吧，就是劣质品蒙混过了质检这关，跑出厂了，被发现后得给召回来，销毁掉。召回率是覆盖面的度量，它度量的是被正确判为正例的正例比例，它和精确率是成对出现的概念，公式如下：</p><p>$$召回率（Recall） = \frac<!-- -->{<!-- -->TP<!-- -->}<!-- -->{<!-- -->(TP + FN)<!-- -->}<!-- -->$$</p><p>召回率考量了“假负（FN）”的存在，也就是需要考虑被误判为“合格品”的“劣质品”，在我们这个问题中的假负就是被误判为“留存”的“要流失”的会员。</p><p>对于刚才这个例子：</p><p><img src="/blog-other/static/httpsstatic001geekbangorgresourceimage655365af36cf08a5eb7a82527d242b505a53.d7c7c6ff.jpg" alt=""/></p><p>就流失会员而言，归一化后的DNN神经网络模型的<strong>召回率为：</strong></p><p>$$召回率（Recall） = \frac<!-- -->{<!-- -->199<!-- -->}<!-- -->{<!-- -->(199 + 162)<!-- -->}<!-- -->=55\%$$</p><p>我们看到，这个算法的召回率比精确率低一些。那么，我们应该以上面57%的精确率为准呢，还是应该以55%的召回率为准？答案是：当我们需要更多考量被模型预测为正的负样本时（本来是忠诚会员，误判为流失），我们看精确率；当我们需要更多考量被模型预测为负的正样本时（本来要流失了，误判为忠诚会员），我们看召回率。</p><p>对于我们这个问题，如果你问我，我会更关注召回率，因为我们就是害怕会员流失嘛。但是，如果精确率不够，运营人员会做很多无用功，把力气、时间和经费白白花在本来不会流失的人身上。</p><p>那有没有一个指标可以直接解决问题，不用这么绕来绕去？接下来，我就给你介绍一个单一指标，它可以基本搞定对不平衡数据集的分类评估。</p><h2 id="f1分数"><a aria-hidden="true" tabindex="-1" href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/12#f1分数"><span class="icon icon-link"></span></a>F1分数</h2><p>这个指标就是F1分数。它结合了精确率和召回率的共同特点。F1分数的公式如下：</p><p>$$F1 = 2 \times \frac<!-- -->{<!-- -->精准率\times召回率<!-- -->}<!-- -->{<!-- -->(精准率 + 召回率)<!-- -->}<!-- -->$$</p><p>这个指标可以同时体现“精确率”和“召回率”的评估效果，在数学上定义为“精确率和召回率的调和均值”。只有当召回率和精确率都很高时，分类模型才能得到较高的F1分数。</p><p>F1指标特别适合于评估各类别样本分布不平衡的问题。因此，当你想用一个简单的方法来比较多种分类模型的优劣时，你选F1分数就对了。</p><p>下面，我们用代码求出<a target="_blank" rel="noopener noreferrer" href="https://time.geekbang.org/column/article/423893">上一讲<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="__dumi-default-external-link-icon"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>中三个模型的F1分数。在sklearn中，F1分数可以通过分类报告classification_report工具进行显示。此时，classification_report也会把精确率、召回率和准确率一起显示出来，一举多得了。这三个指标的计算，也都会在classification_report内部完成，所以，我们只需要把预测值和真值传进这个函数就好了。</p><p>我们先定义一个显示分类报告的函数show_report：</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">from sklearn.metrics import classification_report # 导入分类报告</span></div><div class="token-line"><span class="token plain">    def show_report(X_test, y_test, y_pred): # 定义一个函数显示分类报告</span></div><div class="token-line"><span class="token plain">        print(classification_report(y_test,y_pred,labels=[0, 1])) #打印分类报告</span></div></pre></div><p>再调用这个函数打印出分类报告：</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">show_report(X_test, y_test, y_pred)</span></div></pre></div><p>下面，我们直接给出逻辑回归、归一化前后DNN神经网络模型的分类报告。</p><p>逻辑回归：</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">precision    recall  f1-score   support</span></div><div class="token-line"><span class="token plain">           0       0.83      0.89      0.86      1048</span></div><div class="token-line"><span class="token plain">           1       0.60      0.47      0.53       361</span></div><div class="token-line"><span class="token plain">    accuracy                           0.78      1409</span></div></pre></div><p>DNN神经网络（归一化前）：</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">precision    recall  f1-score   support</span></div><div class="token-line"><span class="token plain">           0       0.77      0.99      0.87      1048</span></div><div class="token-line"><span class="token plain">           1       0.81      0.14      0.24       361</span></div><div class="token-line"><span class="token plain">    accuracy                           0.77      1409</span></div></pre></div><p>DNN神经网络（归一化后）：</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">precision    recall  f1-score   support</span></div><div class="token-line"><span class="token plain">           0       0.85      0.86      0.85      1048</span></div><div class="token-line"><span class="token plain">           1       0.57      0.55      0.56       361</span></div><div class="token-line"><span class="token plain">    accuracy                           0.78      1409</span></div></pre></div><p>在这个Report中，我们更关注1值，也就是相对于流失客户的精确率、召回率和F1分数，尤其是F1分数。结果显示，虽然逻辑回归和归一化后的神经网络准确率都是78%，但是，F1分数最高的模型是归一化后的DNN神经网络。所以，对这个问题来说，归一化后的DNN神经网络性能最棒。</p><p>现在，有了F1分数这个比较优秀的分类评估指标，我们对模型的评估就靠谱得多了。不过，你可能会想：有没有什么图形化的显示方式，能更为直观地比较出多个模型的性能优劣呢？的确有。</p><h2 id="roc曲线和auc"><a aria-hidden="true" tabindex="-1" href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/12#roc曲线和auc"><span class="icon icon-link"></span></a>ROC曲线和AUC</h2><p>除了精确率、召回率、F1分数之外，还有两个经常与二元分类器一起使用的工具：一个是“受试者工作特征曲线”（receiver operating characteristic curve，简称ROC）；另一个是“曲线下面积”（Area under the Curve of ROC，简称AUC）。</p><p>ROC曲线绘制的是“真正类率”和“假正类率”的信息。其中，真正类率也叫真阳性率（TPR），表示在所有实际为阳性的样本中，被正确地判断为阳性的比率。它其实就是召回率的另一个名称。</p><p>$$真阳性率（TPR） = \frac<!-- -->{<!-- -->TP<!-- -->}<!-- -->{<!-- -->(TP + FN)<!-- -->}<!-- -->$$</p><p>假正类率也叫伪阳性率（FPR），表示在所有实际为阴性的样本中，被错误地判断为阳性的比率：</p><p>$$伪阳性率（FPR） = \frac<!-- -->{<!-- -->FP<!-- -->}<!-- -->{<!-- -->(FP + TN)<!-- -->}<!-- -->$$</p><p>要绘制ROC曲线，我们需要先构建一个ROC空间。ROC空间其实就是把伪阳性率（FPR）定义为 X 轴，真阳性率（TPR）定义为 Y 轴，所形成的坐标系空间。构建好ROC空间后，如果给定一个二元分类模型和它所预测的分类概率，我们就能根据样本的真实值和预测值，在ROC空间中画出一个个坐标点 (X=FPR, Y=TPR) 了。</p><p>那怎么判断这些坐标点的好坏呢？我们从坐标点 (0, 0) 到 (1,1) 画一个对角线，将ROC空间划分为左上／右下两个区域。在这条线以上的点代表了一个好的分类结果（真阳性率比伪阳性率高），而在这条线以下的点代表了差的分类结果（真阳性率比伪阳性率低）。由此，你可能也猜出了，在ROC空间里，越靠近左上的点越好，越靠近右下越劣，而对角线上的点，真阳性率和伪阳性率值相同，这就相当于随机猜测的结果。</p><p><img src="/blog-other/static/httpsstatic001geekbangorgresourceimage925692b794722d77378ba7fdb18ef1f64756.006c77bf.png" alt=""/></p><p>如果我们将同一模型所有样本的 (FPR, TPR) 坐标都画在ROC空间里，连成一条线，就能得到该模型的ROC曲线。这条曲线与ROC空间右边缘线和下边缘线围成的面积，就是这个模型的曲线下面积（AUC）。</p><p>我们前面说，在ROC空间里，越靠近左上的点越好，越靠近右下越劣。因此，对于AUC来讲，AUC越大，说明这个模型越趋向左上角越好。从具体的数值来看，AUC的取值范围在0.5和1之间。 AUC越接近1.0，说明模型性能越高；等于0.5时，只相当于随机一猜，说明模型无应用价值。</p><p>如果你想要比较不同的分类模型，就可以在同一个ROC空间中，把每个模型的ROC曲线都画出来，通过比较AUC的大小，就能判断出各个模型的优劣。</p><p>下面，我们就比较一下逻辑回归和DNN神经网络（归一化之后）的ROC曲线和AUC值。因为没有归一化的DNN神经网络性能很差，所以，我们在这里就不把它放在一起比较了。</p><p>首先，我们导入sklearn中绘制ROC曲线和计算AUC的工具roc_curve和auc：</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">from sklearn.metrics import roc_curve #导入roc_curve工具</span></div><div class="token-line"><span class="token plain">    from sklearn.metrics import auc #导入auc工具</span></div></pre></div><p>然后，我们在测试集上对DNN神经网络模型做一个预测，根据预测结果计算出FPR,、TPR和AUC的值。这里dnn代表神经网络。</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">y_pred_dnn = dnn.predict(X_test).ravel() #神经网络预测概率值</span></div><div class="token-line"><span class="token plain">    fpr_dnn, tpr_dnn, thresholds_dnn = roc_curve(y_test, y_pred_dnn) #神经网络 TPR FPR和ROC曲线</span></div><div class="token-line"><span class="token plain">    auc_dnn = auc(fpr_dnn, tpr_dnn) #神经网络 AUC值</span></div></pre></div><p>同样地，我们也计算出逻辑回归模型的FPR、TPR和AUC值，这里lr代表逻辑回归。</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">y_pred_lr = lr.predict_proba(X_test)[:, 1]　＃逻辑回归预测概率值</span></div><div class="token-line"><span class="token plain">    fpr_lr, tpr_lr, thresholds_lr = roc_curve(y_test, y_pred_lr)　#逻辑回归 TPR FPR和ROC曲线</span></div><div class="token-line"><span class="token plain">    auc_lr = auc(fpr_lr, tpr_lr)　#逻辑回归 AUC值</span></div></pre></div><p>最后，我们在一张图中显示这两个模型的ROC曲线和AUC值：</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">plt.plot([0, 1], [0, 1], &#x27;k--&#x27;)　＃设定对角线</span></div><div class="token-line"><span class="token plain">    plt.plot(fpr_dnn, tpr_dnn, label=&#x27;神经网络 (area = {:.3f})&#x27;.format(auc_dnn))　#绘制神经网络ROC曲线</span></div><div class="token-line"><span class="token plain">    plt.plot(fpr_lr, tpr_lr, label=&#x27;逻辑回归 (area = {:.3f})&#x27;.format(auc_lr))　#绘制逻辑回归ROC曲线</span></div><div class="token-line"><span class="token plain">    plt.xlabel(&#x27;False positive rate&#x27;)　＃X轴FPR</span></div><div class="token-line"><span class="token plain">    plt.ylabel(&#x27;True positive rate&#x27;)　＃Y轴TPR</span></div><div class="token-line"><span class="token plain">    plt.title(&#x27;ROC曲线&#x27;)　＃图题</span></div><div class="token-line"><span class="token plain">    plt.legend(loc=&#x27;best&#x27;)　＃图例</span></div><div class="token-line"><span class="token plain">    plt.show()　＃绘图</span></div></pre></div><p>输出如下：</p><p><img src="/blog-other/static/httpsstatic001geekbangorgresourceimage694f690f4b41fd664bd7d5a03758e8a3c94f.53d7968b.png" alt=""/></p><p>在这个曲线中，我们可以很明显地看出，DNN神经网络的ROC曲线在整体上要高于逻辑回归模型（更逼近左上角），AUC值（曲线下面积）是0.811，比逻辑回归的AUC值0.756要高。这说明，DNN神经网络模型的性能要好过逻辑回归。</p><h2 id="总结一下"><a aria-hidden="true" tabindex="-1" href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/12#总结一下"><span class="icon icon-link"></span></a>总结一下</h2><p>好，这一讲的内容就结束了。学完了这一讲，你需要铭记有一个重要的点，那就是<strong>模型的好与不好，是基于用什么标准衡量</strong>。对于正样本和负样本比例极度不平衡的样本集，我们需要选择正确的评估标准。</p><p>那么对于分类问题，尤其是各个类别的值很不平衡的数据集来说，哪些评估标准是更重要的呢？首先应该看混淆矩阵，混淆矩阵能够给出我们真正、假正、真负、假负的值，这个矩阵的信息量比准确率大很多。</p><p>通过混淆矩阵中的真正、假正、真负、假负的值，我们进而能求出精确率、召回率以及二者的综合指标F1分数。其中的F1指标，就是评估样本类别数量并不平衡的二分类问题的最简单方法。而要计算精确率、召回率以及F1分数，也很简单，我们用sklearn的classification_report就能轻松实现。</p><p>此外，我们还可以通过ROC曲线和AUC值，用图表的形式来直观地比较各个模型的分类性能优劣。请你注意，ROC曲线越靠近左上角，模型越优，而AUC的值越接近1，模型越优。</p><h2 id="思考题"><a aria-hidden="true" tabindex="-1" href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/12#思考题"><span class="icon icon-link"></span></a>思考题</h2><p>好，这节课就到这里了，最后，我给你留两道思考题：</p><ol><li>请你从多个维度思考，如何对神经网络模型进行优化，以实现更好的分类效果，得到更优的F1分数。</li></ol><p>提示思路：改变训练的轮次、调整激活函数，优化器，神经网络结构。</p><ol start="2"><li>在<a target="_blank" rel="noopener noreferrer" href="https://time.geekbang.org/column/article/419746">第10讲<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="__dumi-default-external-link-icon"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>中，我们介绍了怎么用KFold工具拆分数据集，做K折验证。其实，对于非平衡数据，我们也可以用StratifiedKFold、StratifiedShuffleSplit等拆分数据集，来做分层采样。所谓分层采样，就是在每一份子集中都保持和原始数据集相同的类别比例。若数据集有2个类别，比例是8:2，则划分后的样本比例仍约是8:2。请你尝试通过这个方式，对逻辑回归模型进行K折验证。此外，train_test_split也有stratify参数，你也可以尝试用它来保持数据分割时的类别比例。</li></ol><p>欢迎你在留言区和我分享你的观点，如果你认为这节课的内容有收获，也欢迎把它分享给你的朋友，我们下一讲再见！</p><p><img src="/blog-other/static/httpsstatic001geekbangorgresourceimage90ec90ba66f0ca40dbf8215567b8668f63ec.64715bf7.jpg" alt=""/></p></div><div class="__dumi-default-layout-footer-meta"><a target="_blank" rel="noopener noreferrer" href="https://github.com/GGwujun/blog/edit/master/ssrc/零基础实战机器学习/03.业务场景闯关篇/12.md">在 GitHub 上编辑此页<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="__dumi-default-external-link-icon"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a><span data-updated-text="最后更新时间：">2023/9/23 21:58:31</span></div></div></div></div>
	<script>
  window.g_useSSR = true;
  window.g_initialProps = {};
	</script>

    <script>
      (function () {
        if (!location.port) {
          (function (i, s, o, g, r, a, m) {
            i["GoogleAnalyticsObject"] = r;
            (i[r] =
              i[r] ||
              function () {
                (i[r].q = i[r].q || []).push(arguments);
              }),
              (i[r].l = 1 * new Date());
            (a = s.createElement(o)), (m = s.getElementsByTagName(o)[0]);
            a.async = 1;
            a.src = g;
            m.parentNode.insertBefore(a, m);
          })(
            window,
            document,
            "script",
            "//www.google-analytics.com/analytics.js",
            "ga"
          );
          ga("create", "UA-149864185-1", "auto");
          ga("send", "pageview");
        }
      })();
    </script>
    <script src="/blog-other/umi.js"></script>
  </body>
</html>
