<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta
      name="viewport"
      content="width=device-width, initial-scale=1, maximum-scale=1, minimum-scale=1, user-scalable=no"
    />
    <link rel="shortcut icon" type="image/x-icon" href="/logo.png" />
    <link rel="stylesheet" href="/blog-other/umi.css" />
    <script>
      window.routerBase = "/blog-other";
    </script>
    <script>
      //! umi version: 3.5.41
    </script>
    <script>
      !(function () {
        var e =
            navigator.cookieEnabled && void 0 !== window.localStorage
              ? localStorage.getItem("dumi:prefers-color")
              : "auto",
          o = window.matchMedia("(prefers-color-scheme: dark)").matches,
          t = ["light", "dark", "auto"];
        document.documentElement.setAttribute(
          "data-prefers-color",
          e === t[2] ? (o ? t[1] : t[0]) : t.indexOf(e) > -1 ? e : t[0]
        );
      })();
    </script>
    <title>19 | 胸有成竹：如何快速定位合适的机器学习算法？ - 大师兄</title>
  </head>
  <body>
    <div id="root"><div class="__dumi-default-layout" data-route="/零基础实战机器学习/04.持续赋能篇/01" data-show-sidemenu="true" data-show-slugs="true" data-site-mode="true" data-gapless="false"><div class="__dumi-default-navbar" data-mode="site"><button class="__dumi-default-navbar-toggle"></button><a class="__dumi-default-navbar-logo" style="background-image:url(&#x27;/logo.png&#x27;)" href="/blog-other/">大师兄</a><nav><div class="__dumi-default-search"><input type="search" class="__dumi-default-search-input" value=""/><ul></ul></div><span>前端开发<ul><li><a href="/blog-other/说透低代码">说透低代码</a></li><li><a href="/blog-other/反爬虫兵法演绎20讲">反爬虫兵法演绎20讲</a></li></ul></span><span>产品与用户体验<ul><li><a href="/blog-other/大厂广告产品心法">大厂广告产品心法</a></li></ul></span><span>面试<ul><li><a href="/blog-other/技术面试官识人手册">技术面试官识人手册</a></li><li><a href="/blog-other/面试现场">面试现场</a></li></ul></span><span>杂谈<ul><li><a href="/blog-other/乔新亮的cto成长复盘">乔新亮的cto成长复盘</a></li><li><a href="/blog-other/互联网人的英语私教课">互联网人的英语私教课</a></li><li><a href="/blog-other/从0开始学游戏开发">从0开始学游戏开发</a></li><li><a href="/blog-other/全栈工程师修炼指南">全栈工程师修炼指南</a></li><li><a href="/blog-other/手机摄影">手机摄影</a></li><li><a href="/blog-other/物联网开发实战">物联网开发实战</a></li><li><a href="/blog-other/白话法律42讲">白话法律42讲</a></li><li><a href="/blog-other/说透5g">说透5g</a></li><li><a href="/blog-other/超级访谈对话张雪峰">超级访谈对话张雪峰</a></li><li><a aria-current="page" class="active" href="/blog-other/零基础实战机器学习">零基础实战机器学习</a></li></ul></span><div class="__dumi-default-navbar-tool"><div class="__dumi-default-dark"><div class="__dumi-default-dark-switch "></div></div></div></nav></div><div class="__dumi-default-menu" data-mode="site"><div class="__dumi-default-menu-inner"><div class="__dumi-default-menu-header"><a class="__dumi-default-menu-logo" style="background-image:url(&#x27;/logo.png&#x27;)" href="/blog-other/"></a><h1>大师兄</h1><p></p></div><div class="__dumi-default-menu-mobile-area"><ul class="__dumi-default-menu-nav-list"><li>前端开发<ul><li><a href="/blog-other/说透低代码">说透低代码</a></li><li><a href="/blog-other/反爬虫兵法演绎20讲">反爬虫兵法演绎20讲</a></li></ul></li><li>产品与用户体验<ul><li><a href="/blog-other/大厂广告产品心法">大厂广告产品心法</a></li></ul></li><li>面试<ul><li><a href="/blog-other/技术面试官识人手册">技术面试官识人手册</a></li><li><a href="/blog-other/面试现场">面试现场</a></li></ul></li><li>杂谈<ul><li><a href="/blog-other/乔新亮的cto成长复盘">乔新亮的cto成长复盘</a></li><li><a href="/blog-other/互联网人的英语私教课">互联网人的英语私教课</a></li><li><a href="/blog-other/从0开始学游戏开发">从0开始学游戏开发</a></li><li><a href="/blog-other/全栈工程师修炼指南">全栈工程师修炼指南</a></li><li><a href="/blog-other/手机摄影">手机摄影</a></li><li><a href="/blog-other/物联网开发实战">物联网开发实战</a></li><li><a href="/blog-other/白话法律42讲">白话法律42讲</a></li><li><a href="/blog-other/说透5g">说透5g</a></li><li><a href="/blog-other/超级访谈对话张雪峰">超级访谈对话张雪峰</a></li><li><a aria-current="page" class="active" href="/blog-other/零基础实战机器学习">零基础实战机器学习</a></li></ul></li></ul><div class="__dumi-default-dark"><div class="__dumi-default-dark-switch "><button title="Dark theme" class="__dumi-default-dark-moon "><svg viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="3854" width="22" height="22"><path d="M991.816611 674.909091a69.166545 69.166545 0 0 0-51.665455-23.272727 70.795636 70.795636 0 0 0-27.438545 5.585454A415.674182 415.674182 0 0 1 754.993338 698.181818c-209.594182 0-393.472-184.785455-393.472-395.636363 0-52.363636 38.539636-119.621818 69.515637-173.614546 4.887273-8.610909 9.634909-16.756364 14.103272-24.901818A69.818182 69.818182 0 0 0 384.631156 0a70.842182 70.842182 0 0 0-27.438545 5.585455C161.678429 90.298182 14.362065 307.898182 14.362065 512c0 282.298182 238.824727 512 532.38691 512a522.286545 522.286545 0 0 0 453.957818-268.334545A69.818182 69.818182 0 0 0 991.816611 674.909091zM546.679156 954.181818c-248.785455 0-462.941091-192-462.941091-442.181818 0-186.647273 140.637091-372.829091 300.939637-442.181818-36.817455 65.629091-92.578909 151.970909-92.578909 232.727273 0 250.181818 214.109091 465.454545 462.917818 465.454545a488.331636 488.331636 0 0 0 185.181091-46.545455 453.003636 453.003636 0 0 1-393.565091 232.727273z m103.656728-669.323636l-14.266182 83.781818a34.909091 34.909091 0 0 0 50.362182 36.770909l74.775272-39.563636 74.752 39.563636a36.142545 36.142545 0 0 0 16.174546 3.956364 34.909091 34.909091 0 0 0 34.210909-40.727273l-14.289455-83.781818 60.509091-59.345455a35.025455 35.025455 0 0 0-19.223272-59.578182l-83.61891-12.101818-37.376-76.101818a34.56 34.56 0 0 0-62.254545 0l-37.376 76.101818-83.618909 12.101818a34.909091 34.909091 0 0 0-19.246546 59.578182z m70.423272-64.698182a34.280727 34.280727 0 0 0 26.135273-19.083636l14.312727-29.090909 14.336 29.090909a34.257455 34.257455 0 0 0 26.135273 19.083636l32.046546 4.887273-23.272728 22.574545a35.234909 35.234909 0 0 0-10.007272 30.952727l5.46909 32.116364-28.625454-15.127273a34.490182 34.490182 0 0 0-32.302546 0l-28.695272 15.127273 5.469091-32.116364a35.141818 35.141818 0 0 0-9.984-30.952727l-23.272728-22.574545z" p-id="3855"></path></svg></button><button title="Light theme" class="__dumi-default-dark-sun "><svg viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="4026" width="22" height="22"><path d="M915.2 476.16h-43.968c-24.704 0-44.736 16-44.736 35.84s20.032 35.904 44.736 35.904H915.2c24.768 0 44.8-16.064 44.8-35.904s-20.032-35.84-44.8-35.84zM512 265.6c-136.704 0-246.464 109.824-246.464 246.4 0 136.704 109.76 246.464 246.464 246.464S758.4 648.704 758.4 512c0-136.576-109.696-246.4-246.4-246.4z m0 425.6c-99.008 0-179.2-80.128-179.2-179.2 0-98.944 80.192-179.2 179.2-179.2S691.2 413.056 691.2 512c0 99.072-80.192 179.2-179.2 179.2zM197.44 512c0-19.84-19.136-35.84-43.904-35.84H108.8c-24.768 0-44.8 16-44.8 35.84s20.032 35.904 44.8 35.904h44.736c24.768 0 43.904-16.064 43.904-35.904zM512 198.464c19.776 0 35.84-20.032 35.84-44.8v-44.8C547.84 84.032 531.84 64 512 64s-35.904 20.032-35.904 44.8v44.8c0 24.768 16.128 44.864 35.904 44.864z m0 627.136c-19.776 0-35.904 20.032-35.904 44.8v44.736C476.096 940.032 492.16 960 512 960s35.84-20.032 35.84-44.8v-44.736c0-24.768-16.064-44.864-35.84-44.864z m329.92-592.832c17.472-17.536 20.288-43.072 6.4-57.024-14.016-14.016-39.488-11.2-57.024 6.336-4.736 4.864-26.496 26.496-31.36 31.36-17.472 17.472-20.288 43.008-6.336 57.024 13.952 14.016 39.488 11.2 57.024-6.336 4.8-4.864 26.496-26.56 31.296-31.36zM213.376 759.936c-4.864 4.8-26.56 26.624-31.36 31.36-17.472 17.472-20.288 42.944-6.4 56.96 14.016 13.952 39.552 11.2 57.024-6.336 4.8-4.736 26.56-26.496 31.36-31.36 17.472-17.472 20.288-43.008 6.336-56.96-14.016-13.952-39.552-11.072-56.96 6.336z m19.328-577.92c-17.536-17.536-43.008-20.352-57.024-6.336-14.08 14.016-11.136 39.488 6.336 57.024 4.864 4.864 26.496 26.56 31.36 31.424 17.536 17.408 43.008 20.288 56.96 6.336 14.016-14.016 11.264-39.488-6.336-57.024-4.736-4.864-26.496-26.56-31.296-31.424z m527.168 628.608c4.864 4.864 26.624 26.624 31.36 31.424 17.536 17.408 43.072 20.224 57.088 6.336 13.952-14.016 11.072-39.552-6.4-57.024-4.864-4.8-26.56-26.496-31.36-31.36-17.472-17.408-43.072-20.288-57.024-6.336-13.952 14.016-11.008 39.488 6.336 56.96z" p-id="4027"></path></svg></button><button title="Default to system" class="__dumi-default-dark-auto "><svg viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="11002" width="22" height="22"><path d="M127.658667 492.885333c0-51.882667 10.24-101.717333 30.378666-149.162666s47.786667-88.064 81.92-122.538667 75.093333-61.781333 122.538667-81.92 96.938667-30.378667 149.162667-30.378667 101.717333 10.24 149.162666 30.378667 88.405333 47.786667 122.88 81.92 61.781333 75.093333 81.92 122.538667 30.378667 96.938667 30.378667 149.162666-10.24 101.717333-30.378667 149.162667-47.786667 88.405333-81.92 122.88-75.093333 61.781333-122.88 81.92-97.28 30.378667-149.162666 30.378667-101.717333-10.24-149.162667-30.378667-88.064-47.786667-122.538667-81.92-61.781333-75.093333-81.92-122.88-30.378667-96.938667-30.378666-149.162667z m329.045333 0c0 130.048 13.994667 244.394667 41.984 343.381334h12.970667c46.762667 0 91.136-9.216 133.461333-27.306667s78.848-42.666667 109.568-73.386667 54.954667-67.242667 73.386667-109.568 27.306667-86.698667 27.306666-133.461333c0-46.421333-9.216-90.794667-27.306666-133.12s-42.666667-78.848-73.386667-109.568-67.242667-54.954667-109.568-73.386667-86.698667-27.306667-133.461333-27.306666h-11.605334c-28.672 123.562667-43.349333 237.909333-43.349333 343.722666z" p-id="11003"></path></svg></button></div></div></div><ul class="__dumi-default-menu-list"><li><a href="/blog-other/零基础实战机器学习">零基础实战机器学习</a></li><li><a href="/blog-other/零基础实战机器学习/01.开篇词">01.开篇词</a><ul><li><a href="/blog-other/零基础实战机器学习/01.开篇词/01"><span>开篇词｜开发者为什么要从实战出发学机器学习？</span></a></li></ul></li><li><a href="/blog-other/零基础实战机器学习/02.准备篇">02.准备篇</a><ul><li><a href="/blog-other/零基础实战机器学习/02.准备篇/01"><span>01｜打好基础：到底什么是机器学习？</span></a></li><li><a href="/blog-other/零基础实战机器学习/02.准备篇/02"><span>02｜工具准备：安装并使用Jupyter Notebook</span></a></li><li><a href="/blog-other/零基础实战机器学习/02.准备篇/03"><span>03｜实战5步（上）：怎么定义问题和预处理数据？</span></a></li><li><a href="/blog-other/零基础实战机器学习/02.准备篇/04"><span>04｜ 实战5步（下）：怎么建立估计10万+软文点击率的模型？</span></a></li></ul></li><li><a href="/blog-other/零基础实战机器学习/03.业务场景闯关篇">03.业务场景闯关篇</a><ul><li><a href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/01"><span>05 | 数据探索：怎样从数据中找到用户的RFM值？</span></a></li><li><a href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/02"><span>06 | 聚类分析：如何用RFM给电商用户做价值分组画像？</span></a></li><li><a href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/03"><span>07｜回归分析：怎样用模型预测用户的生命周期价值？</span></a></li><li><a href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/04"><span>08 | 模型优化（上）：怎么用特征工程提高模型效率？</span></a></li><li><a href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/05"><span>09｜模型优化（中）：防止过拟合，模型也不能太精细</span></a></li><li><a href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/06"><span>10｜模型优化（下）：交叉验证，同时寻找最优的参数</span></a></li><li><a href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/07"><span>11｜深度学习（上）：用CNN带你认识深度学习</span></a></li><li><a href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/08"><span>12｜深度学习（中）：如何用RNN预测激活率走势？</span></a></li><li><a href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/09"><span>13｜深度学习（下）：3招提升神经网络预测准确率</span></a></li><li><a href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/10"><span>14｜留存分析：哪些因素会影响用户的留存率？</span></a></li><li><a href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/11"><span>15｜二元分类：怎么预测用户是否流失？从逻辑回归到深度学习</span></a></li><li><a href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/12"><span>16｜性能评估：不平衡数据集应该使用何种评估指标？</span></a></li><li><a href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/13"><span>17｜集成学习：机器学习模型如何“博采众长”?</span></a></li><li><a href="/blog-other/零基础实战机器学习/03.业务场景闯关篇/14"><span>18 | 增长模型：用XGBoost评估裂变海报的最佳受众群体</span></a></li></ul></li><li><a aria-current="page" class="active" href="/blog-other/零基础实战机器学习/04.持续赋能篇">04.持续赋能篇</a><ul><li><a aria-current="page" class="active" href="/blog-other/零基础实战机器学习/04.持续赋能篇/01"><span>19 | 胸有成竹：如何快速定位合适的机器学习算法？</span></a></li><li><a href="/blog-other/零基础实战机器学习/04.持续赋能篇/02"><span>20 | 模型部署：怎么发布训练好的机器学习模型？</span></a></li><li><a href="/blog-other/零基础实战机器学习/04.持续赋能篇/03"><span>21｜持续精进：如何在机器学习领域中找准前进的方向？</span></a></li></ul></li><li><a href="/blog-other/零基础实战机器学习/05.结束语">05.结束语</a><ul><li><a href="/blog-other/零基础实战机器学习/05.结束语/01"><span>一套习题，测出你对机器学习的掌握程度</span></a></li><li><a href="/blog-other/零基础实战机器学习/05.结束语/02"><span>结束语 | 可以不完美，但重要的是马上开始</span></a></li></ul></li><li><a href="/blog-other/零基础实战机器学习/summary">零基础实战机器学习</a></li></ul></div></div><ul role="slug-list" class="__dumi-default-layout-toc"><li title="从问题的类型开始" data-depth="2"><a href="/blog-other/零基础实战机器学习/04.持续赋能篇/01#从问题的类型开始"><span>从问题的类型开始</span></a></li><li title="回归问题算法选择指南" data-depth="2"><a href="/blog-other/零基础实战机器学习/04.持续赋能篇/01#回归问题算法选择指南"><span>回归问题算法选择指南</span></a></li><li title="分类问题算法选择指南" data-depth="2"><a href="/blog-other/零基础实战机器学习/04.持续赋能篇/01#分类问题算法选择指南"><span>分类问题算法选择指南</span></a></li><li title="选择算法时的其它考量因素" data-depth="2"><a href="/blog-other/零基础实战机器学习/04.持续赋能篇/01#选择算法时的其它考量因素"><span>选择算法时的其它考量因素</span></a></li><li title="训练数据的大小" data-depth="3"><a href="/blog-other/零基础实战机器学习/04.持续赋能篇/01#训练数据的大小"><span>训练数据的大小</span></a></li><li title="特征的数量" data-depth="3"><a href="/blog-other/零基础实战机器学习/04.持续赋能篇/01#特征的数量"><span>特征的数量</span></a></li><li title="性能和可解释性的权衡" data-depth="3"><a href="/blog-other/零基础实战机器学习/04.持续赋能篇/01#性能和可解释性的权衡"><span>性能和可解释性的权衡</span></a></li><li title="速度或训练时间" data-depth="3"><a href="/blog-other/零基础实战机器学习/04.持续赋能篇/01#速度或训练时间"><span>速度或训练时间</span></a></li><li title="数据的线性程度" data-depth="3"><a href="/blog-other/零基础实战机器学习/04.持续赋能篇/01#数据的线性程度"><span>数据的线性程度</span></a></li><li title="总结一下" data-depth="2"><a href="/blog-other/零基础实战机器学习/04.持续赋能篇/01#总结一下"><span>总结一下</span></a></li><li title="思考题" data-depth="2"><a href="/blog-other/零基础实战机器学习/04.持续赋能篇/01#思考题"><span>思考题</span></a></li></ul><div class="__dumi-default-layout-content"><div class="markdown"><h1 id="19--胸有成竹如何快速定位合适的机器学习算法"><a aria-hidden="true" tabindex="-1" href="/blog-other/零基础实战机器学习/04.持续赋能篇/01#19--胸有成竹如何快速定位合适的机器学习算法"><span class="icon icon-link"></span></a>19 | 胸有成竹：如何快速定位合适的机器学习算法？</h1><p>你好，我是黄佳。欢迎来到零基础实战机器学习。</p><p>首先，恭喜你闯过了所有的业务关卡，我们即将开启这个课程的第三个模块：持续赋能篇，这也是我们的最后一个模块。在前面的动手实战过程中，相信你已经对机器学习中的多种算法胸有成竹了！</p><p>那么这儿先回顾一下我们一起学习了哪些算法。</p><p>在获客关，我们用RFM值给电商用户做了分组画像。其中，我们学习了无监督学习中的<strong>聚类算法</strong>，这也是我们这个课程中唯一一个监督学习之外的算法。在变现关，我们预测了用户生命周期价值LTV，并讲解了各种模型优化方式。在此过程中，我们学习了<strong>线性回归</strong>、<strong>决策树</strong>和<strong>随机森林算法</strong>。</p><p>在激活关的深度学习部分，我们学习了如何用<strong>CNN网络</strong>对图片分类；并用<strong>RNN网络</strong>处理了时序数据，预测App的激活数。在留存关预测用户是否会流失的部分，我们通过<strong>逻辑回归算法</strong>和深度学习中的<strong>DNN网络</strong>解决了二元分类问题。在裂变关，我们评估了裂变海报的最佳受众群体。在这个实战中，我们用<strong>XGBoost</strong>这种集成学习方法完成了多元分类。</p><p><img src="/blog-other/static/httpsstatic001geekbangorgresourceimage19e819fd60c66f07eb2ae5910dab575802e8.91300012.jpg" alt=""/></p><p>当然，面对机器学习这个深度全然不可测的海洋，我们在这个课程中使用过的算法只是沧海一粟。不过，我们所选择的这9种算法，是在机器学习入门阶段中最为常用、也最为实用的算法，它们不仅能有效地帮助我们解决诸多实际问题，也能为我们在机器学习领域进一步的钻研打下坚实的基础。只要用好了这9种算法，面对需要分析和挖掘的数据，你已经就拥有了9种非常强大的武器，可以开始战斗了。</p><p>那么，你可能会疑惑：面对新的问题以及需要分析、挖掘的数据，如何快速的定位最合适的算法呢？这是一个很好的问题，同时也是一个很大的课题，而且这个问题也没有直接且确定的答案。不过，今天这一讲，我会试着根据我的经验和知识，给你总结一些简单的原则。</p><p>在接下来的介绍中，我们的算法覆盖范围并不仅限于课程中的9个算法，也会涉及其它一些算法，如果有些算法让你觉得陌生，你可以自己进行一些搜索。</p><p>在这里我先给出一个guideline：<strong>我们可以从问题本身、标签的类型、数据集的大小、特征的数量、计算时间的要求、以及模型的可解释性这些方面，来比较和选择算法。</strong></p><h2 id="从问题的类型开始"><a aria-hidden="true" tabindex="-1" href="/blog-other/零基础实战机器学习/04.持续赋能篇/01#从问题的类型开始"><span class="icon icon-link"></span></a>从问题的类型开始</h2><p>要选择合适的算法，我们首先还是要回到问题本身。把问题定义好，并明确你要解决的目标，是选择算法的前提。</p><p>如果你的目标是对有标签的数据进行预测或分类，那么你就需要从监督学习算法家族中进行选择；如果你的目标是从没有标签的数据中挖掘出一些信息，或者是对数据做特征工程，比如降低数据的维度，那么你就需要在无监督学习算法家族中进行选择。</p><p>如果你的目标是生成没有见过的新数据，例如生成完全不存在的人脸，或者让机器续写个哈利波特啥的，那么生成式机器学习算法值得你研究一下。近年来非常吸引眼球的生成式对抗网络GAN（Generative Adversarial Networks）、Google推出的DeepDream算法，以及变分自编码器VAE等，都是解决这类问题的优秀算法。</p><p>现在，我们回到最为主流的监督学习问题，来继续算法的选择。在监督学习下面，我们又有两大类问题，就是回归问题和分类问题，我们可以根据标签是连续的数值，还是离散的数值，来确定问题的类型，相信你已经非常熟悉了。这两大类问题，均拥有超多的应用场景，也各自拥有一大批的算法。我们首先看一下针对回归问题的算法选择指南。</p><h2 id="回归问题算法选择指南"><a aria-hidden="true" tabindex="-1" href="/blog-other/零基础实战机器学习/04.持续赋能篇/01#回归问题算法选择指南"><span class="icon icon-link"></span></a>回归问题算法选择指南</h2><p>当明确了问题本身属于回归问题后，我们就需要在线性回归、决策树、随机森林、XGBoost、朴素贝叶斯以及神经网络这些常见的回归算法中进行选择。这时候，我们就需要考虑数据集大小、特征的维度（也就是特征的多少）、训练所需的时间等因素。</p><p>当你的回归问题并不复杂，并且希望从易于解释的模型开始时，我建议你选择线性回归模型作为可靠的首选基准算法，线性回归对大、小数据集都适用，而且也可以处理高维特征数据。</p><p>如果你的数据集特征和数据样本数量都不是很多，而且特征之间有关联关系，那么SVM（支持向量机）可以作为一个选择，这个模型对于特征数量有限、意义接近的中等大小的数据集来说比较强大。在使用SVM之前，需要进行特征缩放。</p><p>如果你手头上的数据集样本数量和特征数量都十分巨大，那么可以考虑朴素贝叶斯模型，它比线性模型的速度要快得多，适用于非常大的数据集和高维数据，不过，它的性能通常要低于线性模型。</p><p>当你对模型运行速度有要求的时候，比如你的模型是在线训练、在线预测，那么决策树可以作为你的一个选择。因为它解决回归问题的速度很快，而且也不需要数据缩放。决策树的另一个优点是可以进行可视化，而且非常容易解释。</p><p>不过你要注意，如果参数设置不当，决策树就会出现过拟合的现象；如果限制了树的深度的话，又比较容易出现精度不够的问题。因此，决策树通常是作为集成学习方法的基模型而存在的，很少独立使用。</p><p>如果你追求的是模型的性能和表现，那么，随机森林几乎总是比单棵决策树的表现要好，它的性能非常强大，也不需要数据缩放。但随机森林并不合适处理高维稀疏数据集。</p><p>当然，XGBoost的性能通常比随机森林还略高一点。与随机森林相比，XGBoost的训练速度虽然更慢，但预测速度更快，需要的内存也更少。不过，在参数方面，XGBoost可调的外部参数比随机森林更多，所以调参时候会更繁琐一些。</p><p>另外，如果你的问题是时间序列问题，或者特征数量极为巨大，又没有良好的结构，而且特征之间可能存在非线性依赖关系的时候，你应该考虑使用深度神经网络。因为深度神经网络可以构建非常复杂的模型来解决这类问题，特别是对于大型数据集而言，很有优势。</p><p>但是，请你注意，深度神经网络难于解释，如果你需要优化过程的具体推导细节，那深度学习模型很难给出。此外，它对数据缩放和参数选取也比较敏感，而且，大型神经网络需要很长的训练时间。这些都是你需要根据实际情况考量的因素。</p><p>总之，面对新数据集，我建议你通常最好先从简单模型开始，比如线性模型、朴素贝叶斯或最近邻KNN，看能得到什么样的结果。对数据有了进一步了解之后，你可以考虑构建更复杂模型的算法，比如随机森林、梯度提升决策树、SVM或神经网络。</p><p>下面我们再来看分类问题的算法选择技巧。</p><h2 id="分类问题算法选择指南"><a aria-hidden="true" tabindex="-1" href="/blog-other/零基础实战机器学习/04.持续赋能篇/01#分类问题算法选择指南"><span class="icon icon-link"></span></a>分类问题算法选择指南</h2><p>分类问题的算法选择，在思路上和回归问题略有不同。对于分类问题，我更多是基于问题的性质来寻找合适的算法，而不是从数据集大小、特征数目的多少以及训练时间的快慢来考量。</p><p>当我们要解决用户是否会流失、欺诈检测、促销和裂变效果等问题时，可以采用逻辑回归算法作为这些普通分类问题的基准算法，因为它简单且易于解释。当然，其它分类算法也可以用于解决这类问题。</p><p>而对于投资方面的决策、银行贷款的评估决策等，我们经常使用决策树算法。因为决策树算法最直观，最接近人类的思维方式，算法也非常易于用图表展示。当然，决策树在分类问题中也容易出现过拟合问题，因此，决策树很少单独作为一种算法来解决问题，一般都是作为集成学习方法的基模型出现。</p><p>对于类别比例不平衡的问题，比如检测生产系统中的坏件，预测高风险的病患等，我推荐你采用随机森林算法，它解决了决策树算法的过拟合问题。同时，XGBoost算法和随机森林类似，也是解决各种分类问题的好选择，性能比随机森林略高。</p><p>如果你要解决文本的情感属性判断、文本分类、推荐系统或者是人脸识别问题，那么朴素贝叶斯算法是深度学习出现之前的首选算法。和深度学习相比，朴素贝叶斯算法的优势在于可解释性较好。因此，在要求算法具有良好的解释性时，你可以通过朴素贝叶斯算法解决这类问题。</p><p>而对于疾病诊断和判断、手写数字识别等多种分类问题，SVM是一种比较好的解决方案。当然深度学习也可以解决这类问题，和深度学习相比，SVM的优势也在于可解释性较好。因此，在要求算法具有良好的解释性时，我们用SVM算法来解决多种分类问题比较好。</p><p>最后，我不得不提的是，深度学习神经网络实为解决大数据时代的分类问题的大杀器，我们前面所说的各种分类问题，都可以用深度学习来解决。尤其是非结构化的分类问题，比如语音识别、计算机视觉、自然语言处理、文本分类、自动驾驶等，深度学习都是首选项。</p><p>当然，非要“鸡蛋里挑骨头”的话，那就是在数据量小或者特征结构很好的情况下，深度学习的优势体现得不是很明显，我们还是要尽量选择简单的方案；另外，深度学习的可解释性不好，就像一个黑箱，因此，调参的过程也比较费力。</p><p>好了，这就是分类问题算法选择的一些原则。下面，我再给你总结一下选择算法时的考量因素。</p><h2 id="选择算法时的其它考量因素"><a aria-hidden="true" tabindex="-1" href="/blog-other/零基础实战机器学习/04.持续赋能篇/01#选择算法时的其它考量因素"><span class="icon icon-link"></span></a>选择算法时的其它考量因素</h2><p>我们前面说，<strong>选择算法时有两个最主要的出发点，第一是问题的类型</strong>，我们要回到问题本身，看它是监督学习还是无监督学习；<strong>第二是预测的标签类型</strong>，一般来说，监督学习问题最为主流，这时候我们需要根据标签来进一步确定，问题属于回归问题还是分类问题。</p><p>除此之外，我们在选择算法时还有一些其他的考虑因素，我们一起看看。</p><h3 id="训练数据的大小"><a aria-hidden="true" tabindex="-1" href="/blog-other/零基础实战机器学习/04.持续赋能篇/01#训练数据的大小"><span class="icon icon-link"></span></a>训练数据的大小</h3><p>通常，我们都希望能收集到大量数据，获得更可靠的预测。但很多时候，数据的量是一个制约因素，我们也没办法。因此，如果你的训练数据集较小，也就是数据样本较少，但是特征数较多（如文本数据），这时应该选择具有高偏差、低方差的算法，比如如线性回归、朴素贝叶斯或线性SVM。</p><p>如果你的训练数据足够大，并且特征数量也比较少，那你就可以使用低偏差、高方差的算法，如 KNN、决策树或核SVM。当然，对于数据很多的情况，神经网络也是很好的选择。</p><h3 id="特征的数量"><a aria-hidden="true" tabindex="-1" href="/blog-other/零基础实战机器学习/04.持续赋能篇/01#特征的数量"><span class="icon icon-link"></span></a>特征的数量</h3><p>除数据样本量之外，特征的数量也影响模型的选择。数据集可能有大量的特征，有些特征可能并不是和问题十分相关，因此也并不重要。某种数据集，例如遗传学问题或文本数据，与数据样本的数量相比，特征的数量可能非常大。</p><p>过多的特征会使多数算法的训练时间过长，不过，SVM模型就不会受特征数量的约束，因此，对于大特征空间和较少数据量的情况，SVM模型是我们的最佳选择。当然，如果你要用其他的机器学习模型，可以使用PCA和特征选择技术来降低特征的维度，选择重要特征进行学习。</p><p>除此之外，深度学习也为我们处理巨大特征量的问题提供了非常好的解决方案。当特征数量巨大且特征空间结构复杂时，深度学习神经网络是绝佳选择。</p><h3 id="性能和可解释性的权衡"><a aria-hidden="true" tabindex="-1" href="/blog-other/零基础实战机器学习/04.持续赋能篇/01#性能和可解释性的权衡"><span class="icon icon-link"></span></a>性能和可解释性的权衡</h3><p>有时我们还必须在模型的性能和可解释性之间进行权衡，比如有些合规性文件会要求公司在应用AI时，在给出判断结论的同时给出算法推导的原理和过程，这时候，我们采用相对简单的模型就能降低此部分合规性文档的解释难度。</p><p>高度可解释的算法（如线性回归模型）意味着我们可以轻松理解任何单个预测变量如何与要预测的目标相互关联，因为模型简单，所以很容易解释。但是，线性回归产生的映射函数范围小，其形状只能覆盖很小的特征空间，因此这类算法也被称为限制性算法。</p><p>也有些算法非常灵活，因为它们可以生成更广泛的映射函数形状。比如深层神经网络模型，它可以拟合任意形状的函数，但灵活的模型是以低可解释性为代价，来提供更高的准确性的。**一般来说，随着算法灵活性和准确性的增加，其可解释性会降低。**下图显示了各种算法在准确性和可解释性之间的权衡。</p><p><img src="/blog-other/static/httpsstatic001geekbangorgresourceimage9cb59c350f6b007824d0a9a24af1e817aab5.62d7ac12.png" alt="" title="准确性和可解释性算法之间的权衡"/></p><p>至于我们要使用哪种算法，就要取决于业务问题的目标了。如果你的目标是进行严密的推理，比如疾病的确诊过程，那么限制性模型会更好，因为它们更具可解释性。如果你以更高的精度为目标，那么灵活的模型会更好。</p><h3 id="速度或训练时间"><a aria-hidden="true" tabindex="-1" href="/blog-other/零基础实战机器学习/04.持续赋能篇/01#速度或训练时间"><span class="icon icon-link"></span></a>速度或训练时间</h3><p>更高的准确度通常也意味着更长的训练时间。此外，更大规模的数据集样本也需要更多时间来训练。在实际应用中，这个因素也会驱动算法的选择。</p><p>朴素贝叶斯、线性回归和逻辑回归这样的算法易于实现且运行迅速。像 SVM 这样的算法涉及参数调整，需要更多时间，而神经网络和随机森林，也都需要大量时间来训练数据。因此，如果你的机器学习模型是在线的应用，比如在网页上，用户选择了一个商品，你需要在一两秒钟之内呈现出推荐列表的清单，这时候你就不应该选择最精准但会耗时很长的算法了，而应该考虑朴素贝叶斯等更快的算法。</p><h3 id="数据的线性程度"><a aria-hidden="true" tabindex="-1" href="/blog-other/零基础实战机器学习/04.持续赋能篇/01#数据的线性程度"><span class="icon icon-link"></span></a>数据的线性程度</h3><p>最后，我们还可以通过评估数据特征和标签之间的线性程度，来选择具体的算法。</p><p>许多算法都假设不同类别可以由直线（或更高维的平面或者空间）来分隔，比如逻辑回归和支持向量机。线性回归算法则假设特征和标签数据的分布趋势遵循着一条直线。如果数据是线性的，那么这些算法的表现相当不错。</p><p>然而，数据并不总是线性的，因此对于更为复杂的数据集，我们需要可以处理高维和复杂数据结构的算法，比如核 SVM、随机森林、XGBoost和神经网络。</p><p>那么，如何找出监督学习数据集的线性程度呢？对于回归问题，我们可以像在<a target="_blank" rel="noopener noreferrer" href="https://time.geekbang.org/column/article/414504?cid=100085501">第3讲<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="__dumi-default-external-link-icon"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>中做的那样，显示特征和标签之间的散点图，看看是否能够拟合出线性回归线；对于分类问题，我们先尝试逻辑回归或线性SVM 并检查误差值和分类性能。如果误差值很高、分类性能差，则意味着数据不是线性的，需要复杂的算法来拟合。</p><h2 id="总结一下"><a aria-hidden="true" tabindex="-1" href="/blog-other/零基础实战机器学习/04.持续赋能篇/01#总结一下"><span class="icon icon-link"></span></a>总结一下</h2><p>好了，到这里我们这一讲就结束了。关于快速定位合适的机器学习算法，这其中的要点是定义好问题，明确是监督学习问题还是无监督学习问题，是分类问题还是回归问题，这能让我们排除掉不相干的算法。</p><p>在选择具体的算法时，我建议你从训练数据的大小、特征的数量、是着重考量模型的性能还是考量模型的可解释性、是否要求模型有很快的训练速度，以及数据的线性程度这几个方面，来选择最适宜的算法。</p><p>另外，我建议你从探索数据开始，熟悉你的数据。因为“更好的数据往往胜过更好的算法”，你对数据集的特征之间的性质了解得越清楚，越有可能得到高性能的模型。当然，对模型背后的原理和假设越了解，以及模型外部参数设定的含义越熟悉，也越有可能得到高性能的模型。</p><p>在定位合适的机器学习算法时，还有一个最基本的原则是，从简单的模型开始构建基准模型，然后尝试更复杂的方法。</p><p>最后，请你始终记住，尽可能地尝试多种算法，多种参数组合，然后比较它们的性能，以选择最适合特定任务的算法。但也不要忘记尝试集成方法，因为它通过博彩众长，能为你提供更好的准确性。</p><h2 id="思考题"><a aria-hidden="true" tabindex="-1" href="/blog-other/零基础实战机器学习/04.持续赋能篇/01#思考题"><span class="icon icon-link"></span></a>思考题</h2><p>这一路学习下来，面对不同的问题，你在算法选择方面有哪些心得？你发现哪些算法对于哪些问题有较好的性能呢？欢迎你在留言区和我分享你的观点，如果你认为这节课的内容有收获，也欢迎把它分享给你的朋友，我们下一讲再见！</p><p><img src="/blog-other/static/httpsstatic001geekbangorgresourceimagec969c9736533a2508cc501774069c7beyy69.8d5725ef.jpg" alt=""/></p></div><div class="__dumi-default-layout-footer-meta"><a target="_blank" rel="noopener noreferrer" href="https://github.com/GGwujun/blog/edit/master/ssrc/零基础实战机器学习/04.持续赋能篇/01.md">在 GitHub 上编辑此页<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="__dumi-default-external-link-icon"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a><span data-updated-text="最后更新时间：">2023/9/23 21:58:31</span></div></div></div></div>
	<script>
  window.g_useSSR = true;
  window.g_initialProps = {};
	</script>

    <script>
      (function () {
        if (!location.port) {
          (function (i, s, o, g, r, a, m) {
            i["GoogleAnalyticsObject"] = r;
            (i[r] =
              i[r] ||
              function () {
                (i[r].q = i[r].q || []).push(arguments);
              }),
              (i[r].l = 1 * new Date());
            (a = s.createElement(o)), (m = s.getElementsByTagName(o)[0]);
            a.async = 1;
            a.src = g;
            m.parentNode.insertBefore(a, m);
          })(
            window,
            document,
            "script",
            "//www.google-analytics.com/analytics.js",
            "ga"
          );
          ga("create", "UA-149864185-1", "auto");
          ga("send", "pageview");
        }
      })();
    </script>
    <script src="/blog-other/umi.js"></script>
  </body>
</html>
